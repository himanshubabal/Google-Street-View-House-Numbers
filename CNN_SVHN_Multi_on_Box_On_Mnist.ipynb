{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (229089, 32, 96, 1) (229089, 6)\n",
      "Test set (13068, 32, 96, 1) (13068, 6)\n",
      "Validation set (6666, 32, 96, 1) (6666, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "train_dataset = hdf['train_images'][:]\n",
    "train_labels = hdf['train_labels'][:]\n",
    "test_dataset = hdf['test_images'][:]\n",
    "test_labels = hdf['test_labels'][:]\n",
    "valid_dataset = hdf['valid_images'][:]\n",
    "valid_labels = hdf['valid_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.astype(np.float32)\n",
    "test_dataset = test_dataset.astype(np.float32)\n",
    "valid_dataset = valid_dataset.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "valid_labels = valid_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_save = \"saved_models/combined/multi_on_Box_on_Mnist/CNN_SVHN_Multi_on_Mnist.ckpt\"\n",
    "saved_box_model = \"saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 6 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 12     # First Conv Layer with depth 12\n",
    "    L = 24     # Second Conv Layer with depth 24\n",
    "    M = 36    # Third Conv layer with depth 36\n",
    "    N = 300   # Fourth Fully Connected layer with 300 neurons\n",
    "    P = 200   # Fifth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "    \n",
    "    W5 = tf.Variable(tf.truncated_normal([N, P], stddev=0.1), name=\"W5\")\n",
    "    B5 = tf.Variable(tf.constant(0.1, tf.float32, [P]), name=\"B5\")\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    Y5 = tf.nn.relu(tf.matmul(Y4, W5) + B5)\n",
    "    \n",
    "    Y_F = tf.nn.dropout(Y5, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(Y_F, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(Y_F, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(Y_F, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(Y_F, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(Y_F, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3))\\\n",
    "                   ,tf.reduce_max(tf.abs(W4)),tf.reduce_max(tf.abs(W5))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3))\\\n",
    "                   ,tf.reduce_max(tf.abs(B4)),tf.reduce_max(tf.abs(B5))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (229089, 32, 96, 1)   test :  (229089, 6)\n",
      "Initialized\n",
      "Loss at step 0: 11.541266\n",
      "Minibatch accuracy: 72.7%\n",
      "W :  [ 0.32006046  0.60453296  0.86063355  0.89860326  0.74231857]\n",
      "B :  [ 0.15549284  0.41545463  0.47191656  0.24130754  0.32073873]\n",
      "    \n",
      "Loss at step 500: 2.964242\n",
      "Minibatch accuracy: 83.1%\n",
      "W :  [ 0.30066329  0.61657333  0.86611772  0.87909031  0.78424287]\n",
      "B :  [ 0.12625395  0.38118425  0.4339228   0.24620239  0.3152588 ]\n",
      "    \n",
      "Loss at step 1000: 2.502760\n",
      "Minibatch accuracy: 85.8%\n",
      "W :  [ 0.30519444  0.61171657  0.86558706  0.88111782  0.78821146]\n",
      "B :  [ 0.12037468  0.38733053  0.42506835  0.24575007  0.32835981]\n",
      "    \n",
      "Loss at step 1500: 2.076753\n",
      "Minibatch accuracy: 88.8%\n",
      "W :  [ 0.30588427  0.61699432  0.87492841  0.88493609  0.78595442]\n",
      "B :  [ 0.12046263  0.38873038  0.42486161  0.24275196  0.33125883]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 1  Complete with accuracy: 82.58%\n",
      "Epoch 1  Test Accuracy : 73.98%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 2.211726\n",
      "Minibatch accuracy: 85.8%\n",
      "W :  [ 0.30606779  0.61014342  0.87534803  0.88470596  0.78801024]\n",
      "B :  [ 0.12906541  0.38902545  0.41784027  0.25252339  0.33375812]\n",
      "    \n",
      "Loss at step 500: 1.927143\n",
      "Minibatch accuracy: 88.3%\n",
      "W :  [ 0.30731177  0.62319386  0.8747738   0.88709474  0.78577471]\n",
      "B :  [ 0.12689447  0.38409752  0.42038214  0.25159746  0.3412815 ]\n",
      "    \n",
      "Loss at step 1000: 1.971518\n",
      "Minibatch accuracy: 88.8%\n",
      "W :  [ 0.3040455   0.61522418  0.87381625  0.88893807  0.79694593]\n",
      "B :  [ 0.12385113  0.38503566  0.42119235  0.25589076  0.35280779]\n",
      "    \n",
      "Loss at step 1500: 1.622441\n",
      "Minibatch accuracy: 90.6%\n",
      "W :  [ 0.30352977  0.62450027  0.8807506   0.88896573  0.79494691]\n",
      "B :  [ 0.11749189  0.38533449  0.42353863  0.2529403   0.36662069]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 2  Complete with accuracy: 88.36%\n",
      "Epoch 2  Test Accuracy : 74.64%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.746037\n",
      "Minibatch accuracy: 89.1%\n",
      "W :  [ 0.30291766  0.61845523  0.88091826  0.88954419  0.79572809]\n",
      "B :  [ 0.12299351  0.38361916  0.42070636  0.26067334  0.36683834]\n",
      "    \n",
      "Loss at step 500: 1.530872\n",
      "Minibatch accuracy: 91.6%\n",
      "W :  [ 0.30491966  0.63013619  0.88532037  0.88222688  0.79301405]\n",
      "B :  [ 0.1231375   0.37974292  0.42302376  0.26138601  0.37014684]\n",
      "    \n",
      "Loss at step 1000: 1.574051\n",
      "Minibatch accuracy: 90.3%\n",
      "W :  [ 0.30288622  0.63578349  0.88154286  0.87812436  0.80233163]\n",
      "B :  [ 0.12428313  0.3825461   0.42715162  0.26099691  0.38146603]\n",
      "    \n",
      "Loss at step 1500: 1.411486\n",
      "Minibatch accuracy: 92.7%\n",
      "W :  [ 0.3037608   0.6345607   0.88279444  0.86980277  0.8023876 ]\n",
      "B :  [ 0.11816627  0.38535199  0.42651638  0.26047274  0.39389312]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 3  Complete with accuracy: 90.90%\n",
      "Epoch 3  Test Accuracy : 76.59%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.382101\n",
      "Minibatch accuracy: 91.4%\n",
      "W :  [ 0.30350992  0.63530731  0.87520754  0.86987334  0.81028032]\n",
      "B :  [ 0.12510222  0.38342002  0.42850789  0.26113087  0.39625299]\n",
      "    \n",
      "Loss at step 500: 1.287369\n",
      "Minibatch accuracy: 93.0%\n",
      "W :  [ 0.30626598  0.65206486  0.89295316  0.86434627  0.81261617]\n",
      "B :  [ 0.12506483  0.38287517  0.43223423  0.26876017  0.39687195]\n",
      "    \n",
      "Loss at step 1000: 1.322810\n",
      "Minibatch accuracy: 92.5%\n",
      "W :  [ 0.30320334  0.64852232  0.87842882  0.86232382  0.82545346]\n",
      "B :  [ 0.12750371  0.38483274  0.43672803  0.26692927  0.40390754]\n",
      "    \n",
      "Loss at step 1500: 1.327238\n",
      "Minibatch accuracy: 91.7%\n",
      "W :  [ 0.30403572  0.65670896  0.88182265  0.86244327  0.82163817]\n",
      "B :  [ 0.12181983  0.38812631  0.43630829  0.26821414  0.41320458]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 4  Complete with accuracy: 92.15%\n",
      "Epoch 4  Test Accuracy : 77.51%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.233442\n",
      "Minibatch accuracy: 92.7%\n",
      "W :  [ 0.30588591  0.6551314   0.88265473  0.85943639  0.82620561]\n",
      "B :  [ 0.12482892  0.38782772  0.43862924  0.27061573  0.41301405]\n",
      "    \n",
      "Loss at step 500: 1.105828\n",
      "Minibatch accuracy: 93.8%\n",
      "W :  [ 0.31122985  0.65884811  0.90904206  0.85533452  0.82953614]\n",
      "B :  [ 0.12686294  0.38805461  0.43636104  0.27693588  0.41256249]\n",
      "    \n",
      "Loss at step 1000: 1.087761\n",
      "Minibatch accuracy: 93.8%\n",
      "W :  [ 0.3087742   0.67059976  0.90666157  0.85494095  0.83930427]\n",
      "B :  [ 0.13275456  0.39103815  0.44266602  0.27779886  0.41522536]\n",
      "    \n",
      "Loss at step 1500: 1.139427\n",
      "Minibatch accuracy: 93.0%\n",
      "W :  [ 0.31064644  0.67363197  0.91498834  0.85769564  0.8390069 ]\n",
      "B :  [ 0.12124582  0.39388728  0.4452247   0.27424496  0.4209083 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 5  Complete with accuracy: 93.28%\n",
      "Epoch 5  Test Accuracy : 75.56%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.077289\n",
      "Minibatch accuracy: 93.4%\n",
      "W :  [ 0.31325185  0.67118627  0.9128741   0.86673743  0.84222919]\n",
      "B :  [ 0.12999298  0.39511153  0.44531077  0.27889547  0.41827652]\n",
      "    \n",
      "Loss at step 500: 0.815365\n",
      "Minibatch accuracy: 94.8%\n",
      "W :  [ 0.31542617  0.66690308  0.91838825  0.86597425  0.85395128]\n",
      "B :  [ 0.13399415  0.39728105  0.44446123  0.28389508  0.41778016]\n",
      "    \n",
      "Loss at step 1000: 0.889372\n",
      "Minibatch accuracy: 95.2%\n",
      "W :  [ 0.31492072  0.67235988  0.9279421   0.87038076  0.85585088]\n",
      "B :  [ 0.13381436  0.40145683  0.45659426  0.28421792  0.41760382]\n",
      "    \n",
      "Loss at step 1500: 0.976384\n",
      "Minibatch accuracy: 93.6%\n",
      "W :  [ 0.31808791  0.67707276  0.9396463   0.87169349  0.85973573]\n",
      "B :  [ 0.12723628  0.40614656  0.45629036  0.28195629  0.42039025]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 6  Complete with accuracy: 94.26%\n",
      "Epoch 6  Test Accuracy : 76.97%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.014242\n",
      "Minibatch accuracy: 93.4%\n",
      "W :  [ 0.31784511  0.68057525  0.93652564  0.86970693  0.86184621]\n",
      "B :  [ 0.13079654  0.40546376  0.45651346  0.28434616  0.41541505]\n",
      "    \n",
      "Loss at step 500: 0.704642\n",
      "Minibatch accuracy: 95.8%\n",
      "W :  [ 0.32276389  0.68229514  0.94423437  0.86867595  0.84686446]\n",
      "B :  [ 0.13726205  0.40896448  0.45453721  0.28826547  0.41355813]\n",
      "    \n",
      "Loss at step 1000: 0.891015\n",
      "Minibatch accuracy: 94.5%\n",
      "W :  [ 0.32087246  0.69679445  0.9462629   0.8718518   0.84735423]\n",
      "B :  [ 0.14213356  0.41129619  0.46132776  0.28890133  0.41445273]\n",
      "    \n",
      "Loss at step 1500: 0.813936\n",
      "Minibatch accuracy: 94.8%\n",
      "W :  [ 0.32398096  0.69853789  0.95919764  0.88182938  0.85434091]\n",
      "B :  [ 0.13400805  0.41870049  0.46704635  0.28744429  0.41878629]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 7  Complete with accuracy: 94.65%\n",
      "Epoch 7  Test Accuracy : 77.28%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.802342\n",
      "Minibatch accuracy: 95.5%\n",
      "W :  [ 0.32439053  0.69622201  0.96025217  0.8857742   0.85490733]\n",
      "B :  [ 0.14044297  0.41932029  0.46727428  0.29251134  0.419873  ]\n",
      "    \n",
      "Loss at step 500: 0.582291\n",
      "Minibatch accuracy: 96.7%\n",
      "W :  [ 0.32708874  0.68996054  0.96381217  0.88249016  0.84887379]\n",
      "B :  [ 0.14150371  0.42084411  0.46594492  0.2951965   0.4170796 ]\n",
      "    \n",
      "Loss at step 1000: 0.818083\n",
      "Minibatch accuracy: 95.8%\n",
      "W :  [ 0.32666799  0.70026666  0.96786773  0.88949031  0.86983222]\n",
      "B :  [ 0.14524466  0.4225027   0.47513226  0.29123062  0.42086726]\n",
      "    \n",
      "Loss at step 1500: 0.731703\n",
      "Minibatch accuracy: 95.5%\n",
      "W :  [ 0.32975388  0.70283651  0.99019277  0.89477396  0.87667358]\n",
      "B :  [ 0.14226386  0.4283388   0.47678107  0.29253551  0.42144343]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 8  Complete with accuracy: 95.86%\n",
      "Epoch 8  Test Accuracy : 75.48%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.786969\n",
      "Minibatch accuracy: 95.3%\n",
      "W :  [ 0.32883471  0.71003437  0.99141812  0.89353311  0.87805092]\n",
      "B :  [ 0.14508978  0.43274459  0.4783943   0.29703483  0.41996083]\n",
      "    \n",
      "Loss at step 500: 0.530566\n",
      "Minibatch accuracy: 96.7%\n",
      "W :  [ 0.33453158  0.70996332  0.97827089  0.88813448  0.88210303]\n",
      "B :  [ 0.1451879   0.43561369  0.47581893  0.29715988  0.41704431]\n",
      "    \n",
      "Loss at step 1000: 0.641558\n",
      "Minibatch accuracy: 96.1%\n",
      "W :  [ 0.33237669  0.72238684  0.99299324  0.88800758  0.88105059]\n",
      "B :  [ 0.15057585  0.43595219  0.48463917  0.29536906  0.41708168]\n",
      "    \n",
      "Loss at step 1500: 0.551777\n",
      "Minibatch accuracy: 96.4%\n",
      "W :  [ 0.33680433  0.72387284  1.00979042  0.88211429  0.88122451]\n",
      "B :  [ 0.14184454  0.44388372  0.48687774  0.29679263  0.41418946]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 9  Complete with accuracy: 96.13%\n",
      "Epoch 9  Test Accuracy : 75.67%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.816090\n",
      "Minibatch accuracy: 95.0%\n",
      "W :  [ 0.33661813  0.72317433  1.00551414  0.89070272  0.89042836]\n",
      "B :  [ 0.14505714  0.44656646  0.48971412  0.29986942  0.41526595]\n",
      "    \n",
      "Loss at step 500: 0.486599\n",
      "Minibatch accuracy: 96.6%\n",
      "W :  [ 0.34110034  0.72771209  1.00549126  0.88538152  0.88577312]\n",
      "B :  [ 0.14820589  0.45053804  0.48825464  0.30184245  0.42157614]\n",
      "    \n",
      "Loss at step 1000: 0.774609\n",
      "Minibatch accuracy: 95.8%\n",
      "W :  [ 0.3414838   0.75142944  1.01045024  0.89375728  0.88222748]\n",
      "B :  [ 0.15224974  0.45178011  0.49861702  0.3028903   0.41698426]\n",
      "    \n",
      "Loss at step 1500: 0.623973\n",
      "Minibatch accuracy: 95.9%\n",
      "W :  [ 0.34140536  0.74446362  1.00422704  0.90272021  0.89497834]\n",
      "B :  [ 0.14265449  0.45575088  0.49956268  0.30289423  0.42105389]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 10  Complete with accuracy: 95.82%\n",
      "Epoch 10  Test Accuracy : 77.16%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.579003\n",
      "Minibatch accuracy: 95.9%\n",
      "W :  [ 0.34147114  0.73977888  1.00477338  0.90601081  0.90140575]\n",
      "B :  [ 0.14976363  0.45992312  0.50013697  0.30668646  0.41894555]\n",
      "    \n",
      "Loss at step 500: 0.555178\n",
      "Minibatch accuracy: 96.1%\n",
      "W :  [ 0.3473573   0.73928887  0.99606079  0.90186107  0.90617675]\n",
      "B :  [ 0.15180525  0.46229649  0.497087    0.30711281  0.41754377]\n",
      "    \n",
      "Loss at step 1000: 0.593850\n",
      "Minibatch accuracy: 96.1%\n",
      "W :  [ 0.34685716  0.74558949  1.00445938  0.9111197   0.90432239]\n",
      "B :  [ 0.15802836  0.46058488  0.50576764  0.30521768  0.4157252 ]\n",
      "    \n",
      "Loss at step 1500: 0.693018\n",
      "Minibatch accuracy: 94.8%\n",
      "W :  [ 0.34942341  0.75434166  1.01592338  0.90570295  0.91075742]\n",
      "B :  [ 0.15163234  0.46691746  0.51363397  0.30526054  0.41702104]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 11  Complete with accuracy: 95.74%\n",
      "Epoch 11  Test Accuracy : 76.70%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.566388\n",
      "Minibatch accuracy: 96.4%\n",
      "W :  [ 0.35080042  0.75177687  1.00547218  0.91343069  0.92728817]\n",
      "B :  [ 0.15597923  0.47270089  0.51137209  0.31171662  0.41240877]\n",
      "    \n",
      "Loss at step 500: 0.349782\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.35261506  0.76581776  1.0005126   0.92540079  0.93050164]\n",
      "B :  [ 0.163518    0.47642317  0.50617385  0.31312007  0.40981194]\n",
      "    \n",
      "Loss at step 1000: 0.488890\n",
      "Minibatch accuracy: 96.7%\n",
      "W :  [ 0.35288671  0.76971233  1.00763452  0.92629647  0.93806469]\n",
      "B :  [ 0.1590391   0.47322461  0.51590317  0.30739707  0.41006425]\n",
      "    \n",
      "Loss at step 1500: 0.399942\n",
      "Minibatch accuracy: 97.7%\n",
      "W :  [ 0.3527211   0.77235055  1.02204156  0.93975526  0.94034272]\n",
      "B :  [ 0.15832523  0.47725117  0.5257501   0.30945972  0.41049063]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 12  Complete with accuracy: 97.07%\n",
      "Epoch 12  Test Accuracy : 77.55%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.513598\n",
      "Minibatch accuracy: 96.4%\n",
      "W :  [ 0.353459    0.767102    1.01831508  0.93664449  0.93546391]\n",
      "B :  [ 0.15562147  0.48433709  0.52462751  0.31301227  0.40973386]\n",
      "    \n",
      "Loss at step 500: 0.399620\n",
      "Minibatch accuracy: 96.9%\n",
      "W :  [ 0.35905975  0.77049291  1.03622603  0.94823319  0.93497109]\n",
      "B :  [ 0.16212368  0.4870168   0.52114123  0.30741695  0.41125676]\n",
      "    \n",
      "Loss at step 1000: 0.447587\n",
      "Minibatch accuracy: 97.0%\n",
      "W :  [ 0.35696238  0.77189553  1.03394902  0.94520354  0.93189126]\n",
      "B :  [ 0.16542444  0.48617813  0.5310123   0.30960137  0.41291401]\n",
      "    \n",
      "Loss at step 1500: 0.430217\n",
      "Minibatch accuracy: 96.9%\n",
      "W :  [ 0.35753605  0.78460366  1.03894639  0.94257396  0.95360398]\n",
      "B :  [ 0.15285319  0.49550313  0.53645009  0.30856097  0.4165853 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 13  Complete with accuracy: 96.80%\n",
      "Epoch 13  Test Accuracy : 75.40%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.394540\n",
      "Minibatch accuracy: 97.3%\n",
      "W :  [ 0.35767052  0.79453582  1.03711772  0.94057411  0.95568353]\n",
      "B :  [ 0.16323531  0.49910361  0.53629476  0.31042469  0.4207409 ]\n",
      "    \n",
      "Loss at step 1000: 0.360335\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.36683524  0.79030508  1.03316104  0.93725938  0.98809224]\n",
      "B :  [ 0.17510979  0.51888788  0.54755479  0.31669623  0.43863013]\n",
      "    \n",
      "Loss at step 1500: 0.669029\n",
      "Minibatch accuracy: 95.2%\n",
      "W :  [ 0.36787722  0.78990865  1.04148126  0.94247901  0.99742788]\n",
      "B :  [ 0.16800186  0.52193165  0.55597472  0.3174828   0.43133843]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 15  Complete with accuracy: 96.99%\n",
      "Epoch 15  Test Accuracy : 76.59%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.445299\n",
      "Minibatch accuracy: 96.6%\n",
      "W :  [ 0.36808911  0.78557676  1.04578698  0.94490707  0.99526584]\n",
      "B :  [ 0.17034934  0.52702057  0.556036    0.32325223  0.43232346]\n",
      "    \n",
      "Loss at step 500: 0.184878\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.37400573  0.789922    1.06602764  0.93885863  1.01417291]\n",
      "B :  [ 0.17056166  0.53271425  0.55282247  0.31981802  0.43777788]\n",
      "    \n",
      "Loss at step 1000: 0.296441\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.37151366  0.77306658  1.07563102  0.95248657  1.02252185]\n",
      "B :  [ 0.17650095  0.53263253  0.55659229  0.31741875  0.43594277]\n",
      "    \n",
      "Loss at step 1500: 0.361916\n",
      "Minibatch accuracy: 97.0%\n",
      "W :  [ 0.37478763  0.78555107  1.09848857  0.95601618  1.01564217]\n",
      "B :  [ 0.16684672  0.53372699  0.565907    0.32200953  0.43595198]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 16  Complete with accuracy: 97.50%\n",
      "Epoch 16  Test Accuracy : 75.71%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.392986\n",
      "Minibatch accuracy: 97.0%\n",
      "W :  [ 0.37597242  0.7841801   1.09986377  0.95828921  1.03555143]\n",
      "B :  [ 0.17039199  0.53773266  0.56515563  0.32135236  0.43609771]\n",
      "    \n",
      "Loss at step 500: 0.209184\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.37911737  0.79016376  1.1014688   0.9690038   1.03381741]\n",
      "B :  [ 0.17638467  0.53938335  0.56174898  0.31794846  0.44046211]\n",
      "    \n",
      "Loss at step 1000: 0.320497\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.37659413  0.80685306  1.10322046  0.98591602  1.0293932 ]\n",
      "B :  [ 0.17808743  0.54308397  0.56586504  0.31908888  0.44347546]\n",
      "    \n",
      "Loss at step 1500: 0.276275\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.379906    0.80655748  1.09624064  0.97487104  1.03453815]\n",
      "B :  [ 0.16769642  0.5473507   0.5683108   0.32387313  0.44148031]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 17  Complete with accuracy: 98.00%\n",
      "Epoch 17  Test Accuracy : 74.83%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.376469\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.37983337  0.80683076  1.09156871  0.96911639  1.03910685]\n",
      "B :  [ 0.17447723  0.54810399  0.56961733  0.32634199  0.44382137]\n",
      "    \n",
      "Loss at step 500: 0.330377\n",
      "Minibatch accuracy: 98.0%\n",
      "W :  [ 0.37909004  0.800174    1.09209502  0.95958269  1.04472065]\n",
      "B :  [ 0.16971873  0.55078018  0.56559461  0.31859702  0.46047556]\n",
      "    \n",
      "Loss at step 1000: 0.302413\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.37867627  0.80112511  1.09131432  0.97534919  1.05145574]\n",
      "B :  [ 0.16965948  0.55712211  0.56890196  0.31486455  0.45769483]\n",
      "    \n",
      "Loss at step 1500: 0.350354\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.38028836  0.81176519  1.10049176  0.9751969   1.05471802]\n",
      "B :  [ 0.16345611  0.55773538  0.57672578  0.3218857   0.4537358 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 18  Complete with accuracy: 98.01%\n",
      "Epoch 18  Test Accuracy : 75.40%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.337054\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.37834495  0.81824535  1.08890355  0.97721356  1.05313098]\n",
      "B :  [ 0.17453305  0.56073499  0.57556516  0.3270019   0.45671931]\n",
      "    \n",
      "Loss at step 500: 0.213907\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.38107914  0.82212007  1.10744381  0.97051454  1.04130828]\n",
      "B :  [ 0.17025924  0.56417114  0.572133    0.31785899  0.4659979 ]\n",
      "    \n",
      "Loss at step 1000: 0.325993\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.38204724  0.82122767  1.10699606  0.96727502  1.04262924]\n",
      "B :  [ 0.17999394  0.56571996  0.57139224  0.32460731  0.4640609 ]\n",
      "    \n",
      "Loss at step 1500: 0.388539\n",
      "Minibatch accuracy: 96.7%\n",
      "W :  [ 0.38403416  0.81902969  1.10554719  0.96463281  1.0447166 ]\n",
      "B :  [ 0.16804762  0.57115185  0.57960773  0.32588354  0.45786068]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 19  Complete with accuracy: 97.69%\n",
      "Epoch 19  Test Accuracy : 73.49%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.312768\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.38211346  0.81688106  1.09818387  0.97099918  1.04320097]\n",
      "B :  [ 0.17390171  0.57376307  0.57877195  0.32593116  0.46875551]\n",
      "    \n",
      "Loss at step 500: 0.214545\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.38006201  0.80831999  1.10234702  0.97783417  1.05320668]\n",
      "B :  [ 0.17321405  0.57416058  0.57655799  0.32336456  0.47108746]\n",
      "    \n",
      "Loss at step 1000: 0.379264\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.38204548  0.79895377  1.09749782  0.96531469  1.06039608]\n",
      "B :  [ 0.17700095  0.57281888  0.57900375  0.32201895  0.47288147]\n",
      "    \n",
      "Loss at step 1500: 0.239442\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.38585547  0.80236328  1.11549473  0.96994185  1.06249189]\n",
      "B :  [ 0.17181891  0.57674795  0.58708268  0.32207221  0.46598253]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 20  Complete with accuracy: 98.08%\n",
      "Epoch 20  Test Accuracy : 73.64%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.382499\n",
      "Minibatch accuracy: 97.0%\n",
      "W :  [ 0.38762999  0.80936414  1.11024904  0.97639406  1.05986226]\n",
      "B :  [ 0.17773455  0.57936192  0.58474725  0.32490695  0.47225049]\n",
      "    \n",
      "Loss at step 500: 0.246699\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.38648468  0.79863524  1.09991455  0.99557161  1.04523134]\n",
      "B :  [ 0.17750159  0.58557522  0.5873552   0.32309869  0.4694539 ]\n",
      "    \n",
      "Loss at step 1000: 0.242206\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.38698536  0.80389571  1.11670852  1.00501144  1.06178057]\n",
      "B :  [ 0.17957363  0.58546507  0.59041798  0.32445034  0.47028393]\n",
      "    \n",
      "Loss at step 1500: 0.266497\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.38853171  0.79442799  1.10789406  1.00837409  1.06382406]\n",
      "B :  [ 0.17520629  0.58904064  0.60115516  0.32540068  0.47152856]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 21  Complete with accuracy: 98.09%\n",
      "Epoch 21  Test Accuracy : 77.66%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.187395\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.39094824  0.80889028  1.1021018   1.00832319  1.07674277]\n",
      "B :  [ 0.18047257  0.59048504  0.60016245  0.33074379  0.48172718]\n",
      "    \n",
      "Loss at step 500: 0.217217\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.39281586  0.80721766  1.10448956  1.00286794  1.0836426 ]\n",
      "B :  [ 0.17947905  0.59196478  0.59836674  0.3273083   0.48713937]\n",
      "    \n",
      "Loss at step 1000: 0.308742\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.39200121  0.81563377  1.10627425  1.0052526   1.07994163]\n",
      "B :  [ 0.18426223  0.59327263  0.59877634  0.32820341  0.48523578]\n",
      "    \n",
      "Loss at step 1500: 0.197009\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.39234406  0.81114954  1.1140343   1.0262121   1.07001007]\n",
      "B :  [ 0.17408057  0.5971275   0.60543168  0.32921654  0.47718933]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 22  Complete with accuracy: 98.40%\n",
      "Epoch 22  Test Accuracy : 75.79%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.337436\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.39285466  0.81248873  1.1152668   1.03214335  1.07667184]\n",
      "B :  [ 0.18093584  0.59617317  0.59979129  0.33309841  0.48128837]\n",
      "    \n",
      "Loss at step 500: 0.151849\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.39348879  0.80532867  1.11298573  1.0266819   1.10078502]\n",
      "B :  [ 0.18012705  0.60218     0.6011712   0.3307128   0.48182139]\n",
      "    \n",
      "Loss at step 1000: 0.238977\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.38933635  0.80981588  1.10530567  1.0306412   1.09830976]\n",
      "B :  [ 0.18122075  0.59989089  0.60523957  0.33025903  0.48598462]\n",
      "    \n",
      "Loss at step 1500: 0.209887\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.39191881  0.8076821   1.11160767  1.03117013  1.0983628 ]\n",
      "B :  [ 0.17165761  0.59766597  0.61929768  0.33008352  0.4792856 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 23  Complete with accuracy: 98.44%\n",
      "Epoch 23  Test Accuracy : 76.32%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.177263\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.39123419  0.81141526  1.10629034  1.03640747  1.10956573]\n",
      "B :  [ 0.17625192  0.6003015   0.61758274  0.33346367  0.48091608]\n",
      "    \n",
      "Loss at step 500: 0.184002\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.39436877  0.81028974  1.10551131  1.04286659  1.11984885]\n",
      "B :  [ 0.1754604   0.60039997  0.61299372  0.33049741  0.48532254]\n",
      "    \n",
      "Loss at step 1000: 0.278259\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.39196959  0.82762593  1.1229912   1.04632509  1.11177874]\n",
      "B :  [ 0.18213022  0.6025157   0.61480981  0.32909751  0.49569762]\n",
      "    \n",
      "Loss at step 1500: 0.325275\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.39421815  0.8408463   1.13284171  1.02547753  1.12154126]\n",
      "B :  [ 0.17723687  0.60454702  0.62600684  0.32880002  0.4904536 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 24  Complete with accuracy: 98.44%\n",
      "Epoch 24  Test Accuracy : 73.45%\n",
      "------------------------------------\n",
      "        \n",
      "Training Complete on MNIST Data\n",
      "Test Accuracy :  75.82694763729248\n",
      "Model saved in file: saved_models/combined/multi_on_Box_on_Mnist/CNN_SVHN_Multi_on_Mnist.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset\n",
    "label_data = train_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "multi_all_train_dict = {}\n",
    "batch_size = 128\n",
    "num_steps = int(label_data.shape[0] / batch_size)\n",
    "num_epochs = 25\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    # tf.global_variables_initializer().run()\n",
    "    model_saver.restore(session, saved_box_model)\n",
    "    print('Initialized')\n",
    "\n",
    "    test_batch = int(test_dataset.shape[0]/num_epochs)\n",
    "    test_acc = list()\n",
    "    \n",
    "    for epoch in range(num_epochs - 1):\n",
    "        res_epoch = {}\n",
    "        t_data = test_dataset[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        t_label = test_labels[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        \n",
    "        for step in range(num_steps - 1):\n",
    "            max_learning_rate = 0.0005\n",
    "            min_learning_rate = 0.0001\n",
    "\n",
    "            decay_speed = 5000.0\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "\n",
    "            batch_data = train_data[step*batch_size:(step + 1)*batch_size, :, :, :]\n",
    "            batch_labels = label_data[step*batch_size:(step + 1)*batch_size, :]\n",
    "\n",
    "            feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "            _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "            accuracy = float(acc(train_pred, batch_labels[:,1:6]))\n",
    "\n",
    "            if (step % 500 == 0):\n",
    "                minibatch = {}\n",
    "                minibatch['loss'] = l\n",
    "                minibatch['W'] = W\n",
    "                minibatch['B'] = b\n",
    "                minibatch['accuracy'] = \"%.2f\" % accuracy\n",
    "\n",
    "                res_epoch[int(step/500)] = minibatch\n",
    "                print('Loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "                print('W : ',W)\n",
    "                print('B : ',b)\n",
    "                print('    ')\n",
    "                \n",
    "        multi_all_train_dict[epoch+1] = res_epoch\n",
    "\n",
    "        epoch_acc = 0\n",
    "        for f in res_epoch:\n",
    "            minibatch = res_epoch[f]\n",
    "            epoch_acc += float(minibatch['accuracy'])\n",
    "        epoch_acc = float(epoch_acc/len(res_epoch))\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : t_data, Y_ : t_label, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = float(acc(predictions, t_label[:,1:6]))\n",
    "        test_acc.append(accuracy)\n",
    "\n",
    "        print('------------------------------------')\n",
    "        print('Epoch',epoch+1,' Complete with accuracy: %.2f%%' % epoch_acc)\n",
    "        print('Epoch',epoch+1,' Test Accuracy : %.2f%%' % accuracy)\n",
    "        print('------------------------------------')\n",
    "        print('        ')\n",
    "            \n",
    "    print('Training Complete on MNIST Data')\n",
    "    print('Test Accuracy : ', mean(test_acc))\n",
    "    \n",
    "    save_path = model_saver.save(session, model_to_save)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'results/Multi_on_all.pickle'\n",
    "\n",
    "with open(file, 'wb') as handle:\n",
    "    pickle.dump(multi_all_train_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Valid-Accuracy 0\n",
      "Valid accuracy:  89.48\n",
      "        \n",
      "Valid-Accuracy 1\n",
      "Valid accuracy:  90.08\n",
      "        \n",
      "Valid-Accuracy 2\n",
      "Valid accuracy:  90.22\n",
      "        \n",
      "Valid-Accuracy 3\n",
      "Valid accuracy:  90.1\n",
      "        \n",
      "Valid-Accuracy 4\n",
      "Valid accuracy:  89.56\n",
      "        \n",
      "-----  FINAL  ------\n",
      "Final Validation Set Accuracy :  89.89\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    batch = 1000\n",
    "    \n",
    "    valid_acc = list()\n",
    "    valid_no = int(valid_labels.shape[0] /  batch)\n",
    "    for i in range(valid_no - 1):\n",
    "        model_saver.restore(session, model_to_save)\n",
    "        data = valid_dataset[i*batch:(i+1)*batch]\n",
    "        labels = valid_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        valid_acc.append(accuracy)\n",
    "        \n",
    "        print('Valid-Accuracy', i)\n",
    "        print('Valid accuracy: ', accuracy)\n",
    "        print('        ')\n",
    "            \n",
    "    valid_avg = mean(valid_acc)\n",
    "    \n",
    "    print('-----  FINAL  ------')\n",
    "    print('Final Validation Set Accuracy : ',\"%.2f\" % valid_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
