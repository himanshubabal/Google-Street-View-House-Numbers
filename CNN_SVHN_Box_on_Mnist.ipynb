{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (230070, 32, 96, 1) (230070, 6)\n",
      "Test set (13068, 32, 96, 1) (13068, 6)\n",
      "Validation set (5684, 32, 96, 1) (5684, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi_box.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "train_dataset = hdf['train_images'][:]\n",
    "train_labels = hdf['train_labels'][:]\n",
    "test_dataset = hdf['test_images'][:]\n",
    "test_labels = hdf['test_labels'][:]\n",
    "valid_dataset = hdf['valid_images'][:]\n",
    "valid_labels = hdf['valid_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.astype(np.float32)\n",
    "test_dataset = test_dataset.astype(np.float32)\n",
    "valid_dataset = valid_dataset.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "valid_labels = valid_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_save = \"saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\"\n",
    "saved_mnist_model = \"saved_models/mnist/CNN_SVHN_Mnist.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 6 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 12     # First Conv Layer with depth 12\n",
    "    L = 24     # Second Conv Layer with depth 24\n",
    "    M = 36    # Third Conv layer with depth 36\n",
    "    N = 300   # Fourth Fully Connected layer with 300 neurons\n",
    "    P = 200   # Fifth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "    \n",
    "    W5 = tf.Variable(tf.truncated_normal([N, P], stddev=0.1), name=\"W5\")\n",
    "    B5 = tf.Variable(tf.constant(0.1, tf.float32, [P]), name=\"B5\")\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    Y5 = tf.nn.relu(tf.matmul(Y4, W5) + B5)\n",
    "    \n",
    "    Y_F = tf.nn.dropout(Y5, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(Y_F, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(Y_F, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(Y_F, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(Y_F, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(Y_F, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3))\\\n",
    "                   ,tf.reduce_max(tf.abs(W4)),tf.reduce_max(tf.abs(W5))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3))\\\n",
    "                   ,tf.reduce_max(tf.abs(B4)),tf.reduce_max(tf.abs(B5))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (230070, 32, 96, 1)   test :  (230070, 6)\n",
      "Initialized\n",
      "Loss at step 0: 15.724194\n",
      "Minibatch accuracy: 5.6%\n",
      "W :  [ 0.30989823  0.38223922  0.43278304  0.77872795  0.57660186]\n",
      "B :  [ 0.09201913  0.22464228  0.26228482  0.22948168  0.23504254]\n",
      "    \n",
      "Loss at step 500: 2.042267\n",
      "Minibatch accuracy: 86.4%\n",
      "W :  [ 0.29254538  0.38526696  0.43212166  0.77870804  0.57500988]\n",
      "B :  [ 0.15458682  0.23972686  0.24613462  0.21688513  0.2386256 ]\n",
      "    \n",
      "Loss at step 1000: 1.910222\n",
      "Minibatch accuracy: 88.9%\n",
      "W :  [ 0.29439902  0.3913981   0.43096092  0.77870804  0.57500988]\n",
      "B :  [ 0.16403453  0.24005911  0.24644572  0.21710132  0.23900931]\n",
      "    \n",
      "Loss at step 1500: 1.249308\n",
      "Minibatch accuracy: 93.0%\n",
      "W :  [ 0.28906494  0.39322683  0.43272111  0.77860934  0.57500988]\n",
      "B :  [ 0.16133364  0.24153487  0.24637467  0.22078297  0.24130054]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 1  Complete with accuracy: 68.48%\n",
      "Epoch 1  Test Accuracy : 90.69%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.583975\n",
      "Minibatch accuracy: 90.2%\n",
      "W :  [ 0.28561094  0.39549524  0.43675658  0.77856368  0.57500988]\n",
      "B :  [ 0.1646353   0.24141131  0.2470147   0.22498439  0.24166912]\n",
      "    \n",
      "Loss at step 500: 1.005968\n",
      "Minibatch accuracy: 93.8%\n",
      "W :  [ 0.28274265  0.40561381  0.4257158   0.7787897   0.57500988]\n",
      "B :  [ 0.16231142  0.24552758  0.2466398   0.22910695  0.24470265]\n",
      "    \n",
      "Loss at step 1000: 1.230298\n",
      "Minibatch accuracy: 93.6%\n",
      "W :  [ 0.28014693  0.40554118  0.43906036  0.77880627  0.5748226 ]\n",
      "B :  [ 0.16462104  0.24416001  0.2471301   0.22876099  0.24625033]\n",
      "    \n",
      "Loss at step 1500: 0.897277\n",
      "Minibatch accuracy: 94.1%\n",
      "W :  [ 0.28079087  0.40701431  0.45042902  0.77883404  0.5748226 ]\n",
      "B :  [ 0.1639466   0.24706522  0.24601144  0.22914639  0.24478389]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 2  Complete with accuracy: 92.89%\n",
      "Epoch 2  Test Accuracy : 93.26%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.908785\n",
      "Minibatch accuracy: 94.4%\n",
      "W :  [ 0.27939826  0.40979815  0.45261595  0.77883404  0.5748226 ]\n",
      "B :  [ 0.16805382  0.25432295  0.24868928  0.23176335  0.24917853]\n",
      "    \n",
      "Loss at step 500: 0.772005\n",
      "Minibatch accuracy: 95.6%\n",
      "W :  [ 0.28032216  0.411605    0.43436322  0.77883404  0.5748257 ]\n",
      "B :  [ 0.16601816  0.25688335  0.24895096  0.23079978  0.24911778]\n",
      "    \n",
      "Loss at step 1000: 0.903369\n",
      "Minibatch accuracy: 95.5%\n",
      "W :  [ 0.28114903  0.41831243  0.44051278  0.77873665  0.5748257 ]\n",
      "B :  [ 0.16535334  0.25739086  0.25031808  0.23299035  0.24900001]\n",
      "    \n",
      "Loss at step 1500: 0.670976\n",
      "Minibatch accuracy: 95.6%\n",
      "W :  [ 0.28255606  0.42522439  0.43190867  0.77873665  0.5748257 ]\n",
      "B :  [ 0.16838455  0.25919703  0.24930258  0.22974843  0.25141203]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 3  Complete with accuracy: 95.27%\n",
      "Epoch 3  Test Accuracy : 92.91%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.668607\n",
      "Minibatch accuracy: 95.6%\n",
      "W :  [ 0.28212613  0.42103162  0.42852327  0.77873665  0.5748257 ]\n",
      "B :  [ 0.17660183  0.2626366   0.2525872   0.23231445  0.25213614]\n",
      "    \n",
      "Loss at step 500: 0.628057\n",
      "Minibatch accuracy: 95.8%\n",
      "W :  [ 0.28310525  0.42737201  0.43697751  0.77873665  0.5748257 ]\n",
      "B :  [ 0.17193288  0.26904368  0.25566947  0.23248777  0.25093222]\n",
      "    \n",
      "Loss at step 1000: 0.637546\n",
      "Minibatch accuracy: 96.1%\n",
      "W :  [ 0.28305107  0.43557104  0.42651847  0.77873665  0.5748257 ]\n",
      "B :  [ 0.17173293  0.26467913  0.26011968  0.23385304  0.25417292]\n",
      "    \n",
      "Loss at step 1500: 0.522590\n",
      "Minibatch accuracy: 96.6%\n",
      "W :  [ 0.2854037   0.43812215  0.42916787  0.77873665  0.5748257 ]\n",
      "B :  [ 0.1727346   0.26308015  0.26137081  0.23176037  0.25113514]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 4  Complete with accuracy: 96.01%\n",
      "Epoch 4  Test Accuracy : 93.83%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.463056\n",
      "Minibatch accuracy: 97.3%\n",
      "W :  [ 0.28336877  0.44103235  0.43336973  0.77873665  0.5748257 ]\n",
      "B :  [ 0.18149842  0.26765773  0.26794824  0.23424485  0.24892589]\n",
      "    \n",
      "Loss at step 500: 0.551206\n",
      "Minibatch accuracy: 97.0%\n",
      "W :  [ 0.28533751  0.44405311  0.43748012  0.77873665  0.5748257 ]\n",
      "B :  [ 0.18113104  0.27434602  0.26674005  0.2361103   0.24808517]\n",
      "    \n",
      "Loss at step 1000: 0.547692\n",
      "Minibatch accuracy: 96.2%\n",
      "W :  [ 0.28617862  0.4499124   0.44677985  0.77873665  0.5748257 ]\n",
      "B :  [ 0.17654456  0.2736285   0.26943809  0.23696826  0.25453943]\n",
      "    \n",
      "Loss at step 1500: 0.429855\n",
      "Minibatch accuracy: 97.3%\n",
      "W :  [ 0.28780475  0.4560864   0.45245868  0.77867895  0.5748257 ]\n",
      "B :  [ 0.17568484  0.27337146  0.26973888  0.23276824  0.24977131]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 5  Complete with accuracy: 96.99%\n",
      "Epoch 5  Test Accuracy : 93.91%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.444345\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.28590107  0.45638177  0.45167601  0.78351671  0.5748257 ]\n",
      "B :  [ 0.1853881   0.27625951  0.27814925  0.23250394  0.25175628]\n",
      "    \n",
      "Loss at step 500: 0.323606\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.28976318  0.46429732  0.45742324  0.78290832  0.5748257 ]\n",
      "B :  [ 0.18744619  0.28338018  0.272845    0.23614576  0.25288352]\n",
      "    \n",
      "Loss at step 1000: 0.515061\n",
      "Minibatch accuracy: 97.2%\n",
      "W :  [ 0.28990844  0.47144642  0.46215019  0.78536981  0.5748257 ]\n",
      "B :  [ 0.184571    0.27975357  0.28111172  0.2336342   0.24980502]\n",
      "    \n",
      "Loss at step 1500: 0.431801\n",
      "Minibatch accuracy: 97.2%\n",
      "W :  [ 0.29218242  0.48203787  0.46785837  0.77877915  0.5748257 ]\n",
      "B :  [ 0.18388759  0.28696051  0.2877931   0.23403656  0.25036231]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 6  Complete with accuracy: 97.42%\n",
      "Epoch 6  Test Accuracy : 93.91%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.256238\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.29308346  0.48119214  0.47216335  0.77902687  0.5748257 ]\n",
      "B :  [ 0.1937301   0.29163656  0.2968201   0.23526411  0.24931745]\n",
      "    \n",
      "Loss at step 500: 0.428976\n",
      "Minibatch accuracy: 97.2%\n",
      "W :  [ 0.29438916  0.48346958  0.47013012  0.78567785  0.5748257 ]\n",
      "B :  [ 0.1936352   0.29904926  0.29049826  0.23679529  0.24883623]\n",
      "    \n",
      "Loss at step 1000: 0.315507\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.29308799  0.49358264  0.47447851  0.7813831   0.5748257 ]\n",
      "B :  [ 0.19157135  0.30600879  0.30153495  0.23810583  0.25236818]\n",
      "    \n",
      "Loss at step 1500: 0.307694\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.29605827  0.50134659  0.48036122  0.7733227   0.5748257 ]\n",
      "B :  [ 0.18828855  0.31081408  0.30771807  0.23650217  0.25980014]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 7  Complete with accuracy: 97.93%\n",
      "Epoch 7  Test Accuracy : 94.60%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.226971\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.29504201  0.49806258  0.48546717  0.7624473   0.5748257 ]\n",
      "B :  [ 0.2017024   0.31738371  0.31423447  0.23562083  0.25728437]\n",
      "    \n",
      "Loss at step 500: 0.228405\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.30054599  0.50642139  0.48420766  0.76967323  0.5748257 ]\n",
      "B :  [ 0.20077129  0.32196805  0.3050282   0.23846397  0.2573165 ]\n",
      "    \n",
      "Loss at step 1000: 0.273054\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.29663676  0.50975919  0.48545298  0.77787387  0.5748257 ]\n",
      "B :  [ 0.1991957   0.32564995  0.3127054   0.23718899  0.25834033]\n",
      "    \n",
      "Loss at step 1500: 0.170909\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.29788634  0.52140069  0.49661583  0.78887761  0.5748257 ]\n",
      "B :  [ 0.19391389  0.33274543  0.3185724   0.23846829  0.2591106 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 8  Complete with accuracy: 98.56%\n",
      "Epoch 8  Test Accuracy : 93.45%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.181250\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.29707456  0.5178175   0.5060572   0.77392185  0.56458396]\n",
      "B :  [ 0.20577249  0.33824369  0.33099803  0.23482062  0.2620081 ]\n",
      "    \n",
      "Loss at step 500: 0.247559\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.30422303  0.5182988   0.51382202  0.77608126  0.56884336]\n",
      "B :  [ 0.20559075  0.34344611  0.32486677  0.24235567  0.2578415 ]\n",
      "    \n",
      "Loss at step 1000: 0.289070\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.3008984   0.52574736  0.51023555  0.77493322  0.56912374]\n",
      "B :  [ 0.20641492  0.34951639  0.33294559  0.23600294  0.25852489]\n",
      "    \n",
      "Loss at step 1500: 0.206108\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.30045199  0.5298478   0.51884353  0.77324629  0.56797874]\n",
      "B :  [ 0.1958469   0.35253385  0.33344719  0.23712546  0.266597  ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 9  Complete with accuracy: 98.52%\n",
      "Epoch 9  Test Accuracy : 94.41%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.190342\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.30246097  0.54137892  0.51946992  0.75747305  0.5680427 ]\n",
      "B :  [ 0.20916565  0.3566286   0.344484    0.23992057  0.26608309]\n",
      "    \n",
      "Loss at step 500: 0.248481\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.3092024   0.54091191  0.52921438  0.76150453  0.57008415]\n",
      "B :  [ 0.20904091  0.36631635  0.33572817  0.24358802  0.26448894]\n",
      "    \n",
      "Loss at step 1000: 0.246264\n",
      "Minibatch accuracy: 98.3%\n",
      "W :  [ 0.30588064  0.55000556  0.53373885  0.77012634  0.57593274]\n",
      "B :  [ 0.20780456  0.37003222  0.34220988  0.23679712  0.26546156]\n",
      "    \n",
      "Loss at step 1500: 0.191019\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.30375439  0.54982638  0.54757053  0.77807415  0.57469785]\n",
      "B :  [ 0.20261797  0.37470672  0.34587038  0.23959637  0.26956621]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 10  Complete with accuracy: 98.40%\n",
      "Epoch 10  Test Accuracy : 95.02%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.123636\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.30706072  0.55722022  0.55395657  0.77619773  0.57687187]\n",
      "B :  [ 0.21664874  0.37588552  0.35608387  0.23966616  0.27210864]\n",
      "    \n",
      "Loss at step 500: 0.123849\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31094557  0.55406672  0.55117995  0.77210146  0.57544523]\n",
      "B :  [ 0.21901667  0.38253942  0.34689382  0.24232998  0.26903015]\n",
      "    \n",
      "Loss at step 1000: 0.188781\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.30892524  0.56093729  0.55353492  0.77085412  0.59403741]\n",
      "B :  [ 0.2183926   0.38671461  0.3550114   0.2404363   0.27409753]\n",
      "    \n",
      "Loss at step 1500: 0.082126\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.3062332   0.55047888  0.55624062  0.75740117  0.59188122]\n",
      "B :  [ 0.21290231  0.38902342  0.3645325   0.23950049  0.2759015 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 11  Complete with accuracy: 98.91%\n",
      "Epoch 11  Test Accuracy : 94.10%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.157184\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.30869821  0.55532277  0.55844671  0.7499662   0.59148037]\n",
      "B :  [ 0.2232879   0.39563814  0.37607107  0.23921521  0.28030819]\n",
      "    \n",
      "Loss at step 500: 0.196724\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.3119244   0.56835181  0.55395395  0.75493485  0.58448237]\n",
      "B :  [ 0.22300778  0.40448496  0.36727151  0.24617937  0.2723783 ]\n",
      "    \n",
      "Loss at step 1000: 0.181786\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.311297    0.55652469  0.55207324  0.75479871  0.59626067]\n",
      "B :  [ 0.21515571  0.40724611  0.37071374  0.24240477  0.27802348]\n",
      "    \n",
      "Loss at step 1500: 0.225640\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.30856574  0.5510937   0.57016498  0.75694788  0.61030233]\n",
      "B :  [ 0.21234435  0.4039481   0.37563521  0.24084826  0.28080657]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 12  Complete with accuracy: 98.59%\n",
      "Epoch 12  Test Accuracy : 95.10%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.117329\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.3094359   0.55778646  0.58960241  0.75613821  0.61198145]\n",
      "B :  [ 0.21762305  0.41022399  0.3870874   0.23931801  0.27647018]\n",
      "    \n",
      "Loss at step 500: 0.180425\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.3111164   0.54509902  0.59366161  0.75644487  0.60629159]\n",
      "B :  [ 0.22091961  0.41591319  0.37559801  0.24137996  0.2760556 ]\n",
      "    \n",
      "Loss at step 1000: 0.115976\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31381333  0.54585379  0.5920043   0.76619822  0.60391676]\n",
      "B :  [ 0.2193944   0.41669422  0.38773292  0.23943888  0.28354397]\n",
      "    \n",
      "Loss at step 1500: 0.128637\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.3123199   0.55495518  0.58684021  0.76557726  0.60801625]\n",
      "B :  [ 0.21313345  0.41427201  0.39302856  0.24257886  0.27970374]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 13  Complete with accuracy: 99.18%\n",
      "Epoch 13  Test Accuracy : 93.22%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.075994\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.3130925   0.5614928   0.59815663  0.76425666  0.60285395]\n",
      "B :  [ 0.22644372  0.42123133  0.40182406  0.24072284  0.28247812]\n",
      "    \n",
      "Loss at step 500: 0.075166\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31625944  0.55349696  0.59617436  0.77501225  0.61507916]\n",
      "B :  [ 0.22087443  0.42577848  0.38800091  0.23896722  0.27890709]\n",
      "    \n",
      "Loss at step 1000: 0.146098\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31625342  0.57032764  0.60604227  0.78270739  0.62273443]\n",
      "B :  [ 0.22441845  0.43157223  0.3971737   0.2424785   0.28504205]\n",
      "    \n",
      "Loss at step 1500: 0.102949\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.31489637  0.57351059  0.60644633  0.78389245  0.62945527]\n",
      "B :  [ 0.21839648  0.43372771  0.40730602  0.24135762  0.29293969]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 14  Complete with accuracy: 99.33%\n",
      "Epoch 14  Test Accuracy : 94.41%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.161324\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.3150548   0.58283883  0.62891346  0.78079098  0.62978327]\n",
      "B :  [ 0.23078601  0.43561861  0.41674197  0.24174216  0.29123577]\n",
      "    \n",
      "Loss at step 500: 0.155942\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.31890318  0.57327348  0.63104588  0.79829872  0.61953241]\n",
      "B :  [ 0.22725892  0.43673816  0.39748099  0.23992686  0.28797266]\n",
      "    \n",
      "Loss at step 1000: 0.111928\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31737655  0.58367467  0.63803393  0.79904836  0.61964226]\n",
      "B :  [ 0.22496983  0.43947974  0.40304407  0.24329606  0.28752902]\n",
      "    \n",
      "Loss at step 1500: 0.047318\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31439584  0.58781266  0.64520025  0.79876274  0.61395776]\n",
      "B :  [ 0.21458386  0.44650009  0.41225827  0.24188314  0.28564438]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 15  Complete with accuracy: 99.26%\n",
      "Epoch 15  Test Accuracy : 94.14%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.070022\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31524256  0.59033275  0.65074396  0.79259551  0.61489838]\n",
      "B :  [ 0.23046623  0.4483777   0.4242999   0.24340275  0.29233372]\n",
      "    \n",
      "Loss at step 500: 0.172366\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.32033029  0.58656949  0.64801913  0.79663962  0.61009419]\n",
      "B :  [ 0.22536235  0.4472788   0.41135228  0.24755917  0.29045561]\n",
      "    \n",
      "Loss at step 1000: 0.236927\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.31589997  0.58229482  0.66483247  0.78721744  0.62916225]\n",
      "B :  [ 0.22252952  0.45275536  0.41489843  0.24235491  0.29657799]\n",
      "    \n",
      "Loss at step 1500: 0.052630\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31628704  0.59104413  0.66053659  0.79808855  0.62684429]\n",
      "B :  [ 0.21799128  0.45443431  0.41294497  0.24098662  0.29333842]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 16  Complete with accuracy: 99.34%\n",
      "Epoch 16  Test Accuracy : 94.10%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.083467\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31747866  0.59918553  0.66269583  0.80103588  0.62338716]\n",
      "B :  [ 0.22918941  0.4620609   0.42269316  0.24195041  0.30043608]\n",
      "    \n",
      "Loss at step 500: 0.077771\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31999207  0.60665733  0.6534394   0.81313497  0.61760056]\n",
      "B :  [ 0.22808115  0.46933043  0.40623346  0.24804047  0.30119058]\n",
      "    \n",
      "Loss at step 1000: 0.051555\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.32005861  0.60912448  0.66518354  0.82012266  0.61875618]\n",
      "B :  [ 0.22357813  0.47415331  0.41162437  0.24753195  0.30105445]\n",
      "    \n",
      "Loss at step 1500: 0.021882\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.31690204  0.60201168  0.67822605  0.82689494  0.62407839]\n",
      "B :  [ 0.21791485  0.4697862   0.41620946  0.24401286  0.30282852]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 17  Complete with accuracy: 99.69%\n",
      "Epoch 17  Test Accuracy : 94.33%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.047238\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31718773  0.60605842  0.68690246  0.81981385  0.63811481]\n",
      "B :  [ 0.22737299  0.47187755  0.42636117  0.24226415  0.29901981]\n",
      "    \n",
      "Loss at step 500: 0.052421\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31852439  0.60465991  0.67445743  0.82750183  0.62662989]\n",
      "B :  [ 0.21820033  0.47912112  0.41826528  0.24417615  0.30250424]\n",
      "    \n",
      "Loss at step 1000: 0.159384\n",
      "Minibatch accuracy: 98.4%\n",
      "W :  [ 0.3243899   0.6125114   0.67814642  0.83728343  0.63489127]\n",
      "B :  [ 0.2228846   0.47723007  0.42296988  0.24865611  0.30177879]\n",
      "    \n",
      "Loss at step 1500: 0.070539\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31560129  0.61174935  0.69169855  0.8317163   0.6262334 ]\n",
      "B :  [ 0.21199478  0.47955626  0.42899907  0.24466252  0.29898572]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 18  Complete with accuracy: 99.14%\n",
      "Epoch 18  Test Accuracy : 93.98%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.044282\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31873915  0.6162703   0.69979632  0.83170223  0.63470501]\n",
      "B :  [ 0.22462742  0.48524848  0.44118583  0.24452323  0.30062488]\n",
      "    \n",
      "Loss at step 500: 0.073081\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.32297474  0.6062569   0.70064253  0.83378333  0.64100164]\n",
      "B :  [ 0.22518665  0.48583436  0.42687976  0.24715751  0.30200487]\n",
      "    \n",
      "Loss at step 1000: 0.122243\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.32498649  0.60401976  0.70313656  0.83900899  0.64983368]\n",
      "B :  [ 0.21657239  0.48964879  0.42429358  0.24741495  0.30089638]\n",
      "    \n",
      "Loss at step 1500: 0.077236\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31729022  0.60848033  0.71419072  0.84090263  0.65910572]\n",
      "B :  [ 0.21376787  0.48661077  0.43616101  0.24068396  0.3027626 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 19  Complete with accuracy: 99.38%\n",
      "Epoch 19  Test Accuracy : 94.18%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.029750\n",
      "Minibatch accuracy: 100.0%\n",
      "W :  [ 0.31803918  0.6095233   0.72755444  0.85821491  0.65841424]\n",
      "B :  [ 0.22556344  0.49202204  0.44453412  0.24256356  0.30487737]\n",
      "    \n",
      "Loss at step 500: 0.119472\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31936797  0.61678392  0.72084206  0.86440009  0.65725732]\n",
      "B :  [ 0.21934819  0.49228308  0.43232936  0.24157336  0.3008458 ]\n",
      "    \n",
      "Loss at step 1000: 0.065046\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.32085055  0.62218326  0.7352128   0.86413085  0.65639472]\n",
      "B :  [ 0.21986771  0.4972536   0.43710089  0.24326965  0.29081061]\n",
      "    \n",
      "Loss at step 1500: 0.038471\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31702387  0.61860794  0.73044419  0.87392306  0.6616801 ]\n",
      "B :  [ 0.21392027  0.49507996  0.439688    0.24233432  0.29942897]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 20  Complete with accuracy: 99.57%\n",
      "Epoch 20  Test Accuracy : 93.72%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.055887\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.32136151  0.61911213  0.72627139  0.85591972  0.66162801]\n",
      "B :  [ 0.2263006   0.50247574  0.44726056  0.24219204  0.29851815]\n",
      "    \n",
      "Loss at step 500: 0.196985\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.32370889  0.62232256  0.72603768  0.86343229  0.6735791 ]\n",
      "B :  [ 0.21862708  0.50384331  0.43792793  0.24502861  0.29784063]\n",
      "    \n",
      "Loss at step 1000: 0.059707\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.32636279  0.62981057  0.70864499  0.86040139  0.67282176]\n",
      "B :  [ 0.21932025  0.50260544  0.44150835  0.24876377  0.29579729]\n",
      "    \n",
      "Loss at step 1500: 0.083035\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.32488519  0.63851905  0.70972812  0.86446202  0.67405713]\n",
      "B :  [ 0.22031392  0.49849257  0.4474515   0.2441195   0.29364812]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 21  Complete with accuracy: 99.30%\n",
      "Epoch 21  Test Accuracy : 94.94%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.098033\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.32346669  0.63875347  0.70805162  0.86890697  0.66892052]\n",
      "B :  [ 0.22422436  0.50548238  0.44622293  0.24201488  0.30643156]\n",
      "    \n",
      "Loss at step 500: 0.114940\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.32261443  0.63516158  0.70348907  0.86191589  0.68052965]\n",
      "B :  [ 0.22134174  0.50745273  0.44386193  0.24256469  0.29993048]\n",
      "    \n",
      "Loss at step 1000: 0.060166\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.32323584  0.63031489  0.69942826  0.86761588  0.69129491]\n",
      "B :  [ 0.2182685   0.50735778  0.44692257  0.24319683  0.30032322]\n",
      "    \n",
      "Loss at step 1500: 0.100807\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31968588  0.63825053  0.7042923   0.8648454   0.68508464]\n",
      "B :  [ 0.21117078  0.50942034  0.4526372   0.24271423  0.30032942]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 22  Complete with accuracy: 99.30%\n",
      "Epoch 22  Test Accuracy : 93.95%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.081475\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.3211098   0.64087665  0.69991982  0.87483609  0.684228  ]\n",
      "B :  [ 0.22024368  0.51133353  0.45054358  0.24374224  0.31885615]\n",
      "    \n",
      "Loss at step 500: 0.023379\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.32234314  0.64591271  0.67970788  0.87798595  0.68980205]\n",
      "B :  [ 0.22379649  0.51430833  0.45023406  0.24543403  0.3175891 ]\n",
      "    \n",
      "Loss at step 1000: 0.047191\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.3211557   0.64678651  0.68773025  0.88406688  0.67483866]\n",
      "B :  [ 0.2214231   0.51747245  0.46069825  0.2461248   0.31921166]\n",
      "    \n",
      "Loss at step 1500: 0.031353\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.31801245  0.64828217  0.69607055  0.88326597  0.67280883]\n",
      "B :  [ 0.21252218  0.51958209  0.4570666   0.24664055  0.31231359]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 23  Complete with accuracy: 99.72%\n",
      "Epoch 23  Test Accuracy : 93.64%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.150769\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31713116  0.6592384   0.70464545  0.88113046  0.67588848]\n",
      "B :  [ 0.21851346  0.52060598  0.45807248  0.24571572  0.32583857]\n",
      "    \n",
      "Loss at step 500: 0.024911\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.31909716  0.64946628  0.71726167  0.89264524  0.70544559]\n",
      "B :  [ 0.2169632   0.52540243  0.46228284  0.24446049  0.32096693]\n",
      "    \n",
      "Loss at step 1000: 0.064938\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31879383  0.67216456  0.71489871  0.89971524  0.7030651 ]\n",
      "B :  [ 0.21069287  0.52352989  0.46003214  0.24355045  0.31884477]\n",
      "    \n",
      "Loss at step 1500: 0.129318\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31821641  0.6771819   0.72649503  0.90137053  0.70932466]\n",
      "B :  [ 0.20987664  0.52240419  0.46511453  0.24251659  0.3226254 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 24  Complete with accuracy: 99.49%\n",
      "Epoch 24  Test Accuracy : 94.44%\n",
      "------------------------------------\n",
      "        \n",
      "Training Complete on MNIST Data\n",
      "Test Accuracy :  93.92560664112388\n",
      "Model saved in file: saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset\n",
    "label_data = train_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "box_train_dict = {}\n",
    "batch_size = 128\n",
    "num_steps = int(label_data.shape[0] / batch_size)\n",
    "num_epochs = 25\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    # tf.global_variables_initializer().run()\n",
    "    model_saver.restore(session, saved_mnist_model)\n",
    "    print('Initialized')\n",
    "\n",
    "    test_batch = int(test_dataset.shape[0]/num_epochs)\n",
    "    test_acc = list()\n",
    "    \n",
    "    for epoch in range(num_epochs - 1):\n",
    "        res_epoch = {}\n",
    "        t_data = test_dataset[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        t_label = test_labels[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        \n",
    "        for step in range(num_steps - 1):\n",
    "            max_learning_rate = 0.0005\n",
    "            min_learning_rate = 0.0001\n",
    "\n",
    "            decay_speed = 5000.0\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "\n",
    "            batch_data = train_data[step*batch_size:(step + 1)*batch_size, :, :, :]\n",
    "            batch_labels = label_data[step*batch_size:(step + 1)*batch_size, :]\n",
    "\n",
    "            feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "            _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "            accuracy = float(acc(train_pred, batch_labels[:,1:6]))\n",
    "\n",
    "            if (step % 500 == 0):\n",
    "                minibatch = {}\n",
    "                minibatch['loss'] = l\n",
    "                minibatch['W'] = W\n",
    "                minibatch['B'] = b\n",
    "                minibatch['accuracy'] = \"%.2f\" % accuracy\n",
    "\n",
    "                res_epoch[int(step/500)] = minibatch\n",
    "                print('Loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "                print('W : ',W)\n",
    "                print('B : ',b)\n",
    "                print('    ')\n",
    "                \n",
    "        box_train_dict[epoch+1] = res_epoch\n",
    "\n",
    "        epoch_acc = 0\n",
    "        for f in res_epoch:\n",
    "            minibatch = res_epoch[f]\n",
    "            epoch_acc += float(minibatch['accuracy'])\n",
    "        epoch_acc = float(epoch_acc/len(res_epoch))\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : t_data, Y_ : t_label, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = float(acc(predictions, t_label[:,1:6]))\n",
    "        test_acc.append(accuracy)\n",
    "\n",
    "        print('------------------------------------')\n",
    "        print('Epoch',epoch+1,' Complete with accuracy: %.2f%%' % epoch_acc)\n",
    "        print('Epoch',epoch+1,' Test Accuracy : %.2f%%' % accuracy)\n",
    "        print('------------------------------------')\n",
    "        print('        ')\n",
    "            \n",
    "    print('Training Complete on MNIST Data')\n",
    "    print('Test Accuracy : ', mean(test_acc))\n",
    "    \n",
    "    save_path = model_saver.save(session, model_to_save)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'results/Box_on_Mnist.pickle'\n",
    "\n",
    "with open(file, 'wb') as handle:\n",
    "    pickle.dump(box_train_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Valid-Accuracy 0\n",
      "Valid accuracy:  94.62\n",
      "        \n",
      "Valid-Accuracy 1\n",
      "Valid accuracy:  94.72\n",
      "        \n",
      "Valid-Accuracy 2\n",
      "Valid accuracy:  93.46\n",
      "        \n",
      "Valid-Accuracy 3\n",
      "Valid accuracy:  93.22\n",
      "        \n",
      "-----  FINAL  ------\n",
      "Final Validation Set Accuracy :  94.00\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    batch = 1000\n",
    "    \n",
    "    valid_acc = list()\n",
    "    valid_no = int(valid_labels.shape[0] /  batch)\n",
    "    for i in range(valid_no - 1):\n",
    "        model_saver.restore(session, model_to_save)\n",
    "        data = valid_dataset[i*batch:(i+1)*batch]\n",
    "        labels = valid_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        valid_acc.append(accuracy)\n",
    "        \n",
    "        print('Valid-Accuracy', i)\n",
    "        print('Valid accuracy: ', accuracy)\n",
    "        print('        ')\n",
    "            \n",
    "    valid_avg = mean(valid_acc)\n",
    "    \n",
    "    print('-----  FINAL  ------')\n",
    "    print('Final Validation Set Accuracy : ',\"%.2f\" % valid_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
