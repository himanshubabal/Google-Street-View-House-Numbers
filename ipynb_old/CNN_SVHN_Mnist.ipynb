{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.mlab as mlab\n",
    "import pylab as pl\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize_dataset(images, labels):\n",
    "    shuffle = list(zip(images, labels))\n",
    "    np.random.shuffle(shuffle)\n",
    "    i, l = zip(*shuffle)\n",
    "    i, l = np.asarray(i), np.asarray(l)\n",
    "    return i, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (98114, 32, 96, 1) (98114, 6)\n",
      "Test set (14931, 32, 96, 1) (14931, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/MNIST_multi.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "train_dataset = hdf['train_images'][:]\n",
    "train_labels = hdf['train_labels'][:]\n",
    "test_dataset = hdf['test_images'][:]\n",
    "test_labels = hdf['test_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "    \n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img(im, label):\n",
    "    if len(im.shape) >= 3:\n",
    "        im = im[:,:,0]\n",
    "    plt.imshow(im)\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "    \n",
    "def plot(i):\n",
    "    plot_img(train_dataset[i], train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACeCAYAAAAiy/EDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CIiEfF/3EDiOP6OFCYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b92bf748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACeCAYAAAAiy/EDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJuZ5YQDuplZTvw/SXDdneB+E6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff64cda39e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_label_dict = {}\n",
    "for i in range(train_labels.shape[0]):\n",
    "    l = train_labels[i][0]\n",
    "    if not l in train_label_dict:\n",
    "        train_label_dict[l] = 0\n",
    "    train_label_dict[l] = train_label_dict[l] + 1\n",
    "    \n",
    "test_label_dict = {}\n",
    "for i in range(test_labels.shape[0]):\n",
    "    l = test_labels[i][0]\n",
    "    if not l in test_label_dict:\n",
    "        test_label_dict[l] = 0\n",
    "    test_label_dict[l] = test_label_dict[l] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hist_dict(dict) :\n",
    "    dict = OrderedDict(sorted(dict.items()))\n",
    "    X = np.arange(len(dict))\n",
    "    pl.bar(X, dict.values(), align='center', width=0.5)\n",
    "    pl.xticks(X, dict.keys())\n",
    "    ymax = max(dict.values()) + 500\n",
    "    pl.ylim(0, ymax)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1CkDQJI6ZQBIUqcMAEnqlAEgSZ36f9GF8Dht1b9NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff64cdacb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_dict(test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff64cc9cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_dict(train_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.astype(np.float32)\n",
    "test_dataset = test_dataset.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset, train_labels = randomize_dataset(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize_dataset(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_save = \"saved_models/mnist/CNN_SVHN_Mnist.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 6 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 12     # First Conv Layer with depth 12\n",
    "    L = 24     # Second Conv Layer with depth 24\n",
    "    M = 36    # Third Conv layer with depth 36\n",
    "    N = 300   # Fourth Fully Connected layer with 300 neurons\n",
    "    P = 200   # Fifth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "    \n",
    "    W5 = tf.Variable(tf.truncated_normal([N, P], stddev=0.1), name=\"W5\")\n",
    "    B5 = tf.Variable(tf.constant(0.1, tf.float32, [P]), name=\"B5\")\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    Y5 = tf.nn.relu(tf.matmul(Y4, W5) + B5)\n",
    "    \n",
    "    Y_F = tf.nn.dropout(Y5, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(Y_F, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(Y_F, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(Y_F, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(Y_F, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(Y_F, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3))\\\n",
    "                   ,tf.reduce_max(tf.abs(W4)),tf.reduce_max(tf.abs(W5))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3))\\\n",
    "                   ,tf.reduce_max(tf.abs(B4)),tf.reduce_max(tf.abs(B5))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (98042, 32, 96, 1)   test :  (98042, 6)\n",
      "Initialized\n",
      "Loss at step 0: 1923.939819\n",
      "Minibatch accuracy: 7.0%\n",
      "    \n",
      "Loss at step 150: 9.594503\n",
      "Minibatch accuracy: 43.4%\n",
      "    \n",
      "Loss at step 300: 8.244182\n",
      "Minibatch accuracy: 51.1%\n",
      "    \n",
      "Loss at step 450: 6.072322\n",
      "Minibatch accuracy: 60.2%\n",
      "    \n",
      "Loss at step 600: 6.165967\n",
      "Minibatch accuracy: 60.0%\n",
      "    \n",
      "Loss at step 750: 5.821836\n",
      "Minibatch accuracy: 62.2%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 1  Complete with accuracy: 47.32%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 5.335229\n",
      "Minibatch accuracy: 63.4%\n",
      "    \n",
      "Loss at step 150: 5.314872\n",
      "Minibatch accuracy: 65.2%\n",
      "    \n",
      "Loss at step 300: 5.026712\n",
      "Minibatch accuracy: 64.5%\n",
      "    \n",
      "Loss at step 450: 3.661226\n",
      "Minibatch accuracy: 75.0%\n",
      "    \n",
      "Loss at step 600: 4.053632\n",
      "Minibatch accuracy: 72.7%\n",
      "    \n",
      "Loss at step 750: 3.552626\n",
      "Minibatch accuracy: 74.1%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 2  Complete with accuracy: 69.14%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 3.153763\n",
      "Minibatch accuracy: 79.5%\n",
      "    \n",
      "Loss at step 150: 3.177725\n",
      "Minibatch accuracy: 78.3%\n",
      "    \n",
      "Loss at step 300: 3.009769\n",
      "Minibatch accuracy: 81.6%\n",
      "    \n",
      "Loss at step 450: 2.304291\n",
      "Minibatch accuracy: 86.1%\n",
      "    \n",
      "Loss at step 600: 2.377122\n",
      "Minibatch accuracy: 83.8%\n",
      "    \n",
      "Loss at step 750: 2.202465\n",
      "Minibatch accuracy: 86.7%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 3  Complete with accuracy: 82.66%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 2.014727\n",
      "Minibatch accuracy: 87.3%\n",
      "    \n",
      "Loss at step 150: 1.964466\n",
      "Minibatch accuracy: 86.6%\n",
      "    \n",
      "Loss at step 300: 1.913387\n",
      "Minibatch accuracy: 87.0%\n",
      "    \n",
      "Loss at step 450: 1.624046\n",
      "Minibatch accuracy: 90.2%\n",
      "    \n",
      "Loss at step 600: 1.685035\n",
      "Minibatch accuracy: 88.4%\n",
      "    \n",
      "Loss at step 750: 1.406531\n",
      "Minibatch accuracy: 90.3%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 4  Complete with accuracy: 88.31%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.509292\n",
      "Minibatch accuracy: 90.5%\n",
      "    \n",
      "Loss at step 150: 1.193572\n",
      "Minibatch accuracy: 91.2%\n",
      "    \n",
      "Loss at step 300: 1.533129\n",
      "Minibatch accuracy: 91.7%\n",
      "    \n",
      "Loss at step 450: 1.094789\n",
      "Minibatch accuracy: 92.3%\n",
      "    \n",
      "Loss at step 600: 1.203631\n",
      "Minibatch accuracy: 93.1%\n",
      "    \n",
      "Loss at step 750: 0.999136\n",
      "Minibatch accuracy: 93.4%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 5  Complete with accuracy: 92.06%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.097954\n",
      "Minibatch accuracy: 93.4%\n",
      "    \n",
      "Loss at step 150: 0.969084\n",
      "Minibatch accuracy: 94.7%\n",
      "    \n",
      "Loss at step 300: 1.252176\n",
      "Minibatch accuracy: 93.6%\n",
      "    \n",
      "Loss at step 450: 0.891959\n",
      "Minibatch accuracy: 94.7%\n",
      "    \n",
      "Loss at step 600: 0.971617\n",
      "Minibatch accuracy: 93.3%\n",
      "    \n",
      "Loss at step 750: 0.735023\n",
      "Minibatch accuracy: 95.6%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 6  Complete with accuracy: 94.22%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.746143\n",
      "Minibatch accuracy: 95.3%\n",
      "    \n",
      "Loss at step 150: 0.753312\n",
      "Minibatch accuracy: 95.6%\n",
      "    \n",
      "Loss at step 300: 0.790198\n",
      "Minibatch accuracy: 95.3%\n",
      "    \n",
      "Loss at step 450: 0.764428\n",
      "Minibatch accuracy: 94.7%\n",
      "    \n",
      "Loss at step 600: 0.689865\n",
      "Minibatch accuracy: 95.5%\n",
      "    \n",
      "Loss at step 750: 0.743342\n",
      "Minibatch accuracy: 94.7%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 7  Complete with accuracy: 95.18%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.631855\n",
      "Minibatch accuracy: 96.1%\n",
      "    \n",
      "Loss at step 150: 0.522199\n",
      "Minibatch accuracy: 96.9%\n",
      "    \n",
      "Loss at step 300: 0.630651\n",
      "Minibatch accuracy: 96.1%\n",
      "    \n",
      "Loss at step 450: 0.541479\n",
      "Minibatch accuracy: 95.3%\n",
      "    \n",
      "Loss at step 600: 0.624133\n",
      "Minibatch accuracy: 95.8%\n",
      "    \n",
      "Loss at step 750: 0.560553\n",
      "Minibatch accuracy: 96.6%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 8  Complete with accuracy: 96.12%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.469950\n",
      "Minibatch accuracy: 96.7%\n",
      "    \n",
      "Loss at step 150: 0.699157\n",
      "Minibatch accuracy: 95.9%\n",
      "    \n",
      "Loss at step 300: 0.574109\n",
      "Minibatch accuracy: 95.9%\n",
      "    \n",
      "Loss at step 450: 0.437390\n",
      "Minibatch accuracy: 97.2%\n",
      "    \n",
      "Loss at step 600: 0.463820\n",
      "Minibatch accuracy: 97.2%\n",
      "    \n",
      "Loss at step 750: 0.473458\n",
      "Minibatch accuracy: 97.5%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 9  Complete with accuracy: 96.75%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.396023\n",
      "Minibatch accuracy: 98.0%\n",
      "    \n",
      "Loss at step 150: 0.397203\n",
      "Minibatch accuracy: 96.6%\n",
      "    \n",
      "Loss at step 300: 0.509246\n",
      "Minibatch accuracy: 97.0%\n",
      "    \n",
      "Loss at step 450: 0.313468\n",
      "Minibatch accuracy: 98.0%\n",
      "    \n",
      "Loss at step 600: 0.476583\n",
      "Minibatch accuracy: 96.7%\n",
      "    \n",
      "Loss at step 750: 0.410326\n",
      "Minibatch accuracy: 97.3%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 10  Complete with accuracy: 97.27%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.231534\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "Loss at step 150: 0.293057\n",
      "Minibatch accuracy: 97.7%\n",
      "    \n",
      "Loss at step 300: 0.367487\n",
      "Minibatch accuracy: 98.0%\n",
      "    \n",
      "Loss at step 450: 0.316489\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "Loss at step 600: 0.315703\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "Loss at step 750: 0.367670\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 11  Complete with accuracy: 98.12%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.237229\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 150: 0.254988\n",
      "Minibatch accuracy: 98.0%\n",
      "    \n",
      "Loss at step 300: 0.417836\n",
      "Minibatch accuracy: 97.0%\n",
      "    \n",
      "Loss at step 450: 0.303546\n",
      "Minibatch accuracy: 98.3%\n",
      "    \n",
      "Loss at step 600: 0.308815\n",
      "Minibatch accuracy: 97.8%\n",
      "    \n",
      "Loss at step 750: 0.281266\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 12  Complete with accuracy: 98.02%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.212886\n",
      "Minibatch accuracy: 98.3%\n",
      "    \n",
      "Loss at step 150: 0.264149\n",
      "Minibatch accuracy: 97.5%\n",
      "    \n",
      "Loss at step 300: 0.421029\n",
      "Minibatch accuracy: 97.2%\n",
      "    \n",
      "Loss at step 450: 0.191173\n",
      "Minibatch accuracy: 98.6%\n",
      "    \n",
      "Loss at step 600: 0.239804\n",
      "Minibatch accuracy: 98.3%\n",
      "    \n",
      "Loss at step 750: 0.274027\n",
      "Minibatch accuracy: 98.4%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 13  Complete with accuracy: 98.05%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.237596\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "Loss at step 150: 0.193045\n",
      "Minibatch accuracy: 98.6%\n",
      "    \n",
      "Loss at step 300: 0.204877\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "Loss at step 450: 0.205149\n",
      "Minibatch accuracy: 98.6%\n",
      "    \n",
      "Loss at step 600: 0.297555\n",
      "Minibatch accuracy: 97.8%\n",
      "    \n",
      "Loss at step 750: 0.216913\n",
      "Minibatch accuracy: 98.4%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 14  Complete with accuracy: 98.38%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.102992\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 150: 0.235287\n",
      "Minibatch accuracy: 98.0%\n",
      "    \n",
      "Loss at step 300: 0.254109\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "Loss at step 450: 0.123036\n",
      "Minibatch accuracy: 99.1%\n",
      "    \n",
      "Loss at step 600: 0.256086\n",
      "Minibatch accuracy: 98.1%\n",
      "    \n",
      "Loss at step 750: 0.188737\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 15  Complete with accuracy: 98.57%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.165331\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 150: 0.176922\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 300: 0.170971\n",
      "Minibatch accuracy: 99.1%\n",
      "    \n",
      "Loss at step 450: 0.092973\n",
      "Minibatch accuracy: 99.8%\n",
      "    \n",
      "Loss at step 600: 0.175645\n",
      "Minibatch accuracy: 98.3%\n",
      "    \n",
      "Loss at step 750: 0.141721\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 16  Complete with accuracy: 99.04%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.097321\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "Loss at step 150: 0.095807\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 300: 0.222013\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "Loss at step 450: 0.182728\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 600: 0.114367\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "Loss at step 750: 0.289235\n",
      "Minibatch accuracy: 98.3%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 17  Complete with accuracy: 99.01%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.055513\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 150: 0.152931\n",
      "Minibatch accuracy: 99.1%\n",
      "    \n",
      "Loss at step 300: 0.152693\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "Loss at step 450: 0.194462\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "Loss at step 600: 0.097797\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "Loss at step 750: 0.270018\n",
      "Minibatch accuracy: 98.3%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 18  Complete with accuracy: 98.96%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.135961\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "Loss at step 150: 0.094191\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 300: 0.166256\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "Loss at step 450: 0.118610\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 600: 0.109015\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 750: 0.182101\n",
      "Minibatch accuracy: 98.6%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 19  Complete with accuracy: 98.96%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.096219\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "Loss at step 150: 0.085731\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 300: 0.100104\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 450: 0.091803\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 600: 0.110873\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 750: 0.076164\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 20  Complete with accuracy: 99.43%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.091469\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 150: 0.105021\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 300: 0.029805\n",
      "Minibatch accuracy: 99.8%\n",
      "    \n",
      "Loss at step 450: 0.031322\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 600: 0.149765\n",
      "Minibatch accuracy: 98.6%\n",
      "    \n",
      "Loss at step 750: 0.063590\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 21  Complete with accuracy: 99.35%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.090939\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 150: 0.097589\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 300: 0.058229\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 450: 0.037206\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 600: 0.186817\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 750: 0.035332\n",
      "Minibatch accuracy: 99.8%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 22  Complete with accuracy: 99.53%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.085858\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 150: 0.092228\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 300: 0.102816\n",
      "Minibatch accuracy: 99.2%\n",
      "    \n",
      "Loss at step 450: 0.083809\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 600: 0.063332\n",
      "Minibatch accuracy: 99.8%\n",
      "    \n",
      "Loss at step 750: 0.192228\n",
      "Minibatch accuracy: 98.8%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 23  Complete with accuracy: 99.30%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.128934\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 150: 0.064241\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 300: 0.146073\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 450: 0.082065\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 600: 0.096387\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 750: 0.049091\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 24  Complete with accuracy: 99.45%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.050761\n",
      "Minibatch accuracy: 99.8%\n",
      "    \n",
      "Loss at step 150: 0.065236\n",
      "Minibatch accuracy: 99.7%\n",
      "    \n",
      "Loss at step 300: 0.043183\n",
      "Minibatch accuracy: 99.5%\n",
      "    \n",
      "Loss at step 450: 0.068319\n",
      "Minibatch accuracy: 99.4%\n",
      "    \n",
      "Loss at step 600: 0.148297\n",
      "Minibatch accuracy: 98.9%\n",
      "    \n",
      "Loss at step 750: 0.025068\n",
      "Minibatch accuracy: 99.8%\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 25  Complete with accuracy: 99.53%\n",
      "------------------------------------\n",
      "        \n",
      "Training Complete on MNIST Data\n",
      "Model saved in file: saved_models/mnist/CNN_SVHN_Mnist.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset\n",
    "label_data = train_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "mnist_train_dict = {}\n",
    "num_steps = int(label_data.shape[0] / batch_size)\n",
    "num_epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "      \n",
    "    for epoch in range(num_epochs):\n",
    "        res_epoch = {}\n",
    "        for step in range(num_steps - 1):\n",
    "            max_learning_rate = 0.0005\n",
    "            min_learning_rate = 0.0001\n",
    "\n",
    "            decay_speed = 5000.0\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "\n",
    "            batch_data = train_data[step*batch_size:(step + 1)*batch_size, :, :, :]\n",
    "            batch_labels = label_data[step*batch_size:(step + 1)*batch_size, :]\n",
    "\n",
    "            feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "            _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "            accuracy = float(acc(train_pred, batch_labels[:,1:6]))\n",
    "\n",
    "            if (step % 150 == 0):\n",
    "                minibatch = {}\n",
    "                minibatch['loss'] = l\n",
    "                minibatch['W'] = W\n",
    "                minibatch['B'] = b\n",
    "                minibatch['accuracy'] = \"%.2f\" % accuracy\n",
    "\n",
    "                res_epoch[int(step/150)] = minibatch\n",
    "                print('Loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "                print('    ')\n",
    "                \n",
    "        mnist_train_dict[epoch+1] = res_epoch\n",
    "\n",
    "        epoch_acc = 0\n",
    "        for f in res_epoch:\n",
    "            minibatch = res_epoch[f]\n",
    "            epoch_acc += float(minibatch['accuracy'])\n",
    "        epoch_acc = float(epoch_acc/len(res_epoch))\n",
    "\n",
    "        print('------------------------------------')\n",
    "        print('Epoch',epoch+1,' Complete with accuracy: %.2f%%' % epoch_acc)\n",
    "        print('------------------------------------')\n",
    "        print('        ')\n",
    "            \n",
    "    print('Training Complete on MNIST Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, model_to_save)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'results/MNIST.pickle'\n",
    "\n",
    "with open(file, 'wb') as handle:\n",
    "    pickle.dump(mnist_train_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "       \n",
      "Final Test Set Accuracy :  98.53\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    batch = 500\n",
    "    \n",
    "    test_acc = list()\n",
    "    test_no = int(test_labels.shape[0] / batch)\n",
    "    for i in range(test_no - 1):\n",
    "        model_saver.restore(session, model_to_save)\n",
    "        data = test_dataset[i*batch:(i+1)*batch]\n",
    "        labels = test_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        test_acc.append(accuracy)\n",
    "        \n",
    "    test_avg = mean(test_acc)\n",
    "    \n",
    "    print('       ')\n",
    "    print('Final Test Set Accuracy : ',\"%.2f\" % test_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
