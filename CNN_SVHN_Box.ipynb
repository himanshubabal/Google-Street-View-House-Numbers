{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import h5py\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230069, 32, 96, 1) (230069, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5684, 32, 96, 1) (5684, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/box/SVHN_multi_box.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "svhn_train_box_dataset = hdf['train_images'][:]\n",
    "svhn_train_box_labels = hdf['train_labels'][:]\n",
    "svhn_test_box_dataset = hdf['test_images'][:]\n",
    "svhn_test_box_labels = hdf['test_labels'][:]\n",
    "svhn_valid_box_dataset = hdf['valid_images'][:]\n",
    "svhn_valid_box_labels = hdf['valid_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "\n",
    "print(svhn_train_box_dataset.shape, svhn_train_box_labels.shape)\n",
    "print(svhn_test_box_dataset.shape, svhn_test_box_labels.shape)\n",
    "print(svhn_valid_box_dataset.shape, svhn_valid_box_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svhn_train_box_dataset = svhn_train_box_dataset.astype(np.float32)\n",
    "svhn_test_box_dataset = svhn_test_box_dataset.astype(np.float32)\n",
    "svhn_valid_box_dataset = svhn_valid_box_dataset.astype(np.float32)\n",
    "\n",
    "svhn_train_box_labels = svhn_train_box_labels.astype(np.int32)\n",
    "svhn_test_box_labels = svhn_test_box_labels.astype(np.int32)\n",
    "svhn_valid_box_labels = svhn_valid_box_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230255, 32, 96, 1) (230255, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5500, 32, 96, 1) (5500, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "svhn_test_dataset = hdf['test_images'][:]\n",
    "svhn_test_labels = hdf['test_labels'][:]\n",
    "svhn_train_dataset = hdf['train_images'][:]\n",
    "svhn_train_labels = hdf['train_labels'][:]\n",
    "svhn_valid_dataset = hdf['valid_images'][:]\n",
    "svhn_valid_labels = hdf['valid_labels'][:]\n",
    "\n",
    "hdf.close()    \n",
    "\n",
    "print(svhn_train_dataset.shape, svhn_train_labels.shape)\n",
    "print(svhn_test_dataset.shape, svhn_test_labels.shape)\n",
    "print(svhn_valid_dataset.shape, svhn_valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type        Data/Info\n",
      "------------------------------------------\n",
      "Image                module      <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "gc                   module      <module 'gc' (built-in)>\n",
      "h5py                 module      <module 'h5py' from '/hom<...>ckages/h5py/__init__.py'>\n",
      "hdf                  File        <Closed HDF5 file>\n",
      "hdf_file             str         datasets/pickles/SVHN_multi.hdf5\n",
      "imshow               function    <function imshow at 0x7fb69e53f730>\n",
      "math                 module      <module 'math' from '/hom<...>35m-x86_64-linux-gnu.so'>\n",
      "np                   module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "pickle               module      <module 'pickle' from '/h<...>lib/python3.5/pickle.py'>\n",
      "plt                  module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "random               module      <module 'random' from '/h<...>lib/python3.5/random.py'>\n",
      "svhn_test_dataset    ndarray     13068x32x96x1: 40144896 elems, type `int32`, 160579584 bytes (153.140625 Mb)\n",
      "svhn_test_labels     ndarray     13068x6: 78408 elems, type `int32`, 313632 bytes (306.28125 kb)\n",
      "svhn_train_dataset   ndarray     230255x32x96x1: 707343360 elems, type `int32`, 2829373440 bytes (2698.30078125 Mb)\n",
      "svhn_train_labels    ndarray     230255x6: 1381530 elems, type `int32`, 5526120 bytes (5.270118713378906 Mb)\n",
      "svhn_valid_dataset   ndarray     5500x32x96x1: 16896000 elems, type `int32`, 67584000 bytes (64.453125 Mb)\n",
      "svhn_valid_labels    ndarray     5500x6: 33000 elems, type `int32`, 132000 bytes (128.90625 kb)\n",
      "sys                  module      <module 'sys' (built-in)>\n",
      "tf                   module      <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del svhn_test_box_dataset, svhn_test_box_labels, svhn_train_box_dataset, svhn_train_box_labels, svhn_valid_box_dataset, svhn_valid_box_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type         Data/Info\n",
      "-------------------------------------------\n",
      "B1                   Variable     Tensor(\"Variable_1/read:0<...>hape=(6,), dtype=float32)\n",
      "B2                   Variable     Tensor(\"Variable_3/read:0<...>ape=(12,), dtype=float32)\n",
      "B3                   Variable     Tensor(\"Variable_5/read:0<...>ape=(24,), dtype=float32)\n",
      "B4                   Variable     Tensor(\"Variable_17/read:<...>pe=(200,), dtype=float32)\n",
      "B5_1                 Variable     Tensor(\"Variable_7/read:0<...>ape=(11,), dtype=float32)\n",
      "B5_2                 Variable     Tensor(\"Variable_9/read:0<...>ape=(11,), dtype=float32)\n",
      "B5_3                 Variable     Tensor(\"Variable_11/read:<...>ape=(11,), dtype=float32)\n",
      "B5_4                 Variable     Tensor(\"Variable_13/read:<...>ape=(11,), dtype=float32)\n",
      "B5_5                 Variable     Tensor(\"Variable_15/read:<...>ape=(11,), dtype=float32)\n",
      "HEIGHT               int          32\n",
      "Image                module       <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "K                    int          6\n",
      "L                    int          12\n",
      "M                    int          24\n",
      "N                    int          200\n",
      "W                    ndarray      4: 4 elems, type `float32`, 16 bytes\n",
      "W1                   Variable     Tensor(\"Variable/read:0\",<...> 6, 1, 6), dtype=float32)\n",
      "W2                   Variable     Tensor(\"Variable_2/read:0<...>5, 6, 12), dtype=float32)\n",
      "W3                   Variable     Tensor(\"Variable_4/read:0<...>, 12, 24), dtype=float32)\n",
      "W4                   Variable     Tensor(\"Variable_16/read:<...>608, 200), dtype=float32)\n",
      "W5_1                 Variable     Tensor(\"Variable_6/read:0<...>(200, 11), dtype=float32)\n",
      "W5_2                 Variable     Tensor(\"Variable_8/read:0<...>(200, 11), dtype=float32)\n",
      "W5_3                 Variable     Tensor(\"Variable_10/read:<...>(200, 11), dtype=float32)\n",
      "W5_4                 Variable     Tensor(\"Variable_12/read:<...>(200, 11), dtype=float32)\n",
      "W5_5                 Variable     Tensor(\"Variable_14/read:<...>(200, 11), dtype=float32)\n",
      "WIDTH                int          96\n",
      "W_s                  Tensor       Tensor(\"pack_1:0\", shape=(4,), dtype=float32)\n",
      "X                    Tensor       Tensor(\"Placeholder:0\", s<...>2, 96, 1), dtype=float32)\n",
      "Y1                   Tensor       Tensor(\"Relu:0\", shape=(?<...>2, 96, 6), dtype=float32)\n",
      "Y2                   Tensor       Tensor(\"Relu_1:0\", shape=<...>, 48, 12), dtype=float32)\n",
      "Y3                   Tensor       Tensor(\"Relu_2:0\", shape=<...>, 24, 24), dtype=float32)\n",
      "Y4                   Tensor       Tensor(\"Sigmoid:0\", shape<...>=(?, 200), dtype=float32)\n",
      "YY                   Tensor       Tensor(\"Reshape:0\", shape<...>(?, 4608), dtype=float32)\n",
      "YY4                  Tensor       Tensor(\"dropout/mul:0\", s<...>=(?, 200), dtype=float32)\n",
      "Y_                   Tensor       Tensor(\"Placeholder_1:0\",<...>hape=(?, 6), dtype=int32)\n",
      "Y_1                  Tensor       Tensor(\"Softmax:0\", shape=(?, 11), dtype=float32)\n",
      "Y_2                  Tensor       Tensor(\"Softmax_1:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Y_3                  Tensor       Tensor(\"Softmax_2:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Y_4                  Tensor       Tensor(\"Softmax_3:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Y_5                  Tensor       Tensor(\"Softmax_4:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Ylogits_1            Tensor       Tensor(\"add_4:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_2            Tensor       Tensor(\"add_5:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_3            Tensor       Tensor(\"add_6:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_4            Tensor       Tensor(\"add_7:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_5            Tensor       Tensor(\"add_8:0\", shape=(?, 11), dtype=float32)\n",
      "acc                  function     <function acc at 0x7f59148061e0>\n",
      "accuracy             float64      92.42\n",
      "alpha                Tensor       Tensor(\"Placeholder_2:0\", dtype=float32)\n",
      "b                    ndarray      4: 4 elems, type `float32`, 16 bytes\n",
      "b_s                  Tensor       Tensor(\"pack_2:0\", shape=(4,), dtype=float32)\n",
      "batch                int          1000\n",
      "batch_data           ndarray      128x32x96x1: 393216 elems, type `float32`, 1572864 bytes (1.5 Mb)\n",
      "batch_labels         ndarray      128x6: 768 elems, type `int32`, 3072 bytes\n",
      "batch_size           int          128\n",
      "cross_entropy        Tensor       Tensor(\"add_12:0\", shape=(), dtype=float32)\n",
      "data                 ndarray      1000x32x96x1: 3072000 elems, type `float32`, 12288000 bytes (11.71875 Mb)\n",
      "decay_speed          float        5000.0\n",
      "feed_dict            dict         n=4\n",
      "gc                   module       <module 'gc' (built-in)>\n",
      "graph_svhn           Graph        <tensorflow.python.framew<...>object at 0x7f59148390b8>\n",
      "h5py                 module       <module 'h5py' from '/hom<...>ckages/h5py/__init__.py'>\n",
      "hdf                  File         <Closed HDF5 file>\n",
      "hdf_file             str          datasets/pickles/SVHN_multi.hdf5\n",
      "i                    int          3\n",
      "imshow               function     <function imshow at 0x7f591c140730>\n",
      "l                    float32      1.3328\n",
      "label_data           ndarray      230069x6: 1380414 elems, type `int32`, 5521656 bytes (5.265861511230469 Mb)\n",
      "labels               ndarray      1000x6: 6000 elems, type `int32`, 24000 bytes\n",
      "learning_rate        float        0.000100018159971905\n",
      "math                 module       <module 'math' from '/hom<...>35m-x86_64-linux-gnu.so'>\n",
      "max_learning_rate    float        0.0005\n",
      "mean                 function     <function mean at 0x7f5914a79d08>\n",
      "min_learning_rate    float        0.0001\n",
      "model_saver          Saver        <tensorflow.python.traini<...>object at 0x7f59185ad320>\n",
      "np                   module       <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "num_steps_1          int          50001\n",
      "offset               int          191593\n",
      "pickle               module       <module 'pickle' from '/h<...>lib/python3.5/pickle.py'>\n",
      "pkeep                Tensor       Tensor(\"Placeholder_3:0\", dtype=float32)\n",
      "plt                  module       <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "predictions          ndarray      5x1000x11: 55000 elems, type `float32`, 220000 bytes (214.84375 kb)\n",
      "random               module       <module 'random' from '/h<...>lib/python3.5/random.py'>\n",
      "randomize_dataset    function     <function randomize_dataset at 0x7f5914806488>\n",
      "save_path            str          saved_models/box/CNN_SVHN_Box.ckpt\n",
      "session              Session      <tensorflow.python.client<...>object at 0x7f58d7e77dd8>\n",
      "shape                list         n=4\n",
      "step                 int          50000\n",
      "stride               int          2\n",
      "svhn_test_dataset    ndarray      13068x32x96x1: 40144896 elems, type `int32`, 160579584 bytes (153.140625 Mb)\n",
      "svhn_test_labels     ndarray      13068x6: 78408 elems, type `int32`, 313632 bytes (306.28125 kb)\n",
      "svhn_train_dataset   ndarray      230255x32x96x1: 707343360 elems, type `int32`, 2829373440 bytes (2698.30078125 Mb)\n",
      "svhn_train_labels    ndarray      230255x6: 1381530 elems, type `int32`, 5526120 bytes (5.270118713378906 Mb)\n",
      "svhn_valid_dataset   ndarray      5500x32x96x1: 16896000 elems, type `int32`, 67584000 bytes (64.453125 Mb)\n",
      "svhn_valid_labels    ndarray      5500x6: 33000 elems, type `int32`, 132000 bytes (128.90625 kb)\n",
      "t_batch              int          1000\n",
      "t_step               NoneType     None\n",
      "test_acc             list         n=12\n",
      "test_avg             float        93.53833333333334\n",
      "test_no              int          13\n",
      "tf                   module       <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "train_data           ndarray      230069x32x96x1: 706771968 elems, type `float32`, 2827087872 bytes (2696.12109375 Mb)\n",
      "train_pred           ndarray      5x128x11: 7040 elems, type `float32`, 28160 bytes\n",
      "train_prediction     Tensor       Tensor(\"pack:0\", shape=(5, ?, 11), dtype=float32)\n",
      "train_step           Operation    name: \"Adam\"\\nop: \"NoOp\"\\<...>input: \"^Adam/Assign_1\"\\n\n",
      "valid_acc            list         n=4\n",
      "valid_avg            float        93.09500000000001\n",
      "valid_no             int          5\n"
     ]
    }
   ],
   "source": [
    "% whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svhn_train_dataset = svhn_train_dataset.astype(np.float32)\n",
    "svhn_test_dataset = svhn_test_dataset.astype(np.float32)\n",
    "svhn_valid_dataset = svhn_valid_dataset.astype(np.float32)\n",
    "\n",
    "svhn_train_labels = svhn_train_labels.astype(np.int32)\n",
    "svhn_test_labels = svhn_test_labels.astype(np.int32)\n",
    "svhn_valid_labels = svhn_valid_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230255, 32, 96, 1) (230255, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5500, 32, 96, 1) (5500, 6)\n"
     ]
    }
   ],
   "source": [
    "print(svhn_train_dataset.shape, svhn_train_labels.shape)\n",
    "print(svhn_test_dataset.shape, svhn_test_labels.shape)\n",
    "print(svhn_valid_dataset.shape, svhn_valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svhn_train_dataset, svhn_train_labels = randomize_dataset(svhn_train_dataset, svhn_train_labels)\n",
    "svhn_test_dataset, svhn_test_labels = randomize_dataset(svhn_test_dataset, svhn_test_labels)\n",
    "svhn_valid_dataset, svhn_valid_labels = randomize_dataset(svhn_valid_dataset, svhn_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 32, 96, 1) (125000, 6)\n",
      "(230255, 32, 96, 1) (230255, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5500, 32, 96, 1) (5500, 6)\n"
     ]
    }
   ],
   "source": [
    "svhn_train_dataset_1 = svhn_train_dataset[0:125000]\n",
    "svhn_train_labels_1 = svhn_train_labels[0:125000]\n",
    "\n",
    "print(svhn_train_dataset_1.shape, svhn_train_labels_1.shape)\n",
    "print(svhn_train_dataset.shape, svhn_train_labels.shape)\n",
    "print(svhn_test_dataset.shape, svhn_test_labels.shape)\n",
    "print(svhn_valid_dataset.shape, svhn_valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize_dataset(images, labels):\n",
    "    shuffle = list(zip(images, labels))\n",
    "    np.random.shuffle(shuffle)\n",
    "    i, l = zip(*shuffle)\n",
    "    i, l = np.asarray(i), np.asarray(l)\n",
    "    return i, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 5 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 6     # First Conv Layer with depth 6\n",
    "    L = 12     # Second Conv Layer with depth 12\n",
    "    M = 24    # Third Conv layer with depth 24\n",
    "    N = 200   # Fourth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "\n",
    "    Y4 = tf.sigmoid(tf.matmul(YY, W4) + B4)\n",
    "    YY4 = tf.nn.dropout(Y4, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(YY4, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(YY4, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(YY4, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(YY4, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(YY4, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3)),tf.reduce_max(tf.abs(W4))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3)),tf.reduce_max(tf.abs(B4))])\n",
    "    \n",
    "    var_list = [W1, B1, W2, B2, W3, B3, W4, B4, W5_1, B5_1, W5_2, B5_2, W5_3, B5_3, W5_4, B5_4, W5_5, B5_5]\n",
    "    model_saver = tf.train.Saver(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (230069, 32, 96, 1)   test :  (230069, 6)\n",
      "Initialized\n",
      "W :  [ 0.19758295  0.19993503  0.19987057  0.19999866]\n",
      "b :  [ 0.1  0.1  0.1  0.1]\n",
      "Loss at step 0: 13.472513\n",
      "Minibatch accuracy: 7.2%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.26501966  0.30211484  0.27566063  0.29679999]\n",
      "b :  [ 0.14650765  0.11654811  0.10576747  0.11026224]\n",
      "Loss at step 500: 5.076310\n",
      "Minibatch accuracy: 68.3%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_box_dataset\n",
    "label_data = svhn_train_box_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 20001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    batch = 1000\n",
    "    \n",
    "    test_acc = list()\n",
    "    print('-------TEST--------')\n",
    "    test_no = int(svhn_test_box_labels.shape[0] / batch)\n",
    "    for i in range(test_no - 1):\n",
    "        data = svhn_test_box_dataset[i*t_batch:(i+1)*batch]\n",
    "        labels = svhn_test_box_labels[i*t_batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        test_acc.append(accuracy)\n",
    "        \n",
    "        print('Test-Accuracy', ' i : ', i)\n",
    "        print('Test accuracy: ', accuracy)\n",
    "        print('       ')\n",
    "    \n",
    "    valid_acc = list()\n",
    "    print('-----VALIDIDATION------')\n",
    "    valid_no = int(svhn_valid_box_labels.shape[0] /  batch)\n",
    "    for i in range(valid_no - 1):\n",
    "        data = svhn_valid_box_dataset[i*t_batch:(i+1)*batch]\n",
    "        labels = svhn_valid_box_labels[i*t_batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        valid_acc.append(accuracy)\n",
    "        \n",
    "        print('Valid-Accuracy', ' i : ', i)\n",
    "        print('Valid accuracy: ', accuracy)\n",
    "        print('        ')\n",
    "        \n",
    "        \n",
    "    test_avg = mean(test_acc)\n",
    "    valid_avg = mean(valid_acc)\n",
    "    \n",
    "    print('-----  FINAL  ------')\n",
    "    print('Final Test Set Accuracy : ',\"%.2f\" % test_avg)\n",
    "    print('Final Validation Set Accuracy : ',\"%.2f\" % valid_avg)\n",
    "        \n",
    "#     _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_valid_box_dataset, Y_ : svhn_valid_box_labels, pkeep : 1.0, alpha : 0.002})\n",
    "#     print('Validation accuracy: ', acc(predictions, svhn_valid_box_labels[:,1:6]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (125000, 32, 96, 1)   test :  (125000, 6)\n",
      "Initialized\n",
      "W :  [ 0.1957577   0.19950426  0.19999866  0.19999957]\n",
      "b :  [ 0.1  0.1  0.1  0.1]\n",
      "Loss at step 0: 15.812104\n",
      "Minibatch accuracy: 3.4%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.20176931  0.20336588  0.21233326  0.21602039]\n",
      "b :  [ 0.09924942  0.11802243  0.11003009  0.11306362]\n",
      "Loss at step 500: 6.913124\n",
      "Minibatch accuracy: 53.9%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n",
      "W :  [ 0.20172596  0.20614482  0.21922968  0.232022  ]\n",
      "b :  [ 0.10019359  0.12345539  0.11821508  0.1157744 ]\n",
      "Loss at step 1000: 6.926769\n",
      "Minibatch accuracy: 54.4%\n",
      "Learning rate :  0.00042749230123119273\n",
      "    \n",
      "W :  [ 0.20099458  0.20611057  0.22664881  0.24046591]\n",
      "b :  [ 0.10177581  0.12987101  0.11949582  0.11835108]\n",
      "Loss at step 1500: 6.856278\n",
      "Minibatch accuracy: 53.8%\n",
      "Learning rate :  0.00039632728827268716\n",
      "    \n",
      "W :  [ 0.19851771  0.20685558  0.23405121  0.24046807]\n",
      "b :  [ 0.10594938  0.12891285  0.12108289  0.11941691]\n",
      "Loss at step 2000: 6.854865\n",
      "Minibatch accuracy: 54.5%\n",
      "Learning rate :  0.00036812801841425575\n",
      "    \n",
      "W :  [ 0.19885743  0.20673087  0.22454622  0.24046807]\n",
      "b :  [ 0.10078057  0.12566251  0.12178466  0.11941747]\n",
      "Loss at step 2500: 6.712354\n",
      "Minibatch accuracy: 56.1%\n",
      "Learning rate :  0.0003426122638850534\n",
      "    \n",
      "W :  [ 0.19806634  0.20684935  0.22336483  0.24046807]\n",
      "b :  [ 0.10074405  0.12759718  0.12241045  0.11941747]\n",
      "Loss at step 3000: 6.828880\n",
      "Minibatch accuracy: 55.6%\n",
      "Learning rate :  0.00031952465443761056\n",
      "    \n",
      "Training Complete on SVHN Data\n",
      "Model saved in file: saved_models/multi/CNN_SVHN_New.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_dataset_1\n",
    "label_data = svhn_train_labels_1\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 3001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/multi/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "[[[[ 0.06091791  0.0327538  -0.19416073 -0.01676372  0.02233364 -0.02901404]]\n",
      "\n",
      "  [[-0.04115827 -0.00266697  0.10546505  0.03128034 -0.02302971  0.03785209]]\n",
      "\n",
      "  [[ 0.02321358 -0.08577943 -0.07981791  0.19747455 -0.06205473  0.06701094]]\n",
      "\n",
      "  [[-0.02935915 -0.09522378  0.05649186  0.08751354 -0.05960583 -0.07666398]]\n",
      "\n",
      "  [[-0.14650303  0.17145529 -0.00110248  0.04165018  0.01372952  0.02088568]]\n",
      "\n",
      "  [[ 0.01313367  0.00348472 -0.12836632  0.01750273 -0.06433355 -0.1076489 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.01552692  0.19806165  0.01933289 -0.14826033 -0.04317336 -0.09452876]]\n",
      "\n",
      "  [[ 0.04372241 -0.17828043  0.10888292  0.01148719 -0.05250533 -0.02962187]]\n",
      "\n",
      "  [[-0.00225709 -0.13161032 -0.05115749  0.03142713  0.173245   -0.01677104]]\n",
      "\n",
      "  [[-0.15817691 -0.09034646 -0.07150197 -0.16240661  0.06633522  0.05496876]]\n",
      "\n",
      "  [[ 0.01151476 -0.12420844  0.02609648  0.12235687  0.0465115  -0.04505098]]\n",
      "\n",
      "  [[ 0.0315448   0.05198722 -0.04371455  0.01141434  0.14327204  0.00390389]]]\n",
      "\n",
      "\n",
      " [[[ 0.03091958  0.07570969 -0.02342565 -0.03872439 -0.04015407 -0.08602554]]\n",
      "\n",
      "  [[ 0.02378318 -0.08907981 -0.15645039  0.06542825  0.09423941 -0.10839536]]\n",
      "\n",
      "  [[ 0.02070081  0.01333255  0.0449475   0.09415334 -0.03849457 -0.02886223]]\n",
      "\n",
      "  [[ 0.00760063  0.06761961  0.00117242  0.13430864  0.04532625  0.16775081]]\n",
      "\n",
      "  [[-0.16506451  0.19178335 -0.01929418  0.13293149 -0.06950808 -0.03165402]]\n",
      "\n",
      "  [[ 0.18326561  0.0484001  -0.07809924  0.00830957 -0.11867001  0.05960385]]]\n",
      "\n",
      "\n",
      " [[[-0.03748919  0.034536   -0.09154861  0.08603668  0.14596036  0.03997054]]\n",
      "\n",
      "  [[-0.10398785 -0.01502437 -0.04771554  0.03199447  0.15158996 -0.00840558]]\n",
      "\n",
      "  [[-0.10634744  0.02363387 -0.08033192  0.08695528 -0.0052344   0.02523604]]\n",
      "\n",
      "  [[ 0.11331021  0.07645024  0.03870131  0.11845255  0.09248876 -0.05609425]]\n",
      "\n",
      "  [[ 0.14758033 -0.05645988 -0.06595926  0.08367525 -0.1014366   0.03099165]]\n",
      "\n",
      "  [[-0.08419337  0.11256319  0.08401316  0.08168194  0.09528156  0.00709938]]]\n",
      "\n",
      "\n",
      " [[[-0.17133284 -0.03409197  0.05551128 -0.13806874  0.01626393 -0.02226449]]\n",
      "\n",
      "  [[ 0.03684654  0.1077869  -0.12631294 -0.07464807  0.01916724 -0.10269179]]\n",
      "\n",
      "  [[ 0.00852831  0.04899293  0.14605917 -0.00403936 -0.084778    0.10300333]]\n",
      "\n",
      "  [[-0.00663539 -0.07487232  0.03070545  0.1060371  -0.11604117  0.00386443]]\n",
      "\n",
      "  [[ 0.17946935 -0.06679755  0.0892888   0.07371145  0.13549356 -0.0099855 ]]\n",
      "\n",
      "  [[ 0.05488029  0.0880746   0.10262068 -0.18100721 -0.10969175 -0.11322756]]]\n",
      "\n",
      "\n",
      " [[[-0.04615289 -0.02808108  0.08740799  0.02018475  0.0933042  -0.05140632]]\n",
      "\n",
      "  [[-0.0463795  -0.10210032 -0.01816775 -0.12486283 -0.0418921   0.16506787]]\n",
      "\n",
      "  [[-0.01717398  0.01700228 -0.01106519 -0.08680537 -0.07057849 -0.13027653]]\n",
      "\n",
      "  [[ 0.06206699  0.00820066 -0.02102993  0.05635266 -0.01888345  0.03008891]]\n",
      "\n",
      "  [[ 0.07795174 -0.01799627 -0.01332367  0.01182583  0.12691803 -0.02683318]]\n",
      "\n",
      "  [[ 0.03023325  0.17112572  0.04509779  0.14706104  0.06975733  0.05051372]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/multi/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    print(session.run(W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_17', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-e7059acaa63f>\", line 91, in <module>\n    model_saver = tf.train.Saver(var_list)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ce56aeb21563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_svhn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saved_models/box/CNN_SVHNox_.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1388\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_17', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-e7059acaa63f>\", line 91, in <module>\n    model_saver = tf.train.Saver(var_list)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/box/CNN_SVHNox_.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    print(session.run([W1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/multi/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_test_dataset[:500], Y_ : svhn_test_labels[:500], pkeep : 1.0, alpha : 0.002})\n",
    "    print('Test accuracy: ', acc(predictions, svhn_test_labels[:500,1:6]))\n",
    "    \n",
    "    del l, predictions\n",
    "    _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_valid_dataset, Y_ : svhn_valid_labels, pkeep : 1.0, alpha : 0.002})\n",
    "    print('Validation accuracy: ', acc(predictions, svhn_valid_labels[:,1:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (125000, 32, 96, 1)   test :  (125000, 6)\n",
      "Model restored.\n",
      "Initialized\n",
      "W :  [ 0.41171086  0.69925141  0.47237745  0.7207135 ]\n",
      "b :  [ 0.53505075  0.31870961  0.45383301  0.12280813]\n",
      "Loss at step 0: 54.654106\n",
      "Minibatch accuracy: 16.9%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.42643231  0.70004612  0.46439368  0.71949875]\n",
      "b :  [ 0.53378701  0.31939578  0.45481381  0.12296873]\n",
      "Loss at step 500: 8.034361\n",
      "Minibatch accuracy: 52.0%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-74598fca8e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_dataset_1\n",
    "label_data = svhn_train_labels_1\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 20001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "#     tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/combined/CNN_SVHN_Mix.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
