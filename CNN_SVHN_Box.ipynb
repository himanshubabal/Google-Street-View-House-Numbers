{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230069, 32, 96, 1) (230069, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5684, 32, 96, 1) (5684, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi_box.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "svhn_train_box_dataset = hdf['train_images'][:]\n",
    "svhn_train_box_labels = hdf['train_labels'][:]\n",
    "svhn_test_box_dataset = hdf['test_images'][:]\n",
    "svhn_test_box_labels = hdf['test_labels'][:]\n",
    "svhn_valid_box_dataset = hdf['valid_images'][:]\n",
    "svhn_valid_box_labels = hdf['valid_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "\n",
    "print(svhn_train_box_dataset.shape, svhn_train_box_labels.shape)\n",
    "print(svhn_test_box_dataset.shape, svhn_test_box_labels.shape)\n",
    "print(svhn_valid_box_dataset.shape, svhn_valid_box_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svhn_train_box_dataset = svhn_train_box_dataset.astype(np.float32)\n",
    "svhn_test_box_dataset = svhn_test_box_dataset.astype(np.float32)\n",
    "svhn_valid_box_dataset = svhn_valid_box_dataset.astype(np.float32)\n",
    "\n",
    "svhn_train_box_labels = svhn_train_box_labels.astype(np.int32)\n",
    "svhn_test_box_labels = svhn_test_box_labels.astype(np.int32)\n",
    "svhn_valid_box_labels = svhn_valid_box_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230255, 32, 96, 1) (230255, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5500, 32, 96, 1) (5500, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "svhn_test_dataset = hdf['test_images'][:]\n",
    "svhn_test_labels = hdf['test_labels'][:]\n",
    "svhn_train_dataset = hdf['train_images'][:]\n",
    "svhn_train_labels = hdf['train_labels'][:]\n",
    "svhn_valid_dataset = hdf['valid_images'][:]\n",
    "svhn_valid_labels = hdf['valid_labels'][:]\n",
    "\n",
    "hdf.close()    \n",
    "\n",
    "print(svhn_train_dataset.shape, svhn_train_labels.shape)\n",
    "print(svhn_test_dataset.shape, svhn_test_labels.shape)\n",
    "print(svhn_valid_dataset.shape, svhn_valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type        Data/Info\n",
      "------------------------------------------\n",
      "Image                module      <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "gc                   module      <module 'gc' (built-in)>\n",
      "h5py                 module      <module 'h5py' from '/hom<...>ckages/h5py/__init__.py'>\n",
      "hdf                  File        <Closed HDF5 file>\n",
      "hdf_file             str         datasets/pickles/SVHN_multi.hdf5\n",
      "imshow               function    <function imshow at 0x7fb69e53f730>\n",
      "math                 module      <module 'math' from '/hom<...>35m-x86_64-linux-gnu.so'>\n",
      "np                   module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "pickle               module      <module 'pickle' from '/h<...>lib/python3.5/pickle.py'>\n",
      "plt                  module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "random               module      <module 'random' from '/h<...>lib/python3.5/random.py'>\n",
      "svhn_test_dataset    ndarray     13068x32x96x1: 40144896 elems, type `int32`, 160579584 bytes (153.140625 Mb)\n",
      "svhn_test_labels     ndarray     13068x6: 78408 elems, type `int32`, 313632 bytes (306.28125 kb)\n",
      "svhn_train_dataset   ndarray     230255x32x96x1: 707343360 elems, type `int32`, 2829373440 bytes (2698.30078125 Mb)\n",
      "svhn_train_labels    ndarray     230255x6: 1381530 elems, type `int32`, 5526120 bytes (5.270118713378906 Mb)\n",
      "svhn_valid_dataset   ndarray     5500x32x96x1: 16896000 elems, type `int32`, 67584000 bytes (64.453125 Mb)\n",
      "svhn_valid_labels    ndarray     5500x6: 33000 elems, type `int32`, 132000 bytes (128.90625 kb)\n",
      "sys                  module      <module 'sys' (built-in)>\n",
      "tf                   module      <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del svhn_test_box_dataset, svhn_test_box_labels, svhn_train_box_dataset, svhn_train_box_labels, svhn_valid_box_dataset, svhn_valid_box_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type         Data/Info\n",
      "-------------------------------------------\n",
      "B1                   Variable     Tensor(\"Variable_1/read:0<...>hape=(6,), dtype=float32)\n",
      "B2                   Variable     Tensor(\"Variable_3/read:0<...>ape=(12,), dtype=float32)\n",
      "B3                   Variable     Tensor(\"Variable_5/read:0<...>ape=(24,), dtype=float32)\n",
      "B4                   Variable     Tensor(\"Variable_17/read:<...>pe=(200,), dtype=float32)\n",
      "B5_1                 Variable     Tensor(\"Variable_7/read:0<...>ape=(11,), dtype=float32)\n",
      "B5_2                 Variable     Tensor(\"Variable_9/read:0<...>ape=(11,), dtype=float32)\n",
      "B5_3                 Variable     Tensor(\"Variable_11/read:<...>ape=(11,), dtype=float32)\n",
      "B5_4                 Variable     Tensor(\"Variable_13/read:<...>ape=(11,), dtype=float32)\n",
      "B5_5                 Variable     Tensor(\"Variable_15/read:<...>ape=(11,), dtype=float32)\n",
      "HEIGHT               int          32\n",
      "Image                module       <module 'PIL.Image' from <...>e-packages/PIL/Image.py'>\n",
      "K                    int          6\n",
      "L                    int          12\n",
      "M                    int          24\n",
      "N                    int          200\n",
      "W                    ndarray      4: 4 elems, type `float32`, 16 bytes\n",
      "W1                   Variable     Tensor(\"Variable/read:0\",<...> 6, 1, 6), dtype=float32)\n",
      "W2                   Variable     Tensor(\"Variable_2/read:0<...>5, 6, 12), dtype=float32)\n",
      "W3                   Variable     Tensor(\"Variable_4/read:0<...>, 12, 24), dtype=float32)\n",
      "W4                   Variable     Tensor(\"Variable_16/read:<...>608, 200), dtype=float32)\n",
      "W5_1                 Variable     Tensor(\"Variable_6/read:0<...>(200, 11), dtype=float32)\n",
      "W5_2                 Variable     Tensor(\"Variable_8/read:0<...>(200, 11), dtype=float32)\n",
      "W5_3                 Variable     Tensor(\"Variable_10/read:<...>(200, 11), dtype=float32)\n",
      "W5_4                 Variable     Tensor(\"Variable_12/read:<...>(200, 11), dtype=float32)\n",
      "W5_5                 Variable     Tensor(\"Variable_14/read:<...>(200, 11), dtype=float32)\n",
      "WIDTH                int          96\n",
      "W_s                  Tensor       Tensor(\"pack_1:0\", shape=(4,), dtype=float32)\n",
      "X                    Tensor       Tensor(\"Placeholder:0\", s<...>2, 96, 1), dtype=float32)\n",
      "Y1                   Tensor       Tensor(\"Relu:0\", shape=(?<...>2, 96, 6), dtype=float32)\n",
      "Y2                   Tensor       Tensor(\"Relu_1:0\", shape=<...>, 48, 12), dtype=float32)\n",
      "Y3                   Tensor       Tensor(\"Relu_2:0\", shape=<...>, 24, 24), dtype=float32)\n",
      "Y4                   Tensor       Tensor(\"Sigmoid:0\", shape<...>=(?, 200), dtype=float32)\n",
      "YY                   Tensor       Tensor(\"Reshape:0\", shape<...>(?, 4608), dtype=float32)\n",
      "YY4                  Tensor       Tensor(\"dropout/mul:0\", s<...>=(?, 200), dtype=float32)\n",
      "Y_                   Tensor       Tensor(\"Placeholder_1:0\",<...>hape=(?, 6), dtype=int32)\n",
      "Y_1                  Tensor       Tensor(\"Softmax:0\", shape=(?, 11), dtype=float32)\n",
      "Y_2                  Tensor       Tensor(\"Softmax_1:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Y_3                  Tensor       Tensor(\"Softmax_2:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Y_4                  Tensor       Tensor(\"Softmax_3:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Y_5                  Tensor       Tensor(\"Softmax_4:0\", sha<...>e=(?, 11), dtype=float32)\n",
      "Ylogits_1            Tensor       Tensor(\"add_4:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_2            Tensor       Tensor(\"add_5:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_3            Tensor       Tensor(\"add_6:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_4            Tensor       Tensor(\"add_7:0\", shape=(?, 11), dtype=float32)\n",
      "Ylogits_5            Tensor       Tensor(\"add_8:0\", shape=(?, 11), dtype=float32)\n",
      "acc                  function     <function acc at 0x7f59148061e0>\n",
      "accuracy             float64      92.42\n",
      "alpha                Tensor       Tensor(\"Placeholder_2:0\", dtype=float32)\n",
      "b                    ndarray      4: 4 elems, type `float32`, 16 bytes\n",
      "b_s                  Tensor       Tensor(\"pack_2:0\", shape=(4,), dtype=float32)\n",
      "batch                int          1000\n",
      "batch_data           ndarray      128x32x96x1: 393216 elems, type `float32`, 1572864 bytes (1.5 Mb)\n",
      "batch_labels         ndarray      128x6: 768 elems, type `int32`, 3072 bytes\n",
      "batch_size           int          128\n",
      "cross_entropy        Tensor       Tensor(\"add_12:0\", shape=(), dtype=float32)\n",
      "data                 ndarray      1000x32x96x1: 3072000 elems, type `float32`, 12288000 bytes (11.71875 Mb)\n",
      "decay_speed          float        5000.0\n",
      "feed_dict            dict         n=4\n",
      "gc                   module       <module 'gc' (built-in)>\n",
      "graph_svhn           Graph        <tensorflow.python.framew<...>object at 0x7f59148390b8>\n",
      "h5py                 module       <module 'h5py' from '/hom<...>ckages/h5py/__init__.py'>\n",
      "hdf                  File         <Closed HDF5 file>\n",
      "hdf_file             str          datasets/pickles/SVHN_multi.hdf5\n",
      "i                    int          3\n",
      "imshow               function     <function imshow at 0x7f591c140730>\n",
      "l                    float32      1.3328\n",
      "label_data           ndarray      230069x6: 1380414 elems, type `int32`, 5521656 bytes (5.265861511230469 Mb)\n",
      "labels               ndarray      1000x6: 6000 elems, type `int32`, 24000 bytes\n",
      "learning_rate        float        0.000100018159971905\n",
      "math                 module       <module 'math' from '/hom<...>35m-x86_64-linux-gnu.so'>\n",
      "max_learning_rate    float        0.0005\n",
      "mean                 function     <function mean at 0x7f5914a79d08>\n",
      "min_learning_rate    float        0.0001\n",
      "model_saver          Saver        <tensorflow.python.traini<...>object at 0x7f59185ad320>\n",
      "np                   module       <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "num_steps_1          int          50001\n",
      "offset               int          191593\n",
      "pickle               module       <module 'pickle' from '/h<...>lib/python3.5/pickle.py'>\n",
      "pkeep                Tensor       Tensor(\"Placeholder_3:0\", dtype=float32)\n",
      "plt                  module       <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "predictions          ndarray      5x1000x11: 55000 elems, type `float32`, 220000 bytes (214.84375 kb)\n",
      "random               module       <module 'random' from '/h<...>lib/python3.5/random.py'>\n",
      "randomize_dataset    function     <function randomize_dataset at 0x7f5914806488>\n",
      "save_path            str          saved_models/box/CNN_SVHN_Box.ckpt\n",
      "session              Session      <tensorflow.python.client<...>object at 0x7f58d7e77dd8>\n",
      "shape                list         n=4\n",
      "step                 int          50000\n",
      "stride               int          2\n",
      "svhn_test_dataset    ndarray      13068x32x96x1: 40144896 elems, type `int32`, 160579584 bytes (153.140625 Mb)\n",
      "svhn_test_labels     ndarray      13068x6: 78408 elems, type `int32`, 313632 bytes (306.28125 kb)\n",
      "svhn_train_dataset   ndarray      230255x32x96x1: 707343360 elems, type `int32`, 2829373440 bytes (2698.30078125 Mb)\n",
      "svhn_train_labels    ndarray      230255x6: 1381530 elems, type `int32`, 5526120 bytes (5.270118713378906 Mb)\n",
      "svhn_valid_dataset   ndarray      5500x32x96x1: 16896000 elems, type `int32`, 67584000 bytes (64.453125 Mb)\n",
      "svhn_valid_labels    ndarray      5500x6: 33000 elems, type `int32`, 132000 bytes (128.90625 kb)\n",
      "t_batch              int          1000\n",
      "t_step               NoneType     None\n",
      "test_acc             list         n=12\n",
      "test_avg             float        93.53833333333334\n",
      "test_no              int          13\n",
      "tf                   module       <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "train_data           ndarray      230069x32x96x1: 706771968 elems, type `float32`, 2827087872 bytes (2696.12109375 Mb)\n",
      "train_pred           ndarray      5x128x11: 7040 elems, type `float32`, 28160 bytes\n",
      "train_prediction     Tensor       Tensor(\"pack:0\", shape=(5, ?, 11), dtype=float32)\n",
      "train_step           Operation    name: \"Adam\"\\nop: \"NoOp\"\\<...>input: \"^Adam/Assign_1\"\\n\n",
      "valid_acc            list         n=4\n",
      "valid_avg            float        93.09500000000001\n",
      "valid_no             int          5\n"
     ]
    }
   ],
   "source": [
    "% whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svhn_train_dataset = svhn_train_dataset.astype(np.float32)\n",
    "svhn_test_dataset = svhn_test_dataset.astype(np.float32)\n",
    "svhn_valid_dataset = svhn_valid_dataset.astype(np.float32)\n",
    "\n",
    "svhn_train_labels = svhn_train_labels.astype(np.int32)\n",
    "svhn_test_labels = svhn_test_labels.astype(np.int32)\n",
    "svhn_valid_labels = svhn_valid_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230255, 32, 96, 1) (230255, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5500, 32, 96, 1) (5500, 6)\n"
     ]
    }
   ],
   "source": [
    "print(svhn_train_dataset.shape, svhn_train_labels.shape)\n",
    "print(svhn_test_dataset.shape, svhn_test_labels.shape)\n",
    "print(svhn_valid_dataset.shape, svhn_valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svhn_train_dataset, svhn_train_labels = randomize_dataset(svhn_train_dataset, svhn_train_labels)\n",
    "svhn_test_dataset, svhn_test_labels = randomize_dataset(svhn_test_dataset, svhn_test_labels)\n",
    "svhn_valid_dataset, svhn_valid_labels = randomize_dataset(svhn_valid_dataset, svhn_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 32, 96, 1) (125000, 6)\n",
      "(230255, 32, 96, 1) (230255, 6)\n",
      "(13068, 32, 96, 1) (13068, 6)\n",
      "(5500, 32, 96, 1) (5500, 6)\n"
     ]
    }
   ],
   "source": [
    "svhn_train_dataset_1 = svhn_train_dataset[0:125000]\n",
    "svhn_train_labels_1 = svhn_train_labels[0:125000]\n",
    "\n",
    "print(svhn_train_dataset_1.shape, svhn_train_labels_1.shape)\n",
    "print(svhn_train_dataset.shape, svhn_train_labels.shape)\n",
    "print(svhn_test_dataset.shape, svhn_test_labels.shape)\n",
    "print(svhn_valid_dataset.shape, svhn_valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize_dataset(images, labels):\n",
    "    shuffle = list(zip(images, labels))\n",
    "    np.random.shuffle(shuffle)\n",
    "    i, l = zip(*shuffle)\n",
    "    i, l = np.asarray(i), np.asarray(l)\n",
    "    return i, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 5 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 6     # First Conv Layer with depth 6\n",
    "    L = 12     # Second Conv Layer with depth 12\n",
    "    M = 24    # Third Conv layer with depth 24\n",
    "    N = 200   # Fourth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "\n",
    "    Y4 = tf.sigmoid(tf.matmul(YY, W4) + B4)\n",
    "    YY4 = tf.nn.dropout(Y4, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(YY4, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(YY4, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(YY4, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(YY4, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(YY4, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3)),tf.reduce_max(tf.abs(W4))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3)),tf.reduce_max(tf.abs(B4))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (230069, 32, 96, 1)   test :  (230069, 6)\n",
      "Initialized\n",
      "W :  [ 0.19912431  0.19984199  0.19993149  0.19999866]\n",
      "b :  [ 0.1  0.1  0.1  0.1]\n",
      "Loss at step 0: 10.998222\n",
      "Minibatch accuracy: 25.6%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.27869901  0.28080469  0.31645367  0.29588386]\n",
      "b :  [ 0.10715443  0.10085165  0.10796183  0.10712352]\n",
      "Loss at step 500: 3.978148\n",
      "Minibatch accuracy: 76.1%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n",
      "W :  [ 0.29005209  0.336739    0.36391553  0.36647207]\n",
      "b :  [ 0.13026245  0.09765711  0.11307368  0.10726233]\n",
      "Loss at step 1000: 2.775166\n",
      "Minibatch accuracy: 83.4%\n",
      "Learning rate :  0.00042749230123119273\n",
      "    \n",
      "W :  [ 0.29654711  0.36784068  0.39701965  0.38761118]\n",
      "b :  [ 0.14628613  0.11255246  0.12173833  0.10971935]\n",
      "Loss at step 1500: 2.475353\n",
      "Minibatch accuracy: 84.4%\n",
      "Learning rate :  0.00039632728827268716\n",
      "    \n",
      "W :  [ 0.29915556  0.38268748  0.42087078  0.41162404]\n",
      "b :  [ 0.18033437  0.13236335  0.14346537  0.1101019 ]\n",
      "Loss at step 2000: 2.095910\n",
      "Minibatch accuracy: 88.6%\n",
      "Learning rate :  0.00036812801841425575\n",
      "    \n",
      "W :  [ 0.3004058   0.39187241  0.44357437  0.43873802]\n",
      "b :  [ 0.20029689  0.13978729  0.1635213   0.11472598]\n",
      "Loss at step 2500: 1.900114\n",
      "Minibatch accuracy: 89.1%\n",
      "Learning rate :  0.0003426122638850534\n",
      "    \n",
      "W :  [ 0.3014484   0.39559698  0.45419651  0.44851917]\n",
      "b :  [ 0.21794577  0.14629698  0.18326943  0.11636787]\n",
      "Loss at step 3000: 1.867465\n",
      "Minibatch accuracy: 87.7%\n",
      "Learning rate :  0.00031952465443761056\n",
      "    \n",
      "W :  [ 0.30445141  0.39946118  0.46181992  0.454909  ]\n",
      "b :  [ 0.23701957  0.15831982  0.19794412  0.11481352]\n",
      "Loss at step 3500: 1.915848\n",
      "Minibatch accuracy: 88.4%\n",
      "Learning rate :  0.00029863412151656383\n",
      "    \n",
      "W :  [ 0.30393022  0.39555183  0.46365327  0.46718395]\n",
      "b :  [ 0.24863282  0.15927476  0.21605483  0.11573194]\n",
      "Loss at step 4000: 1.725922\n",
      "Minibatch accuracy: 88.8%\n",
      "Learning rate :  0.00027973158564688865\n",
      "    \n",
      "W :  [ 0.3047269   0.39782777  0.46836624  0.4811621 ]\n",
      "b :  [ 0.25578976  0.1610834   0.22786883  0.11697342]\n",
      "Loss at step 4500: 1.338126\n",
      "Minibatch accuracy: 91.6%\n",
      "Learning rate :  0.0002626278638962397\n",
      "    \n",
      "W :  [ 0.30614656  0.39853722  0.4753173   0.49787772]\n",
      "b :  [ 0.26216382  0.16304564  0.23881954  0.11743306]\n",
      "Loss at step 5000: 1.943651\n",
      "Minibatch accuracy: 88.0%\n",
      "Learning rate :  0.00024715177646857697\n",
      "    \n",
      "W :  [ 0.30741403  0.39673662  0.48213169  0.51375347]\n",
      "b :  [ 0.27493683  0.17279178  0.24715661  0.11865667]\n",
      "Loss at step 5500: 1.201864\n",
      "Minibatch accuracy: 93.1%\n",
      "Learning rate :  0.0002331484334792318\n",
      "    \n",
      "W :  [ 0.307576    0.3957586   0.48682809  0.52073413]\n",
      "b :  [ 0.27919626  0.17050417  0.25785461  0.11676871]\n",
      "Loss at step 6000: 1.394326\n",
      "Minibatch accuracy: 92.0%\n",
      "Learning rate :  0.00022047768476488088\n",
      "    \n",
      "W :  [ 0.30672458  0.39700836  0.49485564  0.5323894 ]\n",
      "b :  [ 0.28295943  0.17415616  0.26518163  0.11817072]\n",
      "Loss at step 6500: 1.301685\n",
      "Minibatch accuracy: 91.9%\n",
      "Learning rate :  0.00020901271721360503\n",
      "    \n",
      "W :  [ 0.30845115  0.40246105  0.50575429  0.54698652]\n",
      "b :  [ 0.28568661  0.17714396  0.2726877   0.11967883]\n",
      "Loss at step 7000: 1.521753\n",
      "Minibatch accuracy: 91.2%\n",
      "Learning rate :  0.0001986387855766426\n",
      "    \n",
      "W :  [ 0.3092179   0.40523785  0.51413393  0.55756307]\n",
      "b :  [ 0.29172039  0.18123467  0.27927029  0.1189911 ]\n",
      "Loss at step 7500: 1.280264\n",
      "Minibatch accuracy: 92.8%\n",
      "Learning rate :  0.00018925206405937195\n",
      "    \n",
      "W :  [ 0.30868742  0.40852386  0.52511948  0.56238341]\n",
      "b :  [ 0.29290566  0.18237129  0.28566596  0.11950738]\n",
      "Loss at step 8000: 1.268107\n",
      "Minibatch accuracy: 93.0%\n",
      "Learning rate :  0.00018075860719786216\n",
      "    \n",
      "W :  [ 0.30834264  0.41326505  0.53184539  0.56941015]\n",
      "b :  [ 0.29685748  0.18363416  0.29071999  0.11957879]\n",
      "Loss at step 8500: 0.914373\n",
      "Minibatch accuracy: 94.5%\n",
      "Learning rate :  0.00017307340962109387\n",
      "    \n",
      "W :  [ 0.31230608  0.41840786  0.53847015  0.57554406]\n",
      "b :  [ 0.3044228   0.19207554  0.29619652  0.122705  ]\n",
      "Loss at step 9000: 1.306086\n",
      "Minibatch accuracy: 93.0%\n",
      "Learning rate :  0.00016611955528863463\n",
      "    \n",
      "W :  [ 0.30983225  0.42286512  0.54644698  0.582313  ]\n",
      "b :  [ 0.3059026   0.18873714  0.30171371  0.12172759]\n",
      "Loss at step 9500: 0.845414\n",
      "Minibatch accuracy: 94.2%\n",
      "Learning rate :  0.00015982744768905404\n",
      "    \n",
      "W :  [ 0.31074658  0.42371362  0.55545056  0.58871752]\n",
      "b :  [ 0.30627728  0.19087681  0.30660272  0.12196843]\n",
      "Loss at step 10000: 1.267783\n",
      "Minibatch accuracy: 92.8%\n",
      "Learning rate :  0.0001541341132946451\n",
      "    \n",
      "W :  [ 0.311382    0.42826176  0.56269586  0.59607178]\n",
      "b :  [ 0.3074784   0.19144826  0.31147194  0.12178887]\n",
      "Loss at step 10500: 1.114718\n",
      "Minibatch accuracy: 92.5%\n",
      "Learning rate :  0.00014898257130119277\n",
      "    \n",
      "W :  [ 0.3130618   0.4332594   0.5637458   0.60125715]\n",
      "b :  [ 0.31328231  0.19715196  0.3162834   0.12249425]\n",
      "Loss at step 11000: 1.069908\n",
      "Minibatch accuracy: 94.1%\n",
      "Learning rate :  0.00014432126334493355\n",
      "    \n",
      "W :  [ 0.31251341  0.43380055  0.56964064  0.60261887]\n",
      "b :  [ 0.31461731  0.19658345  0.32023188  0.12205638]\n",
      "Loss at step 11500: 0.998943\n",
      "Minibatch accuracy: 95.0%\n",
      "Learning rate :  0.0001401035374891215\n",
      "    \n",
      "W :  [ 0.31251058  0.43846887  0.5784139   0.60816675]\n",
      "b :  [ 0.31559864  0.1989058   0.32467869  0.12260862]\n",
      "Loss at step 12000: 0.935072\n",
      "Minibatch accuracy: 94.7%\n",
      "Learning rate :  0.00013628718131576502\n",
      "    \n",
      "W :  [ 0.31555915  0.44269583  0.58088338  0.61360413]\n",
      "b :  [ 0.31999412  0.20418561  0.32849616  0.12308465]\n",
      "Loss at step 12500: 1.386089\n",
      "Minibatch accuracy: 91.2%\n",
      "Learning rate :  0.00013283399944955952\n",
      "    \n",
      "W :  [ 0.31446728  0.44502854  0.58365762  0.61594528]\n",
      "b :  [ 0.32145655  0.20273359  0.33218625  0.12295573]\n",
      "Loss at step 13000: 0.735602\n",
      "Minibatch accuracy: 95.2%\n",
      "Learning rate :  0.00012970943128573357\n",
      "    \n",
      "W :  [ 0.31469592  0.44472912  0.58863622  0.61518276]\n",
      "b :  [ 0.32099316  0.20370214  0.33556417  0.12317042]\n",
      "Loss at step 13500: 1.127502\n",
      "Minibatch accuracy: 93.0%\n",
      "Learning rate :  0.0001268822050958999\n",
      "    \n",
      "W :  [ 0.31545356  0.44868964  0.59227121  0.61989212]\n",
      "b :  [ 0.32248795  0.20474057  0.33852041  0.12296176]\n",
      "Loss at step 14000: 0.909411\n",
      "Minibatch accuracy: 94.7%\n",
      "Learning rate :  0.0001243240250500872\n",
      "    \n",
      "W :  [ 0.31717193  0.45242012  0.59197068  0.62334991]\n",
      "b :  [ 0.32925564  0.21002424  0.34283382  0.12319899]\n",
      "Loss at step 14500: 0.876098\n",
      "Minibatch accuracy: 95.3%\n",
      "Learning rate :  0.0001220092880225629\n",
      "    \n",
      "W :  [ 0.31687203  0.45402247  0.59676337  0.62459302]\n",
      "b :  [ 0.32976317  0.20867689  0.34624666  0.12293001]\n",
      "Loss at step 15000: 1.012614\n",
      "Minibatch accuracy: 94.4%\n",
      "Learning rate :  0.00011991482734714559\n",
      "    \n",
      "Training Complete on SVHN Data\n",
      "Model saved in file: saved_models/box/vars/CNN_SVHN_Box.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_box_dataset\n",
    "label_data = svhn_train_box_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 15001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "-------TEST--------\n",
      "Test-Accuracy  i :  0\n",
      "Test accuracy:  92.6\n",
      "       \n",
      "Test-Accuracy  i :  1\n",
      "Test accuracy:  93.82\n",
      "       \n",
      "Test-Accuracy  i :  2\n",
      "Test accuracy:  93.28\n",
      "       \n",
      "Test-Accuracy  i :  3\n",
      "Test accuracy:  93.66\n",
      "       \n",
      "Test-Accuracy  i :  4\n",
      "Test accuracy:  93.52\n",
      "       \n",
      "Test-Accuracy  i :  5\n",
      "Test accuracy:  93.5\n",
      "       \n",
      "Test-Accuracy  i :  6\n",
      "Test accuracy:  93.42\n",
      "       \n",
      "Test-Accuracy  i :  7\n",
      "Test accuracy:  92.86\n",
      "       \n",
      "Test-Accuracy  i :  8\n",
      "Test accuracy:  93.26\n",
      "       \n",
      "Test-Accuracy  i :  9\n",
      "Test accuracy:  93.16\n",
      "       \n",
      "Test-Accuracy  i :  10\n",
      "Test accuracy:  93.28\n",
      "       \n",
      "Test-Accuracy  i :  11\n",
      "Test accuracy:  92.72\n",
      "       \n",
      "-----VALIDIDATION------\n",
      "Valid-Accuracy  i :  0\n",
      "Valid accuracy:  93.62\n",
      "        \n",
      "Valid-Accuracy  i :  1\n",
      "Valid accuracy:  93.74\n",
      "        \n",
      "Valid-Accuracy  i :  2\n",
      "Valid accuracy:  92.04\n",
      "        \n",
      "Valid-Accuracy  i :  3\n",
      "Valid accuracy:  92.24\n",
      "        \n",
      "-----  FINAL  ------\n",
      "Final Test Set Accuracy :  93.26\n",
      "Final Validation Set Accuracy :  92.91\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    batch = 1000\n",
    "    \n",
    "    test_acc = list()\n",
    "    print('-------TEST--------')\n",
    "    test_no = int(svhn_test_box_labels.shape[0] / batch)\n",
    "    for i in range(test_no - 1):\n",
    "        model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "        data = svhn_test_box_dataset[i*batch:(i+1)*batch]\n",
    "        labels = svhn_test_box_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        test_acc.append(accuracy)\n",
    "        \n",
    "        print('Test-Accuracy', ' i : ', i)\n",
    "        print('Test accuracy: ', accuracy)\n",
    "        print('       ')\n",
    "    \n",
    "    valid_acc = list()\n",
    "    print('-----VALIDIDATION------')\n",
    "    valid_no = int(svhn_valid_box_labels.shape[0] /  batch)\n",
    "    for i in range(valid_no - 1):\n",
    "        model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "        data = svhn_valid_box_dataset[i*batch:(i+1)*batch]\n",
    "        labels = svhn_valid_box_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        valid_acc.append(accuracy)\n",
    "        \n",
    "        print('Valid-Accuracy', ' i : ', i)\n",
    "        print('Valid accuracy: ', accuracy)\n",
    "        print('        ')\n",
    "        \n",
    "        \n",
    "    test_avg = mean(test_acc)\n",
    "    valid_avg = mean(valid_acc)\n",
    "    \n",
    "    print('-----  FINAL  ------')\n",
    "    print('Final Test Set Accuracy : ',\"%.2f\" % test_avg)\n",
    "    print('Final Validation Set Accuracy : ',\"%.2f\" % valid_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (230069, 32, 96, 1)   test :  (230069, 6)\n",
      "Initialized\n",
      "[[[[  4.55973335e-02   1.53596615e-04   5.00065014e-02   1.53114200e-01\n",
      "     -1.94633991e-01   1.69345438e-01]]\n",
      "\n",
      "  [[  2.03227594e-01  -1.21700525e-01   1.57479178e-02   1.93776503e-01\n",
      "     -1.17192507e-01   3.59971933e-02]]\n",
      "\n",
      "  [[  3.92683409e-02   5.16165569e-02   9.49823037e-02   2.46617105e-02\n",
      "     -7.75151774e-02   1.33930728e-01]]\n",
      "\n",
      "  [[ -2.34469771e-02   6.16568476e-02   5.60287125e-02   1.43649548e-01\n",
      "     -1.48194535e-02  -7.61023611e-02]]\n",
      "\n",
      "  [[ -2.96078753e-02  -1.03850670e-01   9.46090743e-02  -1.59331933e-02\n",
      "      7.82122463e-03   6.80771796e-03]]\n",
      "\n",
      "  [[ -1.45946786e-01  -4.58083348e-04   3.16846848e-01   6.82488382e-02\n",
      "      1.25840396e-01  -3.08791772e-02]]]\n",
      "\n",
      "\n",
      " [[[  1.93741888e-01  -4.96291481e-02  -1.62550509e-01   1.23338558e-01\n",
      "      3.02333049e-02   1.34490475e-01]]\n",
      "\n",
      "  [[  6.05372079e-02  -1.62835959e-02  -9.73284990e-02  -3.60536650e-02\n",
      "     -1.41874477e-02   6.84804320e-02]]\n",
      "\n",
      "  [[  7.25641754e-03   2.14329325e-02   9.04426351e-02   1.15373433e-01\n",
      "      1.18342951e-01   6.39736950e-02]]\n",
      "\n",
      "  [[ -9.80572999e-02   8.35123211e-02  -1.02392614e-01   7.91559070e-02\n",
      "     -1.11955246e-02  -3.56572792e-02]]\n",
      "\n",
      "  [[  4.78937738e-02   6.41986430e-02   1.42176002e-01   1.98785216e-01\n",
      "      7.86201358e-02  -6.69335127e-02]]\n",
      "\n",
      "  [[ -9.85533372e-02   2.08620243e-02   2.11086527e-01  -4.84881587e-02\n",
      "      1.16807617e-01   4.86408994e-02]]]\n",
      "\n",
      "\n",
      " [[[  3.73908170e-02  -1.90541849e-01   5.76743633e-02  -1.01009756e-01\n",
      "      1.57499984e-01   1.03858009e-01]]\n",
      "\n",
      "  [[  3.54504911e-03  -2.79520210e-02  -2.35128164e-01   8.39917436e-02\n",
      "      1.60324574e-01  -9.40103829e-03]]\n",
      "\n",
      "  [[  1.30445912e-01  -2.00236067e-02  -1.99461043e-01  -1.30187467e-01\n",
      "      1.49844989e-01  -2.35372633e-01]]\n",
      "\n",
      "  [[ -3.65113094e-02   1.68263575e-03  -7.50575662e-02   9.13476646e-02\n",
      "      1.07226476e-01  -8.53608772e-02]]\n",
      "\n",
      "  [[ -1.28706852e-02   1.02930583e-01  -7.39182979e-02   7.82667771e-02\n",
      "     -5.77090010e-02  -9.31718573e-02]]\n",
      "\n",
      "  [[ -4.02438343e-02   1.70729697e-01  -7.74164945e-02   1.12615258e-01\n",
      "      6.62388504e-02   2.32636780e-02]]]\n",
      "\n",
      "\n",
      " [[[  8.75546038e-02  -1.06762446e-01  -6.71737939e-02  -1.43518940e-01\n",
      "      2.28601739e-01   1.39475241e-01]]\n",
      "\n",
      "  [[  1.28797919e-01  -2.02118069e-01  -7.10432082e-02  -9.36808512e-02\n",
      "      2.03819886e-01  -1.12298377e-01]]\n",
      "\n",
      "  [[ -3.72495432e-03   3.55947344e-03  -6.41751513e-02  -1.26838207e-01\n",
      "      9.85002890e-02  -1.79385066e-01]]\n",
      "\n",
      "  [[  8.51317644e-02   2.14750707e-01  -1.86109543e-01   1.22743458e-01\n",
      "      7.90771395e-02  -2.15512469e-01]]\n",
      "\n",
      "  [[ -3.58452909e-02   2.93216288e-01  -2.66738515e-03  -1.18878223e-01\n",
      "     -8.63020048e-02  -3.05106193e-01]]\n",
      "\n",
      "  [[ -9.56001356e-02   2.24187359e-01   1.83120649e-02   3.86097915e-02\n",
      "     -1.90978721e-01   7.83339441e-02]]]\n",
      "\n",
      "\n",
      " [[[  5.43409586e-02  -2.84017563e-01   1.57372430e-01   1.33507503e-02\n",
      "      9.61536467e-02   6.80773929e-02]]\n",
      "\n",
      "  [[  5.38587719e-02  -1.12490676e-01  -3.56352851e-02  -1.14394367e-01\n",
      "     -8.04610103e-02   7.72130415e-02]]\n",
      "\n",
      "  [[  2.48699971e-02   1.30545702e-02  -1.09431617e-01  -1.13922410e-01\n",
      "     -5.90244085e-02  -1.10958382e-01]]\n",
      "\n",
      "  [[  3.61374468e-02  -5.44142239e-02  -5.16826138e-02  -4.72178087e-02\n",
      "     -2.11681694e-01  -1.53398052e-01]]\n",
      "\n",
      "  [[  8.87519047e-02   7.78095052e-02  -1.64958276e-02   7.20944852e-02\n",
      "     -2.48298317e-01  -1.44741714e-01]]\n",
      "\n",
      "  [[  1.48034804e-02   1.34033248e-01   1.48736602e-02   1.14087798e-01\n",
      "     -1.22525066e-01  -1.30368665e-01]]]\n",
      "\n",
      "\n",
      " [[[ -1.50856361e-01  -1.73359647e-01   2.09181279e-01  -1.25683704e-02\n",
      "     -7.42373988e-02   2.02592507e-01]]\n",
      "\n",
      "  [[  1.50725141e-01  -6.90750182e-02  -4.84333448e-02  -2.33944077e-02\n",
      "     -1.00995928e-01   1.10269688e-01]]\n",
      "\n",
      "  [[  7.78776258e-02   3.87588292e-02   4.64476570e-02  -7.99805764e-03\n",
      "     -6.94089904e-02  -2.35132858e-01]]\n",
      "\n",
      "  [[  1.15903830e-02   8.32113400e-02  -1.05608992e-01  -8.49233568e-02\n",
      "     -1.55195773e-01   6.03337474e-02]]\n",
      "\n",
      "  [[  3.26046310e-02   4.12108339e-02   9.33423266e-02  -2.24104807e-01\n",
      "     -1.58807896e-02  -6.55073449e-02]]\n",
      "\n",
      "  [[  2.35343888e-01   1.65164366e-01  -2.03133617e-02  -8.92245024e-02\n",
      "      8.16129148e-02  -4.13066857e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_box_dataset\n",
    "label_data = svhn_train_box_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 25001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "    print('Initialized')\n",
    "    \n",
    "    W1 = session.run(W1)\n",
    "    print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (125000, 32, 96, 1)   test :  (125000, 6)\n",
      "Initialized\n",
      "W :  [ 0.1957577   0.19950426  0.19999866  0.19999957]\n",
      "b :  [ 0.1  0.1  0.1  0.1]\n",
      "Loss at step 0: 15.812104\n",
      "Minibatch accuracy: 3.4%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.20176931  0.20336588  0.21233326  0.21602039]\n",
      "b :  [ 0.09924942  0.11802243  0.11003009  0.11306362]\n",
      "Loss at step 500: 6.913124\n",
      "Minibatch accuracy: 53.9%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n",
      "W :  [ 0.20172596  0.20614482  0.21922968  0.232022  ]\n",
      "b :  [ 0.10019359  0.12345539  0.11821508  0.1157744 ]\n",
      "Loss at step 1000: 6.926769\n",
      "Minibatch accuracy: 54.4%\n",
      "Learning rate :  0.00042749230123119273\n",
      "    \n",
      "W :  [ 0.20099458  0.20611057  0.22664881  0.24046591]\n",
      "b :  [ 0.10177581  0.12987101  0.11949582  0.11835108]\n",
      "Loss at step 1500: 6.856278\n",
      "Minibatch accuracy: 53.8%\n",
      "Learning rate :  0.00039632728827268716\n",
      "    \n",
      "W :  [ 0.19851771  0.20685558  0.23405121  0.24046807]\n",
      "b :  [ 0.10594938  0.12891285  0.12108289  0.11941691]\n",
      "Loss at step 2000: 6.854865\n",
      "Minibatch accuracy: 54.5%\n",
      "Learning rate :  0.00036812801841425575\n",
      "    \n",
      "W :  [ 0.19885743  0.20673087  0.22454622  0.24046807]\n",
      "b :  [ 0.10078057  0.12566251  0.12178466  0.11941747]\n",
      "Loss at step 2500: 6.712354\n",
      "Minibatch accuracy: 56.1%\n",
      "Learning rate :  0.0003426122638850534\n",
      "    \n",
      "W :  [ 0.19806634  0.20684935  0.22336483  0.24046807]\n",
      "b :  [ 0.10074405  0.12759718  0.12241045  0.11941747]\n",
      "Loss at step 3000: 6.828880\n",
      "Minibatch accuracy: 55.6%\n",
      "Learning rate :  0.00031952465443761056\n",
      "    \n",
      "Training Complete on SVHN Data\n",
      "Model saved in file: saved_models/multi/CNN_SVHN_New.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_dataset_1\n",
    "label_data = svhn_train_labels_1\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 3001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/multi/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "[[[[ 0.06091791  0.0327538  -0.19416073 -0.01676372  0.02233364 -0.02901404]]\n",
      "\n",
      "  [[-0.04115827 -0.00266697  0.10546505  0.03128034 -0.02302971  0.03785209]]\n",
      "\n",
      "  [[ 0.02321358 -0.08577943 -0.07981791  0.19747455 -0.06205473  0.06701094]]\n",
      "\n",
      "  [[-0.02935915 -0.09522378  0.05649186  0.08751354 -0.05960583 -0.07666398]]\n",
      "\n",
      "  [[-0.14650303  0.17145529 -0.00110248  0.04165018  0.01372952  0.02088568]]\n",
      "\n",
      "  [[ 0.01313367  0.00348472 -0.12836632  0.01750273 -0.06433355 -0.1076489 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.01552692  0.19806165  0.01933289 -0.14826033 -0.04317336 -0.09452876]]\n",
      "\n",
      "  [[ 0.04372241 -0.17828043  0.10888292  0.01148719 -0.05250533 -0.02962187]]\n",
      "\n",
      "  [[-0.00225709 -0.13161032 -0.05115749  0.03142713  0.173245   -0.01677104]]\n",
      "\n",
      "  [[-0.15817691 -0.09034646 -0.07150197 -0.16240661  0.06633522  0.05496876]]\n",
      "\n",
      "  [[ 0.01151476 -0.12420844  0.02609648  0.12235687  0.0465115  -0.04505098]]\n",
      "\n",
      "  [[ 0.0315448   0.05198722 -0.04371455  0.01141434  0.14327204  0.00390389]]]\n",
      "\n",
      "\n",
      " [[[ 0.03091958  0.07570969 -0.02342565 -0.03872439 -0.04015407 -0.08602554]]\n",
      "\n",
      "  [[ 0.02378318 -0.08907981 -0.15645039  0.06542825  0.09423941 -0.10839536]]\n",
      "\n",
      "  [[ 0.02070081  0.01333255  0.0449475   0.09415334 -0.03849457 -0.02886223]]\n",
      "\n",
      "  [[ 0.00760063  0.06761961  0.00117242  0.13430864  0.04532625  0.16775081]]\n",
      "\n",
      "  [[-0.16506451  0.19178335 -0.01929418  0.13293149 -0.06950808 -0.03165402]]\n",
      "\n",
      "  [[ 0.18326561  0.0484001  -0.07809924  0.00830957 -0.11867001  0.05960385]]]\n",
      "\n",
      "\n",
      " [[[-0.03748919  0.034536   -0.09154861  0.08603668  0.14596036  0.03997054]]\n",
      "\n",
      "  [[-0.10398785 -0.01502437 -0.04771554  0.03199447  0.15158996 -0.00840558]]\n",
      "\n",
      "  [[-0.10634744  0.02363387 -0.08033192  0.08695528 -0.0052344   0.02523604]]\n",
      "\n",
      "  [[ 0.11331021  0.07645024  0.03870131  0.11845255  0.09248876 -0.05609425]]\n",
      "\n",
      "  [[ 0.14758033 -0.05645988 -0.06595926  0.08367525 -0.1014366   0.03099165]]\n",
      "\n",
      "  [[-0.08419337  0.11256319  0.08401316  0.08168194  0.09528156  0.00709938]]]\n",
      "\n",
      "\n",
      " [[[-0.17133284 -0.03409197  0.05551128 -0.13806874  0.01626393 -0.02226449]]\n",
      "\n",
      "  [[ 0.03684654  0.1077869  -0.12631294 -0.07464807  0.01916724 -0.10269179]]\n",
      "\n",
      "  [[ 0.00852831  0.04899293  0.14605917 -0.00403936 -0.084778    0.10300333]]\n",
      "\n",
      "  [[-0.00663539 -0.07487232  0.03070545  0.1060371  -0.11604117  0.00386443]]\n",
      "\n",
      "  [[ 0.17946935 -0.06679755  0.0892888   0.07371145  0.13549356 -0.0099855 ]]\n",
      "\n",
      "  [[ 0.05488029  0.0880746   0.10262068 -0.18100721 -0.10969175 -0.11322756]]]\n",
      "\n",
      "\n",
      " [[[-0.04615289 -0.02808108  0.08740799  0.02018475  0.0933042  -0.05140632]]\n",
      "\n",
      "  [[-0.0463795  -0.10210032 -0.01816775 -0.12486283 -0.0418921   0.16506787]]\n",
      "\n",
      "  [[-0.01717398  0.01700228 -0.01106519 -0.08680537 -0.07057849 -0.13027653]]\n",
      "\n",
      "  [[ 0.06206699  0.00820066 -0.02102993  0.05635266 -0.01888345  0.03008891]]\n",
      "\n",
      "  [[ 0.07795174 -0.01799627 -0.01332367  0.01182583  0.12691803 -0.02683318]]\n",
      "\n",
      "  [[ 0.03023325  0.17112572  0.04509779  0.14706104  0.06975733  0.05051372]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/multi/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    print(session.run(W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_17', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-e7059acaa63f>\", line 91, in <module>\n    model_saver = tf.train.Saver(var_list)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ce56aeb21563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_svhn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saved_models/box/CNN_SVHNox_.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1388\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_17', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-e7059acaa63f>\", line 91, in <module>\n    model_saver = tf.train.Saver(var_list)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for saved_models/box/CNN_SVHNox_.ckpt\n\t [[Node: save/RestoreV2_17 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_17/tensor_names, save/RestoreV2_17/shape_and_slices)]]\n\t [[Node: save/RestoreV2_12/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_140_save/RestoreV2_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/box/CNN_SVHNox_.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    print(session.run([W1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/multi/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_test_dataset[:500], Y_ : svhn_test_labels[:500], pkeep : 1.0, alpha : 0.002})\n",
    "    print('Test accuracy: ', acc(predictions, svhn_test_labels[:500,1:6]))\n",
    "    \n",
    "    del l, predictions\n",
    "    _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_valid_dataset, Y_ : svhn_valid_labels, pkeep : 1.0, alpha : 0.002})\n",
    "    print('Validation accuracy: ', acc(predictions, svhn_valid_labels[:,1:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (125000, 32, 96, 1)   test :  (125000, 6)\n",
      "Model restored.\n",
      "Initialized\n",
      "W :  [ 0.41171086  0.69925141  0.47237745  0.7207135 ]\n",
      "b :  [ 0.53505075  0.31870961  0.45383301  0.12280813]\n",
      "Loss at step 0: 54.654106\n",
      "Minibatch accuracy: 16.9%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.42643231  0.70004612  0.46439368  0.71949875]\n",
      "b :  [ 0.53378701  0.31939578  0.45481381  0.12296873]\n",
      "Loss at step 500: 8.034361\n",
      "Minibatch accuracy: 52.0%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-74598fca8e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = svhn_train_dataset_1\n",
    "label_data = svhn_train_labels_1\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 20001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "#     tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/combined/CNN_SVHN_Mix.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
