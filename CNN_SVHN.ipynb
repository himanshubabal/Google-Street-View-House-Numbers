{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33401, 32, 96, 3)\n",
      "(33401, 6)\n",
      "(13068, 32, 96, 3)\n",
      "(13068, 6)\n"
     ]
    }
   ],
   "source": [
    "pickle_train = 'SVHN_new_inter_train.pickle'\n",
    "with open(pickle_train, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    svhn_train_dataset = save['train_images']\n",
    "    svhn_train_labels = save['train_labels']\n",
    "    del save\n",
    "    \n",
    "    print(svhn_train_dataset.shape)\n",
    "    print(svhn_train_labels.shape)\n",
    "    \n",
    "    \n",
    "pickle_train = 'SVHN_new_inter_test.pickle'\n",
    "with open(pickle_train, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    svhn_test_dataset = save['test_images']\n",
    "    svhn_test_labels = save['test_labels']\n",
    "    del save\n",
    "    \n",
    "    print(svhn_test_dataset.shape)\n",
    "    print(svhn_test_labels.shape)\n",
    "    \n",
    "    \n",
    "svhn_train_labels = (svhn_train_labels.astype(np.int32))\n",
    "svhn_test_labels = (svhn_test_labels.astype(np.int32))\n",
    "# svhn_valid_labels = (svhn_valid_labels.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "#     X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 3])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 5 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 12     # First Conv Layer with depth 6\n",
    "    L = 24     # Second Conv Layer with depth 12\n",
    "    M = 48    # Third Conv layer with depth 24\n",
    "    N = 300   # Fourth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1))    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1))\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]))\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1))\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]))\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1))\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]))\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1))\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]))\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1))\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]))\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1))\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]))\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1))\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]))\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 28x140\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 14x70\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 7x35\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1))\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    YY4 = tf.nn.dropout(Y4, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(YY4, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(YY4, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(YY4, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(YY4, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(YY4, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "  \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-ce8f2c284a6d>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Loss at step 0: 4285.546387\n",
      "Minibatch accuracy: 6.9%\n",
      "Learning rate :  0.003\n",
      "    \n",
      "Loss at step 500: 5.773893\n",
      "Minibatch accuracy: 64.4%\n",
      "Learning rate :  0.002358522270907074\n",
      "    \n",
      "Loss at step 1000: 5.554959\n",
      "Minibatch accuracy: 64.2%\n",
      "Learning rate :  0.0018589389131666372\n",
      "    \n",
      "Loss at step 1500: 4.282089\n",
      "Minibatch accuracy: 71.4%\n",
      "Learning rate :  0.0014698630029489428\n",
      "    \n",
      "Loss at step 2000: 4.120118\n",
      "Minibatch accuracy: 73.8%\n",
      "Learning rate :  0.0011668503793971828\n",
      "    \n",
      "Loss at step 2500: 3.730647\n",
      "Minibatch accuracy: 75.2%\n",
      "Learning rate :  0.0009308639108945514\n",
      "    \n",
      "Loss at step 3000: 2.842067\n",
      "Minibatch accuracy: 80.8%\n",
      "Learning rate :  0.0007470774644304465\n",
      "    \n",
      "Loss at step 3500: 2.717951\n",
      "Minibatch accuracy: 82.2%\n",
      "Learning rate :  0.000603944436006291\n",
      "    \n",
      "Loss at step 4000: 2.516369\n",
      "Minibatch accuracy: 84.1%\n",
      "Learning rate :  0.0004924723213861769\n",
      "    \n",
      "Loss at step 4500: 2.761705\n",
      "Minibatch accuracy: 82.7%\n",
      "Learning rate :  0.00040565775122940656\n",
      "    \n",
      "Loss at step 5000: 2.236223\n",
      "Minibatch accuracy: 85.3%\n",
      "Learning rate :  0.00033804649600930654\n",
      "    \n",
      "Loss at step 5500: 2.134656\n",
      "Minibatch accuracy: 86.9%\n",
      "Learning rate :  0.00028539079749945195\n",
      "    \n",
      "Loss at step 6000: 2.501324\n",
      "Minibatch accuracy: 83.0%\n",
      "Learning rate :  0.00024438249826680544\n",
      "    \n",
      "Loss at step 6500: 1.841242\n",
      "Minibatch accuracy: 87.7%\n",
      "Learning rate :  0.00021244520271199385\n",
      "    \n",
      "Loss at step 7000: 1.797665\n",
      "Minibatch accuracy: 87.7%\n",
      "Learning rate :  0.00018757241192472366\n",
      "    \n",
      "Loss at step 7500: 1.707917\n",
      "Minibatch accuracy: 88.6%\n",
      "Learning rate :  0.00016820146298242642\n",
      "    \n",
      "Loss at step 8000: 1.360022\n",
      "Minibatch accuracy: 92.2%\n",
      "Learning rate :  0.00015311535277732913\n",
      "    \n",
      "Loss at step 8500: 1.519918\n",
      "Minibatch accuracy: 90.5%\n",
      "Learning rate :  0.00014136627833609785\n",
      "    \n",
      "Loss at step 9000: 1.660242\n",
      "Minibatch accuracy: 90.3%\n",
      "Learning rate :  0.0001322160899609027\n",
      "    \n",
      "Loss at step 9500: 1.584322\n",
      "Minibatch accuracy: 89.2%\n",
      "Learning rate :  0.00012508991608904985\n",
      "    \n",
      "Loss at step 10000: 1.799592\n",
      "Minibatch accuracy: 89.2%\n",
      "Learning rate :  0.00011954004629734786\n",
      "    \n",
      "Loss at step 10500: 1.808714\n",
      "Minibatch accuracy: 87.8%\n",
      "Learning rate :  0.00011521780335762602\n",
      "    \n",
      "Loss at step 11000: 1.513886\n",
      "Minibatch accuracy: 89.7%\n",
      "Learning rate :  0.0001118516371715458\n",
      "    \n",
      "Loss at step 11500: 1.273423\n",
      "Minibatch accuracy: 91.2%\n",
      "Learning rate :  0.00010923006430987804\n",
      "    \n",
      "Loss at step 12000: 1.331929\n",
      "Minibatch accuracy: 91.6%\n",
      "Learning rate :  0.00010718838131233245\n",
      "    \n",
      "Loss at step 12500: 0.885642\n",
      "Minibatch accuracy: 94.2%\n",
      "Learning rate :  0.00010559831699506036\n",
      "    \n",
      "Loss at step 13000: 1.348131\n",
      "Minibatch accuracy: 91.6%\n",
      "Learning rate :  0.00010435997365963497\n",
      "    \n",
      "Loss at step 13500: 1.379176\n",
      "Minibatch accuracy: 90.8%\n",
      "Learning rate :  0.00010339555090029441\n",
      "    \n",
      "Loss at step 14000: 1.301196\n",
      "Minibatch accuracy: 90.6%\n",
      "Learning rate :  0.00010264445770010811\n",
      "    \n",
      "Loss at step 14500: 1.206395\n",
      "Minibatch accuracy: 92.2%\n",
      "Learning rate :  0.0001020595057276434\n",
      "    \n",
      "Loss at step 15000: 1.233013\n",
      "Minibatch accuracy: 90.2%\n",
      "Learning rate :  0.00010160394467342873\n",
      "    \n",
      "Loss at step 15500: 0.751807\n",
      "Minibatch accuracy: 94.8%\n",
      "Learning rate :  0.0001012491533676695\n",
      "    \n",
      "Loss at step 16000: 1.216066\n",
      "Minibatch accuracy: 92.7%\n",
      "Learning rate :  0.0001009728416209173\n",
      "    \n",
      "Loss at step 16500: 1.001580\n",
      "Minibatch accuracy: 93.4%\n",
      "Learning rate :  0.00010075764981617484\n",
      "    \n",
      "Loss at step 17000: 1.057734\n",
      "Minibatch accuracy: 93.3%\n",
      "Learning rate :  0.00010059005827013088\n",
      "    \n",
      "Loss at step 17500: 0.937373\n",
      "Minibatch accuracy: 94.1%\n",
      "Learning rate :  0.00010045953784283568\n",
      "    \n",
      "Loss at step 18000: 0.979980\n",
      "Minibatch accuracy: 93.0%\n",
      "Learning rate :  0.00010035788843185138\n",
      "    \n",
      "Loss at step 18500: 0.979809\n",
      "Minibatch accuracy: 93.3%\n",
      "Learning rate :  0.00010027872379097804\n",
      "    \n",
      "Loss at step 19000: 0.927008\n",
      "Minibatch accuracy: 93.1%\n",
      "Learning rate :  0.00010021707030667433\n",
      "    \n",
      "Loss at step 19500: 0.910485\n",
      "Minibatch accuracy: 93.6%\n",
      "Learning rate :  0.00010016905452481952\n",
      "    \n",
      "Loss at step 20000: 0.957740\n",
      "Minibatch accuracy: 92.2%\n",
      "Learning rate :  0.00010013165979631121\n",
      "    \n",
      "Loss at step 20500: 0.765125\n",
      "Minibatch accuracy: 95.8%\n",
      "Learning rate :  0.00010010253675246619\n",
      "    \n",
      "Loss at step 21000: 0.863332\n",
      "Minibatch accuracy: 94.8%\n",
      "Learning rate :  0.00010007985570311427\n",
      "    \n",
      "Loss at step 21500: 0.784536\n",
      "Minibatch accuracy: 95.0%\n",
      "Learning rate :  0.00010006219168411811\n",
      "    \n",
      "Loss at step 22000: 0.642847\n",
      "Minibatch accuracy: 95.9%\n",
      "Learning rate :  0.00010004843493229172\n",
      "    \n",
      "Loss at step 22500: 0.952339\n",
      "Minibatch accuracy: 93.8%\n",
      "Learning rate :  0.0001000377211631968\n",
      "    \n",
      "Loss at step 23000: 0.887079\n",
      "Minibatch accuracy: 95.0%\n",
      "Learning rate :  0.00010002937727143603\n",
      "    \n",
      "Loss at step 23500: 0.616913\n",
      "Minibatch accuracy: 96.1%\n",
      "Learning rate :  0.00010002287904199889\n",
      "    \n",
      "Loss at step 24000: 0.764648\n",
      "Minibatch accuracy: 95.0%\n",
      "Learning rate :  0.00010001781821582466\n",
      "    \n",
      "Loss at step 24500: 0.775870\n",
      "Minibatch accuracy: 95.3%\n",
      "Learning rate :  0.00010001387684043718\n",
      "    \n",
      "Loss at step 25000: 0.837563\n",
      "Minibatch accuracy: 94.5%\n",
      "Learning rate :  0.00010001080729419903\n",
      "    \n",
      "Loss at step 25500: 0.624855\n",
      "Minibatch accuracy: 96.1%\n",
      "Learning rate :  0.00010000841672918509\n",
      "    \n",
      "Loss at step 26000: 0.825016\n",
      "Minibatch accuracy: 95.6%\n",
      "Learning rate :  0.00010000655495528025\n",
      "    \n",
      "Loss at step 26500: 0.567886\n",
      "Minibatch accuracy: 96.6%\n",
      "Learning rate :  0.00010000510500430526\n",
      "    \n",
      "Loss at step 27000: 0.919130\n",
      "Minibatch accuracy: 93.6%\n",
      "Learning rate :  0.00010000397578135052\n",
      "    \n",
      "Loss at step 27500: 0.526987\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.0001000030963416291\n",
      "    \n",
      "Loss at step 28000: 0.564664\n",
      "Minibatch accuracy: 96.4%\n",
      "Learning rate :  0.0001000024114332854\n",
      "    \n",
      "Loss at step 28500: 0.794798\n",
      "Minibatch accuracy: 95.0%\n",
      "Learning rate :  0.000100001878026131\n",
      "    \n",
      "Loss at step 29000: 0.507069\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.00010000146260822146\n",
      "    \n",
      "Loss at step 29500: 0.447293\n",
      "Minibatch accuracy: 97.3%\n",
      "Learning rate :  0.0001000011390804282\n",
      "    \n",
      "Loss at step 30000: 0.587780\n",
      "Minibatch accuracy: 95.8%\n",
      "Learning rate :  0.00010000088711672946\n",
      "    \n",
      "Loss at step 30500: 0.474314\n",
      "Minibatch accuracy: 97.0%\n",
      "Learning rate :  0.00010000069088720359\n",
      "    \n",
      "Loss at step 31000: 0.512533\n",
      "Minibatch accuracy: 96.2%\n",
      "Learning rate :  0.00010000053806349516\n",
      "    \n",
      "Loss at step 31500: 0.521985\n",
      "Minibatch accuracy: 97.5%\n",
      "Learning rate :  0.00010000041904427137\n",
      "    \n",
      "Loss at step 32000: 0.514130\n",
      "Minibatch accuracy: 96.6%\n",
      "Learning rate :  0.00010000032635200669\n",
      "    \n",
      "Loss at step 32500: 0.459265\n",
      "Minibatch accuracy: 97.0%\n",
      "Learning rate :  0.00010000025416319837\n",
      "    \n",
      "Loss at step 33000: 0.475451\n",
      "Minibatch accuracy: 97.2%\n",
      "Learning rate :  0.00010000019794249791\n",
      "    \n",
      "Loss at step 33500: 0.399391\n",
      "Minibatch accuracy: 97.5%\n",
      "Learning rate :  0.00010000015415777238\n",
      "    \n",
      "Loss at step 34000: 0.387262\n",
      "Minibatch accuracy: 97.3%\n",
      "Learning rate :  0.00010000012005819385\n",
      "    \n",
      "Loss at step 34500: 0.480254\n",
      "Minibatch accuracy: 97.5%\n",
      "Learning rate :  0.00010000009350141538\n",
      "    \n",
      "Loss at step 35000: 0.459492\n",
      "Minibatch accuracy: 96.6%\n",
      "Learning rate :  0.00010000007281897552\n",
      "    \n",
      "Loss at step 35500: 0.619103\n",
      "Minibatch accuracy: 96.7%\n",
      "Learning rate :  0.00010000005671147516\n",
      "    \n",
      "Loss at step 36000: 0.361783\n",
      "Minibatch accuracy: 97.0%\n",
      "Learning rate :  0.00010000004416694127\n",
      "    \n",
      "Loss at step 36500: 0.339322\n",
      "Minibatch accuracy: 97.2%\n",
      "Learning rate :  0.00010000003439724844\n",
      "    \n",
      "Loss at step 37000: 0.368886\n",
      "Minibatch accuracy: 98.0%\n",
      "Learning rate :  0.00010000002678860403\n",
      "    \n",
      "Loss at step 37500: 0.390833\n",
      "Minibatch accuracy: 97.2%\n",
      "Learning rate :  0.0001000000208629858\n",
      "    \n",
      "Loss at step 38000: 0.344686\n",
      "Minibatch accuracy: 97.7%\n",
      "Learning rate :  0.00010000001624810967\n",
      "    \n",
      "Loss at step 38500: 0.529362\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.00010000001265404054\n",
      "    \n",
      "Loss at step 39000: 0.346302\n",
      "Minibatch accuracy: 97.7%\n",
      "Learning rate :  0.00010000000985497668\n",
      "    \n",
      "Loss at step 39500: 0.334197\n",
      "Minibatch accuracy: 97.8%\n",
      "Learning rate :  0.00010000000767506355\n",
      "    \n",
      "Loss at step 40000: 0.278247\n",
      "Minibatch accuracy: 98.6%\n",
      "Learning rate :  0.00010000000597734551\n",
      "    \n",
      "Loss at step 40500: 0.430428\n",
      "Minibatch accuracy: 97.3%\n",
      "Learning rate :  0.00010000000465516137\n",
      "    \n",
      "Loss at step 41000: 0.469652\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.00010000000362544332\n",
      "    \n",
      "Loss at step 41500: 0.415852\n",
      "Minibatch accuracy: 97.7%\n",
      "Learning rate :  0.0001000000028234981\n",
      "    \n",
      "Loss at step 42000: 0.458604\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.00010000000219894253\n",
      "    \n",
      "Loss at step 42500: 0.447268\n",
      "Minibatch accuracy: 97.2%\n",
      "Learning rate :  0.00010000000171253817\n",
      "    \n",
      "Loss at step 43000: 0.371933\n",
      "Minibatch accuracy: 97.8%\n",
      "Learning rate :  0.00010000000133372606\n",
      "    \n",
      "Loss at step 43500: 0.434982\n",
      "Minibatch accuracy: 97.5%\n",
      "Learning rate :  0.0001000000010387069\n",
      "    \n",
      "Loss at step 44000: 0.480792\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.00010000000080894576\n",
      "    \n",
      "Loss at step 44500: 0.273549\n",
      "Minibatch accuracy: 98.8%\n",
      "Learning rate :  0.00010000000063000758\n",
      "    \n",
      "Loss at step 45000: 0.308226\n",
      "Minibatch accuracy: 98.1%\n",
      "Learning rate :  0.0001000000004906504\n",
      "    \n",
      "Loss at step 45500: 0.317843\n",
      "Minibatch accuracy: 98.4%\n",
      "Learning rate :  0.00010000000038211892\n",
      "    \n",
      "Loss at step 46000: 0.487648\n",
      "Minibatch accuracy: 96.9%\n",
      "Learning rate :  0.00010000000029759451\n",
      "    \n",
      "Loss at step 46500: 0.244022\n",
      "Minibatch accuracy: 99.1%\n",
      "Learning rate :  0.00010000000023176684\n",
      "    \n",
      "Loss at step 47000: 0.414905\n",
      "Minibatch accuracy: 97.8%\n",
      "Learning rate :  0.0001000000001805002\n",
      "    \n",
      "Loss at step 47500: 0.364742\n",
      "Minibatch accuracy: 98.0%\n",
      "Learning rate :  0.0001000000001405737\n",
      "    \n",
      "Loss at step 48000: 0.275093\n",
      "Minibatch accuracy: 98.6%\n",
      "Learning rate :  0.0001000000001094789\n",
      "    \n",
      "Loss at step 48500: 0.389388\n",
      "Minibatch accuracy: 97.7%\n",
      "Learning rate :  0.00010000000008526226\n",
      "    \n",
      "Loss at step 49000: 0.249776\n",
      "Minibatch accuracy: 98.8%\n",
      "Learning rate :  0.00010000000006640232\n",
      "    \n",
      "Loss at step 49500: 0.267333\n",
      "Minibatch accuracy: 98.1%\n",
      "Learning rate :  0.00010000000005171417\n",
      "    \n",
      "Loss at step 50000: 0.288693\n",
      "Minibatch accuracy: 98.3%\n",
      "Learning rate :  0.00010000000004027504\n",
      "    \n",
      "Training Complete on SVHN Data\n",
      "Model saved in file: saved_models/CNN_SVHN_New.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps_1 = 50001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    tf.initialize_all_variables().run() \n",
    "#     tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.003\n",
    "        min_learning_rate = 0.0001\n",
    "        decay_speed = 2000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "\n",
    "        offset = (step * batch_size) % (svhn_train_labels.shape[0] - batch_size)\n",
    "        batch_data = svhn_train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = svhn_train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred = session.run([train_step, cross_entropy, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "        if (step % 500 == 0): \n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on SVHN Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, \"saved_models/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "#     _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_test_dataset, Y_ : svhn_test_labels, pkeep : 1.0, alpha : 0.002})\n",
    "#     print('Test accuracy: ', acc(predictions, svhn_test_labels[:,1:6]))\n",
    "    \n",
    "#     _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_valid_dataset, Y_ : svhn_valid_labels, pkeep : 1.0, alpha : 0.002})\n",
    "#     print('Validation accuracy: ', acc(predictions, svhn_valid_labels[:,1:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[13068,33,97,1]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_137, Variable/read)]]\n\t [[Node: add_12/_181 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_465_add_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-b512987cf6e8>\", line 51, in <module>\n    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[13068,33,97,1]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_137, Variable/read)]]\n\t [[Node: add_12/_181 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_465_add_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[13068,33,97,1]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_137, Variable/read)]]\n\t [[Node: add_12/_181 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_465_add_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b40cc4874364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msvhn_test_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msvhn_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.002\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_test_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[13068,33,97,1]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_137, Variable/read)]]\n\t [[Node: add_12/_181 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_465_add_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-b512987cf6e8>\", line 51, in <module>\n    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[13068,33,97,1]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_0/_137, Variable/read)]]\n\t [[Node: add_12/_181 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_465_add_12\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"saved_models/CNN_SVHN_New.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "    \n",
    "    _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_test_dataset, Y_ : svhn_test_labels, pkeep : 1.0, alpha : 0.002})\n",
    "    print('Test accuracy: ', acc(predictions, svhn_test_labels[:,1:6]))\n",
    "    \n",
    "#     _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : svhn_valid_dataset, Y_ : svhn_valid_labels, pkeep : 1.0, alpha : 0.002})\n",
    "#     print('Validation accuracy: ', acc(predictions, svhn_valid_labels[:,1:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
