{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from download_helper.path import data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf_file = data_dir + 'svhn_raw/SVHN.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "\n",
    "train_images = hdf['train_images'][:]\n",
    "train_labels = hdf['train_labels'][:]\n",
    "train_bboxes = hdf['train_bboxes'][:]\n",
    "\n",
    "test_images = hdf['test_images'][:]\n",
    "test_labels = hdf['test_labels'][:]\n",
    "test_bboxes = hdf['test_bboxes'][:]\n",
    "\n",
    "# valid_images = hdf['valid_images'][:]\n",
    "# valid_labels = hdf['valid_labels'][:]\n",
    "# valid_bboxes = hdf['valid_bboxes'][:]\n",
    "            \n",
    "hdf.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "# valid_images = valid_images.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "# valid_labels = valid_labels.astype(np.int32)\n",
    "\n",
    "train_bboxes = train_bboxes.astype(np.int32)\n",
    "test_bboxes = test_bboxes.astype(np.int32)\n",
    "# valid_bboxes = valid_bboxes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (230000, 64, 64), (230000, 11), (230000, 40))\n",
      "('Test set', (13068, 64, 64), (13068, 11), (13068, 40))\n"
     ]
    }
   ],
   "source": [
    "print('Training set', train_images.shape, train_labels.shape, train_bboxes.shape)\n",
    "print('Test set', test_images.shape, test_labels.shape, test_bboxes.shape)\n",
    "# print('Valid set', valid_images.shape, valid_labels.shape, valid_bboxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rectangle\n",
    "# (x1, y1) & (a1, b2):\n",
    "#          Top Left Corner for\n",
    "#          Rectangle 1 and 2 respectively\n",
    "# (x2, y2) & (a2, b2):\n",
    "#          Top Left Corner for\n",
    "#          Rectangle 1 and 2 respectively\n",
    "def get_iou(x1, y1, x2, y2, a1, b1, a2, b2):\n",
    "    x_overlap = max(0, min(x1 + x2, a1 + a2) - max(x1, a1))\n",
    "    y_overlap = max(0, min(y1 + y2, b1 + b2) - max(y1, b1))\n",
    "    intersection_area = x_overlap * y_overlap\n",
    "    \n",
    "    # areas of both rectangles\n",
    "    area_1 = abs(x2 - x1) * abs(y2 - y1)\n",
    "    area_2 = abs(a2 - a1) * abs(b2 - b1)\n",
    "    # Total (Union) area\n",
    "    union_area = area_1 + area_2 - intersection_area\n",
    "        \n",
    "    iou = (intersection_area * 1.0) / union_area\n",
    "    return(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(x, is_training, iteration, conv=False, offset=0.0, scale=1.0):\n",
    "    \"\"\"\n",
    "    Credits\n",
    "    -------\n",
    "    This code is based on code written by Martin Gorner:\n",
    "    - https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_4.2_batchnorm_convolutional.py\n",
    "    \"\"\"\n",
    "    # adding the iteration prevents from averaging across non-existing iterations\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.9999, iteration)\n",
    "    bnepsilon = 1e-5\n",
    "\n",
    "    # calculate mean and variance for batch of logits\n",
    "    if conv:\n",
    "        mean, variance = tf.nn.moments(x, [0, 1, 2])\n",
    "    else:\n",
    "        # mean and variance along the batch\n",
    "        mean, variance = tf.nn.moments(x, [0])\n",
    "\n",
    "    update_moving_averages = exp_moving_avg.apply([mean, variance])\n",
    "    tf.add_to_collection(\"update_moving_averages\", update_moving_averages)\n",
    "\n",
    "    # Mean and Variance (how it get it is dependent on whether it is training)\n",
    "    # TODO: Change the following to use the `is_trianing` directly without logical_not()\n",
    "    #       to make it more intuitive.\n",
    "    m = tf.cond(tf.logical_not(is_training),\n",
    "                lambda: exp_moving_avg.average(mean),\n",
    "                lambda: mean)\n",
    "    v = tf.cond(tf.logical_not(is_training),\n",
    "                lambda: exp_moving_avg.average(variance),\n",
    "                lambda: variance)\n",
    "\n",
    "    # Offset\n",
    "    param_shape = mean.get_shape().as_list()\n",
    "    beta_init = tf.constant_initializer(offset)\n",
    "    beta = tf.Variable(initial_value=beta_init(param_shape), name=\"beta\")\n",
    "\n",
    "    # Scale\n",
    "    gamma_init = tf.constant_initializer(scale)\n",
    "    gamma = tf.Variable(initial_value=gamma_init(param_shape), name=\"gamma\")\n",
    "\n",
    "    # Apply Batch Norm\n",
    "    Ybn = tf.nn.batch_normalization(x, m, v, offset=beta, scale=gamma,\n",
    "                                    variance_epsilon=bnepsilon, name='batchnorm')\n",
    "    return Ybn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, rate=0.01, name=\"leaky_relu\"):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        leak_rate = tf.multiply(x, rate, name=\"leak_rate\")\n",
    "        activation = tf.maximum(x, leak_rate, name=scope)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_pipeline(X_in, in_width, out_width, fltr_conv, stride_conv, is_train, iteration, pkeep, token=1, conv=True):\n",
    "    with tf.name_scope('convolution_' + str(token)):\n",
    "        W = tf.Variable(tf.truncated_normal([fltr_conv, fltr_conv, in_width, out_width], stddev=0.1))    \n",
    "        B = tf.Variable(tf.constant(0.1, tf.float32, [out_width]))\n",
    "\n",
    "        Y_conv = tf.nn.conv2d(X_in, W, strides=[1, stride_conv, stride_conv, 1], padding='SAME') + B\n",
    "        Y_bnorm = batchnorm(Y_conv, is_train, iteration, conv)\n",
    "        Y_drop = tf.nn.dropout(Y_bnorm, pkeep)\n",
    "        Y_relu = leaky_relu(Y_drop)\n",
    "    return(Y_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(x, name=\"flatten_layer\"):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        num_elements = np.product(x.get_shape().as_list()[1:])\n",
    "        x = tf.reshape(x, [-1, num_elements], name=scope)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_pipeline(X_in, num_nodes, is_train, iteration, pkeep, token=1, conv=False):\n",
    "    in_nodes = int(X_in.shape.as_list()[-1])\n",
    "\n",
    "    with tf.name_scope('fully_connected_' + str(token)):\n",
    "        W = tf.Variable(tf.truncated_normal([in_nodes, num_nodes], stddev=0.1))    \n",
    "        B = tf.Variable(tf.constant(0.1, tf.float32, [num_nodes]))\n",
    "\n",
    "        Y_fc = tf.matmul(X_in, W) + B\n",
    "        Y_bn = batchnorm(Y_fc, is_train, iteration, conv)\n",
    "        Y_dp = tf.nn.dropout(Y_bn, keep_prob=pkeep)\n",
    "        Y_lr = leaky_relu(Y_dp, rate=0.01, name=\"relu\")\n",
    "    return(Y_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_digit_loss(logits_list, Y_, max_digits=11, name=\"multi_digit_loss\"):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        # LOSSES FOR EACH DIGIT BRANCH\n",
    "        losses = [None] * (max_digits)\n",
    "        for i in range(max_digits):\n",
    "            losses[i] = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_list[i], labels=Y_[:,i])\n",
    "            \n",
    "        # AVERAGE LOSS\n",
    "        loss = sum(losses) / float(max_digits)\n",
    "        loss = tf.reduce_mean(loss, name=scope)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_path = 'tf_logs/svhn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_digits(predicted_digits, correct_digits):\n",
    "    a = (predicted_digits == correct_digits).mean(axis=0)\n",
    "    \n",
    "    # All correct prediction accuracy\n",
    "    b = (predicted_digits == correct_digits).mean(axis=None)*100\n",
    "#     b = float(str(round(b, 2)))\n",
    "              \n",
    "    # Individual correct prediction accuracy\n",
    "    c = (predicted_digits == correct_digits).all(axis=1).mean()*100\n",
    "              \n",
    "#     c = float(str(round(c, 3)))\n",
    "    return (b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_bboxes(predicted_bboxes, correct_bboxes):    \n",
    "    # Shape of bboxes -> n x 40\n",
    "    n_bboxes = correct_bboxes.shape[1] // 4\n",
    "    n_samples = correct_bboxes.shape[0]\n",
    "    \n",
    "    iou = np.empty(shape=[n_samples, n_bboxes])\n",
    "    \n",
    "    for i in range(n_bboxes):\n",
    "        iou[:,i] = get_batch_iou(predicted_bboxes[:, 4*i: 4+4*i], correct_bboxes[:, 4*i: 4+4*i])\n",
    "    \n",
    "    #                         - - - - - - - - -\n",
    "    # return(iou.mean(axis=0), iou.mean(axis=None), iou.mean(axis=1))\n",
    "    a = iou.mean(axis=None)*100\n",
    "#     a = float(str(round(a, 2)))\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_iou(a, b):\n",
    "    x1 = np.array([a[:, 0], b[:, 0]]).max(axis=0)\n",
    "    y1 = np.array([a[:, 1], b[:, 1]]).max(axis=0)\n",
    "    x2 = np.array([a[:, 2], b[:, 2]]).min(axis=0)\n",
    "    y2 = np.array([a[:, 3], b[:, 3]]).min(axis=0)\n",
    "    \n",
    "    # AREAS OF OVERLAP - Area where the boxes intersect\n",
    "    width = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "    \n",
    "    # handle case where there is NO overlap\n",
    "    width[width < 0] = 0\n",
    "    height[height < 0] = 0\n",
    "    \n",
    "    area_overlap = width * height\n",
    "    \n",
    "    # COMBINED AREAS\n",
    "    area_a = (a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1])\n",
    "    area_b = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "    \n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = area_overlap / (area_combined + 1e-8)\n",
    "    return(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "no_of_digits = 10\n",
    "# 11 digits possible for each place -> 0,1,2,3,4,5,6,7,8,9,10\n",
    "max_possible_var = 11\n",
    "    \n",
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    with tf.name_scope('input'):\n",
    "        # Image\n",
    "        X_ = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH], name='X_input')\n",
    "        X_ = X_ / 255\n",
    "        X = tf.reshape(X_, shape=[-1, HEIGHT, WIDTH, 1], name='X_input_reshaped')\n",
    "        # print('X : ', X.shape.as_list())\n",
    "\n",
    "        # Label\n",
    "        Y_ = tf.placeholder(tf.int32, [None, no_of_digits + 1], name='Labels')\n",
    "        # Bounding Box\n",
    "        Z_ = tf.placeholder(tf.int32, [None, no_of_digits * 4], name='Bboxes')\n",
    "\n",
    "        # Learning Rate - alpha\n",
    "        alpha = tf.placeholder(tf.float32, name='Learning_Rate')\n",
    "        # Dropout (or better : 1 - toDropOut) Probablity\n",
    "        pkeep = tf.placeholder(tf.float32, name='Dropout-pkeep')\n",
    "        # Model trainig or testing\n",
    "        is_train = tf.placeholder(tf.bool, name='Is_Training')\n",
    "        # Iteration\n",
    "        iteration = tf.placeholder(tf.int32, name='Iteration-i')\n",
    "    \n",
    "    # Depth      # Filter   Stride   Size\n",
    "    K = 6        # 3        1        64 x 64 x 6\n",
    "    L = 24       # 3        1        64 x 64 x 24\n",
    "    M = 96       # 5        1        64 x 64 x 96\n",
    "    # MAX POOL   # 3        2        32 x 32 x 24\n",
    "    N = 48       # 3        1        32 x 32 x 48\n",
    "    O = 96       # 5        1        32 x 32 x 96\n",
    "    P = 256      # 3        1        32 x 32 x 256\n",
    "    # MAX POOL   # 3        2        16 x 16 x 256\n",
    "    Q = 256      # 5        1        16 x 16 x 256\n",
    "    J = 256      # 3        1        16 x 16 x 256\n",
    "    # Max Pool   # 3        2         8 x  8 x 256\n",
    "    \n",
    "    # Fully Connected / Dense\n",
    "    R = 4096\n",
    "    S = 4096\n",
    "    T = 512\n",
    "    U = 64\n",
    "    V = 256\n",
    "\n",
    "    \n",
    "    Y1 = conv_pipeline(X,  in_width=1, out_width=K, fltr_conv=3, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=1)    \n",
    "    Y1 = conv_pipeline(Y1, in_width=K, out_width=L, fltr_conv=3, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=2)    \n",
    "    Y1 = conv_pipeline(Y1, in_width=L, out_width=M, fltr_conv=5, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=3)    \n",
    "    \n",
    "    Y1 = tf.nn.max_pool(Y1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='Max_Pool_1')\n",
    "    \n",
    "    Y1 = conv_pipeline(Y1, in_width=M, out_width=N, fltr_conv=3, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=4)    \n",
    "    Y1 = conv_pipeline(Y1, in_width=N, out_width=O, fltr_conv=5, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=5)    \n",
    "    Y1 = conv_pipeline(Y1, in_width=O, out_width=P, fltr_conv=3, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=6)\n",
    "\n",
    "    Y1 = tf.nn.max_pool(Y1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='Max_Pool_2')\n",
    "    \n",
    "    Y1 = conv_pipeline(Y1, in_width=P, out_width=Q, fltr_conv=5, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=7)    \n",
    "    Y1 = conv_pipeline(Y1, in_width=Q, out_width=J, fltr_conv=3, stride_conv=1, is_train=is_train, iteration=iteration, pkeep=pkeep, token=8)    \n",
    "\n",
    "    Y1 = tf.nn.max_pool(Y1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='Max_Pool_3')\n",
    "    \n",
    "    \n",
    "    Y1 = flatten_layer(Y1)\n",
    "    \n",
    "    Y1 = fc_pipeline(Y1, R, is_train, iteration, pkeep, token=1)    \n",
    "    Y1 = fc_pipeline(Y1, S, is_train, iteration, pkeep, token=2)    \n",
    "    Y1 = fc_pipeline(Y1, T, is_train, iteration, pkeep, token=3)\n",
    "    \n",
    "    Y_digits = fc_pipeline(Y1, U, is_train, iteration, pkeep=1.0, token=41)\n",
    "    Y_bboxes = fc_pipeline(Y1, V, is_train, iteration, pkeep=1.0, token=42)\n",
    "    \n",
    "    \n",
    "    d_logits = [None] * (no_of_digits + 1)\n",
    "    for i in range(no_of_digits+1):\n",
    "        d_logits[i] = fc_pipeline(Y_digits, max_possible_var, is_train, iteration, pkeep=1.0, token=410+i)\n",
    "    digits_logits = tf.stack(d_logits, axis=0)\n",
    "    # print(digits_logits.shape.as_list())\n",
    "    \n",
    "    bboxes_logits = fc_pipeline(Y_bboxes, no_of_digits * 4, is_train, iteration, pkeep=1.0, token=421)\n",
    "    # print(bboxes_logits.shape.as_list())\n",
    "    \n",
    "    # print(Y_.shape.as_list())\n",
    "    \n",
    "    with tf.name_scope('loss_function'):\n",
    "        loss_digits = multi_digit_loss(digits_logits, Y_, max_digits=no_of_digits+1, name=\"loss_digits\")\n",
    "        loss_bboxes = tf.sqrt(tf.reduce_mean(tf.square(1 * (bboxes_logits - tf.to_float(Z_)))), name=\"loss_bboxes\")\n",
    "        loss_total = tf.add(loss_bboxes, loss_digits, name=\"loss_total\")\n",
    "    \n",
    "    with tf.name_scope('optimisers'):\n",
    "        optimizer_digit = tf.train.AdamOptimizer(learning_rate=alpha,\n",
    "                                   beta1=0.9, beta2=0.999,\n",
    "                                   epsilon=1e-08,\n",
    "                                   name=\"optimizer_digits\").minimize(loss_digits)\n",
    "\n",
    "        optimizer_box = tf.train.AdamOptimizer(learning_rate=alpha,\n",
    "                                   beta1=0.9, beta2=0.999,\n",
    "                                   epsilon=1e-08,\n",
    "                                   name=\"optimizer_boxes\").minimize(loss_bboxes)\n",
    "    \n",
    "    \n",
    "    digits_preds = tf.transpose(tf.argmax(digits_logits, axis=2))\n",
    "    digits_preds = tf.to_int32(digits_preds, name=\"digit_predictions\")\n",
    "    \n",
    "    bboxes_preds = tf.to_int32(bboxes_logits, name='box_predictions')\n",
    "    \n",
    "    tf.summary.scalar(\"loss_digits\", loss_digits)\n",
    "    tf.summary.scalar(\"loss_bboxes\", loss_bboxes)\n",
    "    tf.summary.scalar(\"loss_total\", loss_total)\n",
    "\n",
    "    model_saver = tf.train.Saver()\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_save = \"saved_models/svhn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (230000, 64, 64), (230000, 11), (230000, 40))\n",
      "('Test set', (13068, 64, 64), (13068, 11), (13068, 40))\n",
      "('Batch Size: ', 128, ' num_steps: ', 1796, ' num_epochs: ', 5)\n",
      "\n",
      "Initalizing...\n",
      "Initialized\n",
      "\n",
      "Accuracy digits - Individual : 8.74%\n",
      "Accuracy digits - All        : 0.00%\n",
      "Accuracy bboxes - All        : 0.25%\n",
      "Loss - Digits                : 2.60%\n",
      "Loss - Bboxes                : 17.57%\n",
      "\n",
      "Accuracy digits - Individual : 64.91%\n",
      "Accuracy digits - All        : 0.78%\n",
      "Accuracy bboxes - All        : 1.49%\n",
      "Loss - Digits                : 1.57%\n",
      "Loss - Bboxes                : 16.84%\n",
      "\n",
      "------------------------------------------\n",
      "Epoch                      ==> 1\n",
      "Accuracy digits - Individual : 53.48%\n",
      "Accuracy digits - All        : 0.00%\n",
      "Accuracy bboxes - All        : 460.80%\n",
      "Loss - Digits                : 1350994190416134685842206202668253184.00%\n",
      "Loss - Bboxes                : inf%\n",
      "------------------------------------------\n",
      "      \n",
      "Accuracy digits - Individual : 77.84%\n",
      "Accuracy digits - All        : 13.28%\n",
      "Accuracy bboxes - All        : 3.46%\n",
      "Loss - Digits                : 1.15%\n",
      "Loss - Bboxes                : 16.84%\n",
      "\n",
      "Accuracy digits - Individual : 83.31%\n",
      "Accuracy digits - All        : 35.16%\n",
      "Accuracy bboxes - All        : 7.19%\n",
      "Loss - Digits                : 0.94%\n",
      "Loss - Bboxes                : 16.26%\n",
      "\n",
      "------------------------------------------\n",
      "Epoch                      ==> 2\n",
      "Accuracy digits - Individual : 48.22%\n",
      "Accuracy digits - All        : 0.00%\n",
      "Accuracy bboxes - All        : 7813001.76%\n",
      "Loss - Digits                : inf%\n",
      "Loss - Bboxes                : inf%\n",
      "------------------------------------------\n",
      "      \n",
      "Accuracy digits - Individual : 87.50%\n",
      "Accuracy digits - All        : 47.66%\n",
      "Accuracy bboxes - All        : 9.50%\n",
      "Loss - Digits                : 0.71%\n",
      "Loss - Bboxes                : 16.27%\n",
      "\n",
      "Accuracy digits - Individual : 89.99%\n",
      "Accuracy digits - All        : 56.25%\n",
      "Accuracy bboxes - All        : 14.81%\n",
      "Loss - Digits                : 0.61%\n",
      "Loss - Bboxes                : 15.72%\n",
      "\n",
      "------------------------------------------\n",
      "Epoch                      ==> 3\n",
      "Accuracy digits - Individual : 47.23%\n",
      "Accuracy digits - All        : 0.00%\n",
      "Accuracy bboxes - All        : 509.88%\n",
      "Loss - Digits                : nan%\n",
      "Loss - Bboxes                : inf%\n",
      "------------------------------------------\n",
      "      \n",
      "Accuracy digits - Individual : 92.33%\n",
      "Accuracy digits - All        : 67.97%\n",
      "Accuracy bboxes - All        : 18.32%\n",
      "Loss - Digits                : 0.47%\n",
      "Loss - Bboxes                : 15.74%\n",
      "\n",
      "Accuracy digits - Individual : 93.25%\n",
      "Accuracy digits - All        : 69.53%\n",
      "Accuracy bboxes - All        : 23.31%\n",
      "Loss - Digits                : 0.42%\n",
      "Loss - Bboxes                : 15.21%\n",
      "\n",
      "------------------------------------------\n",
      "Epoch                      ==> 4\n",
      "Accuracy digits - Individual : 41.62%\n",
      "Accuracy digits - All        : 0.00%\n",
      "Accuracy bboxes - All        : 15625383.13%\n",
      "Loss - Digits                : nan%\n",
      "Loss - Bboxes                : inf%\n",
      "------------------------------------------\n",
      "      \n",
      "Training Complete on SVHN Data\n",
      "Model saved in file: saved_models/svhn/SVHN\n"
     ]
    }
   ],
   "source": [
    "print('Training set', train_images.shape, train_labels.shape, train_bboxes.shape)\n",
    "print('Test set', test_images.shape, test_labels.shape, test_bboxes.shape)\n",
    "# print('Valid set', valid_images.shape, valid_labels.shape, valid_bboxes.shape)\n",
    "\n",
    "batch_size = 128\n",
    "num_steps = int(train_labels.shape[0] / batch_size)\n",
    "num_epochs = 5\n",
    "print('Batch Size: ', batch_size, ' num_steps: ', num_steps, ' num_epochs: ', num_epochs)\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    print('')\n",
    "    print('Initalizing...')\n",
    "    tf.global_variables_initializer().run()\n",
    "    writer = tf.summary.FileWriter(log_path, graph=graph_svhn)\n",
    "    print('Initialized')\n",
    "    print('')\n",
    "    \n",
    "#     valid_i = valid_images[:batch_size]\n",
    "#     valid_l = valid_labels[:batch_size]\n",
    "#     valid_b = valid_bboxes[:batch_size]\n",
    "    \n",
    "    for epoch in range(num_epochs - 1):\n",
    "        test_i = test_images[epoch*batch_size:(epoch+1)*batch_size]\n",
    "        test_l = test_labels[epoch*batch_size:(epoch+1)*batch_size]\n",
    "        test_b = test_bboxes[epoch*batch_size:(epoch+1)*batch_size]\n",
    "        \n",
    "        for step in range(num_steps - 1):\n",
    "            max_learning_rate = 0.0005\n",
    "            min_learning_rate = 0.0001\n",
    "\n",
    "            decay_speed = 5000.0\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "            # learning_rate = 0.0001\n",
    "            \n",
    "            batch_data   = train_images[step*batch_size:(step + 1)*batch_size]\n",
    "            batch_labels = train_labels[step*batch_size:(step + 1)*batch_size]\n",
    "            batch_bboxes = train_bboxes[step*batch_size:(step + 1)*batch_size]\n",
    "                        \n",
    "            feed_dict = {X_ : batch_data, Y_ : batch_labels, Z_ : batch_bboxes, pkeep : 0.90, alpha : learning_rate,\n",
    "                            is_train : True, iteration : step}\n",
    "            \n",
    "            _, _, loss_digit, loss_box, digits, bboxes, summary = session.run([optimizer_digit, optimizer_box, \n",
    "                                                                   loss_digits, loss_bboxes, digits_preds, \n",
    "                                                                   bboxes_preds, summary_op], feed_dict=feed_dict)            \n",
    "            writer.add_summary(summary, step)\n",
    "            \n",
    "            if step % int(num_steps/2) == 0:\n",
    "                print('Accuracy digits - Individual : %.2f%%'% accuracy_digits(digits, batch_labels)[0])\n",
    "                print('Accuracy digits - All        : %.2f%%'% accuracy_digits(digits, batch_labels)[1])\n",
    "                print('Accuracy bboxes - All        : %.2f%%'% accuracy_bboxes(bboxes, batch_bboxes))\n",
    "                print('Loss - Digits                : %.2f%%'% loss_digit)\n",
    "                print('Loss - Bboxes                : %.2f%%'% loss_box)\n",
    "                print('')\n",
    "                \n",
    "                \n",
    "        # Get Test accuracy\n",
    "        print('------------------------------------------')\n",
    "        feed_dict = {X_ : test_i, Y_ : test_l, Z_ : test_b, pkeep : 1.0, alpha : 1e-9,\n",
    "                            is_train : False, iteration : epoch}\n",
    "        loss_digit, loss_box, digits, bboxes = session.run([loss_digits, loss_bboxes, digits_preds, bboxes_preds], feed_dict=feed_dict)\n",
    "        \n",
    "        print('Epoch                      ==> ' + str(epoch + 1))\n",
    "        print('Accuracy digits - Individual : %.2f%%'% accuracy_digits(digits, test_l)[0])\n",
    "        print('Accuracy digits - All        : %.2f%%'% accuracy_digits(digits, test_l)[1])\n",
    "        print('Accuracy bboxes - All        : %.2f%%'% accuracy_bboxes(bboxes, test_b))\n",
    "        print('Loss - Digits                : %.2f%%'% loss_digit)\n",
    "        print('Loss - Bboxes                : %.2f%%'% loss_box)\n",
    "        print('------------------------------------------')\n",
    "        print('      ')\n",
    "        \n",
    "        path = model_to_save + str(epoch+1) + '/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        model_saver.save(session, path + 'SVHN-' + str(epoch+1))\n",
    "        \n",
    "    # Get Valid accuracy\n",
    "#     feed_dict = {X_ : valid_i, Y_ : valid_l, Z_ : valid_b, pkeep : 1.0, alpha : 1e-9,\n",
    "#                             is_train : False, iteration : epoch}\n",
    "#     loss_digit, loss_box, digits, bboxes = session.run([loss_digits, loss_bboxes, digits_preds, bboxes_preds], feed_dict=feed_dict)\n",
    "    \n",
    "#     print('=========================================')\n",
    "#     print('    FINAL ACCURACY   ')\n",
    "#     print('Accuracy digits - Individual : %.2f%%'% accuracy_digits(digits, valid_l)[0])\n",
    "#     print('Accuracy digits - All        : %.2f%%'% accuracy_digits(digits, valid_l)[1])\n",
    "#     print('Accuracy bboxes - All        : %.2f%%'% accuracy_bboxes(bboxes, valid_b))\n",
    "#     print('Loss - Digits                : %.2f%'% loss_digit)\n",
    "#     print('Loss - Bboxes                : %.2f%'% loss_box)\n",
    "#     print('=========================================')\n",
    "#     print('      ')\n",
    "    \n",
    "    print('Training Complete on SVHN Data')    \n",
    "    save_path = model_saver.save(session, model_to_save + 'SVHN')\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#             accuracy = float(acc(train_pred, batch_labels[:,1:6]))\n",
    "\n",
    "#             if (step % 500 == 0):\n",
    "#                 minibatch = {}\n",
    "#                 minibatch['loss'] = l\n",
    "#                 minibatch['W'] = W\n",
    "#                 minibatch['B'] = b\n",
    "#                 minibatch['accuracy'] = \"%.2f\" % accuracy\n",
    "\n",
    "#                 res_epoch[int(step/500)] = minibatch\n",
    "#                 print('Loss at step %d: %f' % (step, l))\n",
    "#                 print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "#                 print('    ')\n",
    "                \n",
    "#         box_train_dict[epoch+1] = res_epoch\n",
    "\n",
    "#         epoch_acc = 0\n",
    "#         for f in res_epoch:\n",
    "#             minibatch = res_epoch[f]\n",
    "#             epoch_acc += float(minibatch['accuracy'])\n",
    "#         epoch_acc = float(epoch_acc/len(res_epoch))\n",
    "        \n",
    "#         _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : t_data, Y_ : t_label, pkeep : 1.0, alpha : 0.002})\n",
    "#         accuracy = float(acc(predictions, t_label[:,1:6]))\n",
    "#         test_acc.append(accuracy)\n",
    "\n",
    "#         print('------------------------------------')\n",
    "#         print('Epoch',epoch+1,' Complete with accuracy: %.2f%%' % epoch_acc)\n",
    "#         print('Epoch',epoch+1,' Test Accuracy : %.2f%%' % accuracy)\n",
    "#         print('------------------------------------')\n",
    "#         print('        ')\n",
    "            \n",
    "#     print('Training Complete on MNIST Data')\n",
    "#     print('Test Accuracy : ', mean(test_acc))\n",
    "    \n",
    "#     save_path = model_saver.save(session, model_to_save)\n",
    "#     print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
