{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (230070, 32, 96, 1) (230070, 6)\n",
      "Test set (13068, 32, 96, 1) (13068, 6)\n",
      "Validation set (5684, 32, 96, 1) (5684, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi_box.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "train_dataset = hdf['train_images'][:]\n",
    "train_labels = hdf['train_labels'][:]\n",
    "test_dataset = hdf['test_images'][:]\n",
    "test_labels = hdf['test_labels'][:]\n",
    "valid_dataset = hdf['valid_images'][:]\n",
    "valid_labels = hdf['valid_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.astype(np.float32)\n",
    "test_dataset = test_dataset.astype(np.float32)\n",
    "valid_dataset = valid_dataset.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "valid_labels = valid_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_save = \"saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\"\n",
    "saved_mnist_model = \"saved_models/mnist/CNN_SVHN_Mnist.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 5 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 6     # First Conv Layer with depth 6\n",
    "    L = 12     # Second Conv Layer with depth 12\n",
    "    M = 24    # Third Conv layer with depth 24\n",
    "    N = 200   # Fourth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([N, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "\n",
    "    Y4 = tf.sigmoid(tf.matmul(YY, W4) + B4)\n",
    "    YY4 = tf.nn.dropout(Y4, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(YY4, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(YY4, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(YY4, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(YY4, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(YY4, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3)),tf.reduce_max(tf.abs(W4))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3)),tf.reduce_max(tf.abs(B4))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (125000, 32, 96, 1)   test :  (125000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset[0:125000]\n",
    "label_data = train_labels[0:125000]\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "W :  [ 0.37272164  0.48718435  0.31338772  0.49764675]\n",
      "b :  [ 0.18485929  0.1950376   0.4238168   0.19206028]\n",
      "Loss at step 0: 25.721560\n",
      "Minibatch accuracy: 20.9%\n",
      "Learning rate :  0.0005\n",
      "    \n",
      "W :  [ 0.26393014  0.43997326  0.31701458  0.46591577]\n",
      "b :  [ 0.10094957  0.23922502  0.43333384  0.22426257]\n",
      "Loss at step 500: 5.380329\n",
      "Minibatch accuracy: 65.6%\n",
      "Learning rate :  0.00046193496721438383\n",
      "    \n",
      "W :  [ 0.25741571  0.42034903  0.32025674  0.45070529]\n",
      "b :  [ 0.11217725  0.24895503  0.42950973  0.22426257]\n",
      "Loss at step 1000: 3.726057\n",
      "Minibatch accuracy: 76.4%\n",
      "Learning rate :  0.00042749230123119273\n",
      "    \n",
      "W :  [ 0.26374039  0.40657538  0.34241992  0.45074892]\n",
      "b :  [ 0.13493617  0.24854377  0.42789453  0.2242624 ]\n",
      "Loss at step 1500: 3.761067\n",
      "Minibatch accuracy: 75.8%\n",
      "Learning rate :  0.00039632728827268716\n",
      "    \n",
      "W :  [ 0.26791763  0.39813828  0.3564668   0.45078686]\n",
      "b :  [ 0.14564338  0.24620987  0.42511451  0.22426243]\n",
      "Loss at step 2000: 3.200605\n",
      "Minibatch accuracy: 79.8%\n",
      "Learning rate :  0.00036812801841425575\n",
      "    \n",
      "W :  [ 0.26874009  0.39078847  0.36926946  0.47328255]\n",
      "b :  [ 0.15177885  0.24376465  0.42142144  0.22425817]\n",
      "Loss at step 2500: 3.039713\n",
      "Minibatch accuracy: 80.0%\n",
      "Learning rate :  0.0003426122638850534\n",
      "    \n",
      "W :  [ 0.27060568  0.3838107   0.37551099  0.50141931]\n",
      "b :  [ 0.15075839  0.24371532  0.41952351  0.22425093]\n",
      "Loss at step 3000: 2.596792\n",
      "Minibatch accuracy: 83.9%\n",
      "Learning rate :  0.00031952465443761056\n",
      "    \n",
      "W :  [ 0.27309155  0.38039291  0.38293308  0.52603751]\n",
      "b :  [ 0.15124805  0.24141873  0.41738114  0.22415355]\n",
      "Loss at step 3500: 2.673553\n",
      "Minibatch accuracy: 83.9%\n",
      "Learning rate :  0.00029863412151656383\n",
      "    \n",
      "W :  [ 0.27438921  0.38166156  0.3828539   0.54125184]\n",
      "b :  [ 0.14320555  0.24474216  0.41796076  0.22413862]\n",
      "Loss at step 4000: 2.284304\n",
      "Minibatch accuracy: 86.6%\n",
      "Learning rate :  0.00027973158564688865\n",
      "    \n",
      "W :  [ 0.27744344  0.38490587  0.38714734  0.54919547]\n",
      "b :  [ 0.13687311  0.25276512  0.41822591  0.22413735]\n",
      "Loss at step 4500: 2.193838\n",
      "Minibatch accuracy: 87.0%\n",
      "Learning rate :  0.0002626278638962397\n",
      "    \n",
      "W :  [ 0.27961493  0.38533682  0.38783386  0.55829364]\n",
      "b :  [ 0.13223208  0.26243001  0.422124    0.22426766]\n",
      "Loss at step 5000: 2.014635\n",
      "Minibatch accuracy: 87.5%\n",
      "Learning rate :  0.00024715177646857697\n",
      "    \n",
      "W :  [ 0.28107774  0.388051    0.38952848  0.56382197]\n",
      "b :  [ 0.12920897  0.26863769  0.42406175  0.2246791 ]\n",
      "Loss at step 5500: 2.039282\n",
      "Minibatch accuracy: 87.3%\n",
      "Learning rate :  0.0002331484334792318\n",
      "    \n",
      "W :  [ 0.2827231   0.38671228  0.39043111  0.56837028]\n",
      "b :  [ 0.12529933  0.27505499  0.42810825  0.22484955]\n",
      "Loss at step 6000: 1.992999\n",
      "Minibatch accuracy: 88.0%\n",
      "Learning rate :  0.00022047768476488088\n",
      "    \n",
      "W :  [ 0.2836251   0.38657141  0.3911514   0.57232052]\n",
      "b :  [ 0.12343033  0.28069893  0.43253848  0.22473013]\n",
      "Loss at step 6500: 1.754791\n",
      "Minibatch accuracy: 89.4%\n",
      "Learning rate :  0.00020901271721360503\n",
      "    \n",
      "W :  [ 0.28522816  0.38565627  0.39115992  0.57687312]\n",
      "b :  [ 0.12115296  0.28570879  0.43600622  0.22554444]\n",
      "Loss at step 7000: 1.472378\n",
      "Minibatch accuracy: 91.2%\n",
      "Learning rate :  0.0001986387855766426\n",
      "    \n",
      "W :  [ 0.28697574  0.38625425  0.39284152  0.58297551]\n",
      "b :  [ 0.11913063  0.28988922  0.43967864  0.22469053]\n",
      "Loss at step 7500: 1.432063\n",
      "Minibatch accuracy: 91.1%\n",
      "Learning rate :  0.00018925206405937195\n",
      "    \n",
      "W :  [ 0.28763634  0.38555425  0.3953757   0.59760851]\n",
      "b :  [ 0.1170333   0.29429659  0.4443472   0.22654496]\n",
      "Loss at step 8000: 1.453315\n",
      "Minibatch accuracy: 90.5%\n",
      "Learning rate :  0.00018075860719786216\n",
      "    \n",
      "W :  [ 0.28902009  0.38792294  0.39834619  0.61002678]\n",
      "b :  [ 0.1169403   0.29950169  0.4467043   0.22019829]\n",
      "Loss at step 8500: 1.163419\n",
      "Minibatch accuracy: 93.8%\n",
      "Learning rate :  0.00017307340962109387\n",
      "    \n",
      "W :  [ 0.2902911   0.38655865  0.40123114  0.62136441]\n",
      "b :  [ 0.11644114  0.3026228   0.44988939  0.22325484]\n",
      "Loss at step 9000: 1.352029\n",
      "Minibatch accuracy: 91.9%\n",
      "Learning rate :  0.00016611955528863463\n",
      "    \n",
      "W :  [ 0.29164332  0.3876639   0.40458393  0.63317692]\n",
      "b :  [ 0.11766249  0.30624756  0.45236737  0.22009331]\n",
      "Loss at step 9500: 1.388924\n",
      "Minibatch accuracy: 92.7%\n",
      "Learning rate :  0.00015982744768905404\n",
      "    \n",
      "W :  [ 0.29232982  0.38825074  0.40705475  0.64515203]\n",
      "b :  [ 0.11595637  0.30975175  0.45508465  0.22311045]\n",
      "Loss at step 10000: 1.088579\n",
      "Minibatch accuracy: 93.1%\n",
      "Learning rate :  0.0001541341132946451\n",
      "    \n",
      "W :  [ 0.29402038  0.39089546  0.40845045  0.65580595]\n",
      "b :  [ 0.11850145  0.31236523  0.45935044  0.22057386]\n",
      "Loss at step 10500: 1.467741\n",
      "Minibatch accuracy: 91.2%\n",
      "Learning rate :  0.00014898257130119277\n",
      "    \n",
      "W :  [ 0.29385906  0.3912161   0.40862644  0.66684783]\n",
      "b :  [ 0.11710057  0.31580916  0.46145698  0.2206389 ]\n",
      "Loss at step 11000: 1.292789\n",
      "Minibatch accuracy: 91.9%\n",
      "Learning rate :  0.00014432126334493355\n",
      "    \n",
      "W :  [ 0.29596311  0.39352584  0.40916076  0.67404073]\n",
      "b :  [ 0.11947556  0.31793106  0.46484601  0.22114974]\n",
      "Loss at step 11500: 1.181757\n",
      "Minibatch accuracy: 91.4%\n",
      "Learning rate :  0.0001401035374891215\n",
      "    \n",
      "W :  [ 0.29600736  0.39430532  0.41126579  0.68084359]\n",
      "b :  [ 0.11831042  0.32046986  0.46571627  0.22149611]\n",
      "Loss at step 12000: 1.330794\n",
      "Minibatch accuracy: 92.7%\n",
      "Learning rate :  0.00013628718131576502\n",
      "    \n",
      "W :  [ 0.2973938   0.3952027   0.41466245  0.68655491]\n",
      "b :  [ 0.11994074  0.3229647   0.47042486  0.22176588]\n",
      "Loss at step 12500: 1.192309\n",
      "Minibatch accuracy: 92.3%\n",
      "Learning rate :  0.00013283399944955952\n",
      "    \n",
      "W :  [ 0.29766583  0.39679685  0.41668865  0.69309473]\n",
      "b :  [ 0.11870737  0.32575187  0.4714953   0.22249494]\n",
      "Loss at step 13000: 1.236566\n",
      "Minibatch accuracy: 92.0%\n",
      "Learning rate :  0.00012970943128573357\n",
      "    \n",
      "W :  [ 0.29923743  0.39799845  0.42051226  0.70031726]\n",
      "b :  [ 0.12088124  0.32743782  0.47459257  0.22268887]\n",
      "Loss at step 13500: 1.561949\n",
      "Minibatch accuracy: 89.1%\n",
      "Learning rate :  0.0001268822050958999\n",
      "    \n",
      "W :  [ 0.29973441  0.39873958  0.4217737   0.70650363]\n",
      "b :  [ 0.12074777  0.33009148  0.4758409   0.22323427]\n",
      "Loss at step 14000: 1.070862\n",
      "Minibatch accuracy: 93.3%\n",
      "Learning rate :  0.0001243240250500872\n",
      "    \n",
      "W :  [ 0.30062005  0.40008566  0.42531148  0.71413088]\n",
      "b :  [ 0.12384415  0.33270848  0.48022151  0.22372781]\n",
      "Loss at step 14500: 1.148533\n",
      "Minibatch accuracy: 93.4%\n",
      "Learning rate :  0.0001220092880225629\n",
      "    \n",
      "W :  [ 0.30132464  0.40064451  0.42598292  0.71853596]\n",
      "b :  [ 0.12303598  0.33424714  0.48077804  0.22414561]\n",
      "Loss at step 15000: 1.137144\n",
      "Minibatch accuracy: 93.4%\n",
      "Learning rate :  0.00011991482734714559\n",
      "    \n",
      "W :  [ 0.3025426   0.40013868  0.42964712  0.72573435]\n",
      "b :  [ 0.12499035  0.33607993  0.485358    0.22432217]\n",
      "Loss at step 15500: 1.101691\n",
      "Minibatch accuracy: 94.1%\n",
      "Learning rate :  0.00011801968095742312\n",
      "    \n",
      "W :  [ 0.30368483  0.40281263  0.43036532  0.72942907]\n",
      "b :  [ 0.12531993  0.33742958  0.48484531  0.2246282 ]\n",
      "Loss at step 16000: 1.020721\n",
      "Minibatch accuracy: 94.8%\n",
      "Learning rate :  0.00011630488159134649\n",
      "    \n",
      "W :  [ 0.30458793  0.40427989  0.43375435  0.73343939]\n",
      "b :  [ 0.1263971   0.34030709  0.48884991  0.22517417]\n",
      "Loss at step 16500: 1.054187\n",
      "Minibatch accuracy: 93.8%\n",
      "Learning rate :  0.00011475326696049602\n",
      "    \n",
      "W :  [ 0.30409181  0.40644273  0.43568069  0.73785025]\n",
      "b :  [ 0.12632592  0.34239963  0.49121639  0.22569805]\n",
      "Loss at step 17000: 1.051982\n",
      "Minibatch accuracy: 92.7%\n",
      "Learning rate :  0.00011334930798413044\n",
      "    \n",
      "W :  [ 0.30548376  0.40711224  0.43896782  0.74450612]\n",
      "b :  [ 0.12815596  0.34483385  0.49390528  0.22586673]\n",
      "Loss at step 17500: 0.991889\n",
      "Minibatch accuracy: 93.8%\n",
      "Learning rate :  0.0001120789533689274\n",
      "    \n",
      "W :  [ 0.30602366  0.40844476  0.43884784  0.75159007]\n",
      "b :  [ 0.12874794  0.34665585  0.49534705  0.22593337]\n",
      "Loss at step 18000: 0.766430\n",
      "Minibatch accuracy: 94.8%\n",
      "Learning rate :  0.00011092948897891703\n",
      "    \n",
      "W :  [ 0.30652699  0.40817434  0.44248706  0.75500822]\n",
      "b :  [ 0.13048564  0.34876826  0.49793729  0.2259911 ]\n",
      "Loss at step 18500: 0.901015\n",
      "Minibatch accuracy: 94.4%\n",
      "Learning rate :  0.00010988941058813576\n",
      "    \n",
      "W :  [ 0.30740979  0.40968746  0.44414923  0.75898468]\n",
      "b :  [ 0.13198586  0.35065418  0.4990814   0.2261651 ]\n",
      "Loss at step 19000: 0.747784\n",
      "Minibatch accuracy: 95.6%\n",
      "Learning rate :  0.00010894830874246625\n",
      "    \n",
      "W :  [ 0.30874136  0.41192368  0.44756833  0.76523215]\n",
      "b :  [ 0.13297455  0.35342053  0.50216419  0.22629631]\n",
      "Loss at step 19500: 0.848707\n",
      "Minibatch accuracy: 94.5%\n",
      "Learning rate :  0.00010809676457832176\n",
      "    \n",
      "W :  [ 0.30894765  0.41272742  0.44632998  0.7669664 ]\n",
      "b :  [ 0.13183965  0.35469148  0.50358105  0.22720218]\n",
      "Loss at step 20000: 0.917476\n",
      "Minibatch accuracy: 95.2%\n",
      "Learning rate :  0.00010732625555549367\n",
      "    \n",
      "W :  [ 0.31003869  0.4137688   0.45004219  0.76912606]\n",
      "b :  [ 0.1339217   0.35689971  0.50642282  0.22740468]\n",
      "Loss at step 20500: 0.908408\n",
      "Minibatch accuracy: 95.0%\n",
      "Learning rate :  0.0001066290701607045\n",
      "    \n",
      "W :  [ 0.31078094  0.41564265  0.45009449  0.77229828]\n",
      "b :  [ 0.13290377  0.35934716  0.50801021  0.22774972]\n",
      "Loss at step 21000: 0.650212\n",
      "Minibatch accuracy: 95.6%\n",
      "Learning rate :  0.00010599823072819108\n",
      "    \n",
      "W :  [ 0.31108385  0.41488484  0.45394698  0.77588004]\n",
      "b :  [ 0.13507135  0.36105147  0.51054615  0.22776113]\n",
      "Loss at step 21500: 0.824100\n",
      "Minibatch accuracy: 94.7%\n",
      "Learning rate :  0.00010542742360488037\n",
      "    \n",
      "W :  [ 0.31271112  0.41742063  0.45511046  0.77650219]\n",
      "b :  [ 0.13506176  0.3632012   0.5115723   0.22774243]\n",
      "Loss at step 22000: 0.759525\n",
      "Minibatch accuracy: 95.8%\n",
      "Learning rate :  0.00010491093596122738\n",
      "    \n",
      "W :  [ 0.31319138  0.4173575   0.45635554  0.78072411]\n",
      "b :  [ 0.13724594  0.36471877  0.5135386   0.22771643]\n",
      "Loss at step 22500: 0.779281\n",
      "Minibatch accuracy: 95.5%\n",
      "Learning rate :  0.00010444359861529693\n",
      "    \n",
      "W :  [ 0.31446004  0.41989255  0.45639986  0.78167617]\n",
      "b :  [ 0.13667814  0.36775061  0.51540625  0.22742215]\n",
      "Loss at step 23000: 0.743329\n",
      "Minibatch accuracy: 94.7%\n",
      "Learning rate :  0.00010402073429785344\n",
      "    \n",
      "W :  [ 0.31511837  0.42047182  0.45882031  0.78551024]\n",
      "b :  [ 0.1381731   0.36971271  0.51892281  0.22739822]\n",
      "Loss at step 23500: 0.795951\n",
      "Minibatch accuracy: 95.3%\n",
      "Learning rate :  0.00010363811084067834\n",
      "    \n",
      "W :  [ 0.31667879  0.42236567  0.4577398   0.78529674]\n",
      "b :  [ 0.1383899   0.37142706  0.52022421  0.22750823]\n",
      "Loss at step 24000: 1.012699\n",
      "Minibatch accuracy: 93.6%\n",
      "Learning rate :  0.00010329189881960801\n",
      "    \n",
      "W :  [ 0.31707874  0.42413878  0.45970774  0.7875694 ]\n",
      "b :  [ 0.13903312  0.37374568  0.52338403  0.22746862]\n",
      "Loss at step 24500: 0.685230\n",
      "Minibatch accuracy: 95.6%\n",
      "Learning rate :  0.00010297863322836974\n",
      "    \n",
      "W :  [ 0.31876591  0.42550114  0.461402    0.78877091]\n",
      "b :  [ 0.13971332  0.37593174  0.5251826   0.22726418]\n",
      "Loss at step 25000: 0.844280\n",
      "Minibatch accuracy: 94.7%\n",
      "Learning rate :  0.00010269517879963419\n",
      "    \n",
      "W :  [ 0.31919298  0.42625466  0.46327487  0.79186982]\n",
      "b :  [ 0.14131737  0.37779099  0.52765876  0.22737603]\n",
      "Loss at step 25500: 0.740943\n",
      "Minibatch accuracy: 95.5%\n",
      "Learning rate :  0.00010243869862620625\n",
      "    \n",
      "W :  [ 0.32053488  0.42714202  0.46292409  0.79453135]\n",
      "b :  [ 0.14204706  0.38018945  0.52981234  0.226457  ]\n",
      "Loss at step 26000: 0.678425\n",
      "Minibatch accuracy: 95.9%\n",
      "Learning rate :  0.00010220662576830431\n",
      "    \n",
      "W :  [ 0.32075784  0.42835048  0.46505415  0.79578137]\n",
      "b :  [ 0.1425871   0.38310182  0.53195083  0.22638108]\n",
      "Loss at step 26500: 0.670729\n",
      "Minibatch accuracy: 95.5%\n",
      "Learning rate :  0.00010199663756276409\n",
      "    \n",
      "W :  [ 0.32198095  0.4296912   0.46433568  0.79807132]\n",
      "b :  [ 0.14436027  0.38502416  0.53433979  0.22587499]\n",
      "Loss at step 27000: 0.475121\n",
      "Minibatch accuracy: 96.7%\n",
      "Learning rate :  0.00010180663237704508\n",
      "    \n",
      "W :  [ 0.32320085  0.43120858  0.46546906  0.80010945]\n",
      "b :  [ 0.14420752  0.3875052   0.53573233  0.22585391]\n",
      "Loss at step 27500: 0.990581\n",
      "Minibatch accuracy: 94.7%\n",
      "Learning rate :  0.00010163470857538563\n",
      "    \n",
      "W :  [ 0.32393363  0.43166885  0.46715012  0.80065387]\n",
      "b :  [ 0.14542675  0.38950872  0.53809088  0.22236313]\n",
      "Loss at step 28000: 0.653915\n",
      "Minibatch accuracy: 95.9%\n",
      "Learning rate :  0.00010147914548659317\n",
      "    \n",
      "W :  [ 0.32530248  0.43267661  0.47173211  0.80291957]\n",
      "b :  [ 0.14611968  0.39089149  0.54031748  0.22359137]\n",
      "Loss at step 28500: 0.935276\n",
      "Minibatch accuracy: 94.4%\n",
      "Learning rate :  0.00010133838618298851\n",
      "    \n",
      "W :  [ 0.32652721  0.43263057  0.47308442  0.80263186]\n",
      "b :  [ 0.14709534  0.3935971   0.54260492  0.22003452]\n",
      "Loss at step 29000: 0.920794\n",
      "Minibatch accuracy: 93.6%\n",
      "Learning rate :  0.00010121102189815033\n",
      "    \n",
      "W :  [ 0.32738757  0.43439379  0.47349021  0.80461675]\n",
      "b :  [ 0.14671101  0.3958022   0.54480505  0.22073531]\n",
      "Loss at step 29500: 0.691724\n",
      "Minibatch accuracy: 95.6%\n",
      "Learning rate :  0.00010109577792750736\n",
      "    \n",
      "W :  [ 0.32847896  0.43684894  0.47460422  0.80207807]\n",
      "b :  [ 0.14845321  0.39768589  0.54613793  0.22082385]\n",
      "Loss at step 30000: 0.637040\n",
      "Minibatch accuracy: 96.2%\n",
      "Learning rate :  0.00010099150087066655\n",
      "    \n",
      "Training Complete on MNIST Data\n",
      "Model saved in file: saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps_1 = 30001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "#     tf.global_variables_initializer().run()\n",
    "    model_saver.restore(session, saved_mnist_model)\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps_1):\n",
    "        #  learning rate decay\n",
    "        max_learning_rate = 0.0005\n",
    "        min_learning_rate = 0.0001\n",
    "\n",
    "        decay_speed = 5000.0\n",
    "        learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "        offset = (step * batch_size) % (label_data.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = label_data[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "        _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step % 500 == 0):\n",
    "            print('W : ', W)\n",
    "            print('b : ', b)\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "            print('Learning rate : ', learning_rate)\n",
    "            print('    ')\n",
    "            \n",
    "    print('Training Complete on MNIST Data')\n",
    "    \n",
    "    save_path = model_saver.save(session, model_to_save)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "-------TEST--------\n",
      "Test-Accuracy  i :  0\n",
      "Test accuracy:  92.5\n",
      "       \n",
      "Test-Accuracy  i :  1\n",
      "Test accuracy:  92.54\n",
      "       \n",
      "Test-Accuracy  i :  2\n",
      "Test accuracy:  92.74\n",
      "       \n",
      "Test-Accuracy  i :  3\n",
      "Test accuracy:  93.12\n",
      "       \n",
      "Test-Accuracy  i :  4\n",
      "Test accuracy:  92.54\n",
      "       \n",
      "Test-Accuracy  i :  5\n",
      "Test accuracy:  93.02\n",
      "       \n",
      "Test-Accuracy  i :  6\n",
      "Test accuracy:  92.3\n",
      "       \n",
      "Test-Accuracy  i :  7\n",
      "Test accuracy:  92.46\n",
      "       \n",
      "Test-Accuracy  i :  8\n",
      "Test accuracy:  92.5\n",
      "       \n",
      "Test-Accuracy  i :  9\n",
      "Test accuracy:  92.48\n",
      "       \n",
      "Test-Accuracy  i :  10\n",
      "Test accuracy:  92.58\n",
      "       \n",
      "Test-Accuracy  i :  11\n",
      "Test accuracy:  91.96\n",
      "       \n",
      "-----VALIDIDATION------\n",
      "Valid-Accuracy  i :  0\n",
      "Valid accuracy:  93.8\n",
      "        \n",
      "Valid-Accuracy  i :  1\n",
      "Valid accuracy:  93.56\n",
      "        \n",
      "Valid-Accuracy  i :  2\n",
      "Valid accuracy:  92.36\n",
      "        \n",
      "Valid-Accuracy  i :  3\n",
      "Valid accuracy:  91.84\n",
      "        \n",
      "-----  FINAL  ------\n",
      "Final Test Set Accuracy :  92.56\n",
      "Final Validation Set Accuracy :  92.89\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    batch = 1000\n",
    "    \n",
    "    test_acc = list()\n",
    "    print('-------TEST--------')\n",
    "    test_no = int(test_labels.shape[0] / batch)\n",
    "    for i in range(test_no - 1):\n",
    "        model_saver.restore(session, model_to_save)\n",
    "        data = test_dataset[i*batch:(i+1)*batch]\n",
    "        labels = test_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        test_acc.append(accuracy)\n",
    "        \n",
    "        print('Test-Accuracy', ' i : ', i)\n",
    "        print('Test accuracy: ', accuracy)\n",
    "        print('       ')\n",
    "        \n",
    "        \n",
    "    valid_acc = list()\n",
    "    print('-----VALIDIDATION------')\n",
    "    valid_no = int(valid_labels.shape[0] /  batch)\n",
    "    for i in range(valid_no - 1):\n",
    "        model_saver.restore(session, \"saved_models/box/CNN_SVHN_Box.ckpt\")\n",
    "        data = valid_dataset[i*batch:(i+1)*batch]\n",
    "        labels = valid_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        valid_acc.append(accuracy)\n",
    "        \n",
    "        print('Valid-Accuracy', ' i : ', i)\n",
    "        print('Valid accuracy: ', accuracy)\n",
    "        print('        ')\n",
    "        \n",
    "        \n",
    "    test_avg = mean(test_acc)\n",
    "    valid_avg = mean(valid_acc)\n",
    "    \n",
    "    print('-----  FINAL  ------')\n",
    "    print('Final Test Set Accuracy : ',\"%.2f\" % test_avg)\n",
    "    print('Final Validation Set Accuracy : ',\"%.2f\" % valid_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (230070, 32, 96, 1)   test :  (230070, 6)\n",
      "Initialized\n",
      "[[[[-0.02527582 -0.03388838  0.17283109 -0.01729741  0.11071919  0.05671528]]\n",
      "\n",
      "  [[ 0.02738943  0.25082365 -0.08692781 -0.04401178 -0.19098282  0.09372631]]\n",
      "\n",
      "  [[ 0.01513229  0.16658266 -0.1579423   0.04245133 -0.06786012 -0.03109819]]\n",
      "\n",
      "  [[ 0.04886926 -0.02381074 -0.12172074 -0.16224514  0.00765794  0.02660118]]\n",
      "\n",
      "  [[-0.07955003  0.17488185 -0.10784341  0.04254873 -0.07012692 -0.05076994]]\n",
      "\n",
      "  [[-0.2283912   0.02961999 -0.13866241  0.1758426   0.07978735  0.05376627]]]\n",
      "\n",
      "\n",
      " [[[-0.01999278  0.01229267 -0.05016958  0.08774988 -0.09853687 -0.01078244]]\n",
      "\n",
      "  [[-0.04156701 -0.18340199  0.0421268  -0.10152702 -0.10684902  0.19675153]]\n",
      "\n",
      "  [[ 0.10333272 -0.07133339 -0.08224076 -0.06104412  0.04099017  0.08499293]]\n",
      "\n",
      "  [[ 0.14036308  0.03031152  0.00557194 -0.15385486  0.0408501   0.08124785]]\n",
      "\n",
      "  [[ 0.09970131 -0.16520067 -0.02688326 -0.2040102   0.01480669 -0.03756951]]\n",
      "\n",
      "  [[ 0.02729728  0.02942066 -0.13933307  0.15488821 -0.04547837  0.10014364]]]\n",
      "\n",
      "\n",
      " [[[-0.10361539 -0.18025066  0.13949531  0.09762789 -0.01848813  0.16978647]]\n",
      "\n",
      "  [[ 0.07001586 -0.1832778  -0.01460677  0.17317241 -0.19066897  0.21801515]]\n",
      "\n",
      "  [[ 0.04242126 -0.20022011 -0.01295103 -0.03463494 -0.12681253  0.12407196]]\n",
      "\n",
      "  [[ 0.08720795 -0.16944826 -0.08293291  0.0410636   0.04640657  0.00213607]]\n",
      "\n",
      "  [[ 0.12132257 -0.15542622 -0.01462394 -0.19753636  0.10726552  0.02619671]]\n",
      "\n",
      "  [[ 0.16100268 -0.07842435  0.01329542  0.02462649  0.06046576 -0.17511055]]]\n",
      "\n",
      "\n",
      " [[[-0.05352776  0.09806404  0.13252702  0.27600333 -0.32847059  0.09263244]]\n",
      "\n",
      "  [[-0.18014678 -0.08573072  0.14354299  0.17187935 -0.1111111   0.13671702]]\n",
      "\n",
      "  [[ 0.14157973  0.00786577  0.0730289  -0.05342219  0.00219316  0.01861035]]\n",
      "\n",
      "  [[ 0.07632752  0.04257121 -0.06407503 -0.07604349  0.14639863 -0.06827158]]\n",
      "\n",
      "  [[ 0.200194    0.0519914   0.00256431 -0.32267207  0.09529004 -0.20622151]]\n",
      "\n",
      "  [[ 0.03014182 -0.07048519  0.09203082  0.00566123  0.17303543 -0.12884209]]]\n",
      "\n",
      "\n",
      " [[[-0.26601911  0.0753607   0.04964787  0.04634164 -0.18824466 -0.05080108]]\n",
      "\n",
      "  [[-0.15545475  0.12278489  0.1104182   0.20632294  0.00166776  0.0120628 ]]\n",
      "\n",
      "  [[ 0.00198957  0.03383418  0.07898764  0.08769049  0.16071093 -0.05861945]]\n",
      "\n",
      "  [[ 0.10231175  0.02237255  0.15759848  0.00362896  0.2472914  -0.1864507 ]]\n",
      "\n",
      "  [[ 0.07655985  0.13318023  0.01170035 -0.19630639  0.11904795 -0.06131272]]\n",
      "\n",
      "  [[ 0.11302146  0.08596878 -0.05985112  0.1028169   0.01895441 -0.10937537]]]\n",
      "\n",
      "\n",
      " [[[-0.06155988  0.10142977  0.04659921 -0.00898632  0.0367384   0.00215658]]\n",
      "\n",
      "  [[-0.25393856  0.05362687  0.04715051 -0.17543666  0.15788239  0.05478872]]\n",
      "\n",
      "  [[-0.11442932  0.08357622  0.0861437  -0.04553493  0.19688033 -0.15523049]]\n",
      "\n",
      "  [[-0.12554757  0.06253596 -0.01302872  0.05445521 -0.00889713 -0.09767582]]\n",
      "\n",
      "  [[ 0.08735325 -0.01314484  0.01052831 -0.08258356  0.02636536 -0.08685207]]\n",
      "\n",
      "  [[-0.00607211 -0.00169229  0.05433377  0.05170505 -0.12384415 -0.11438911]]]]\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset\n",
    "label_data = train_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "num_steps_1 = 25001\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, model_to_save)\n",
    "    print('Initialized')\n",
    "    \n",
    "    W1 = session.run(W1)\n",
    "    print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_ = []\n",
    "for img in img_name :\n",
    "    n = img + '_.jpg'\n",
    "    images_.append(Image.open(n).convert('L'))\n",
    "    \n",
    "for img in images_ :\n",
    "    img = img.convert('L')\n",
    "    \n",
    "images_array_ = []\n",
    "for i in images_ :\n",
    "    images_array_.append(np.array(i))\n",
    "    \n",
    "for i in range(len(images_array_)) :\n",
    "    images_array_[i] = images_array_[i][:,:,np.newaxis]\n",
    "    \n",
    "images_array_ = np.array(images_array_)\n",
    "\n",
    "images_array_ = (images_array_.astype(np.float32))\n",
    "tags = (tags.astype(np.int32))\n",
    "\n",
    "print(images_array_.shape, tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import scipy.ndimage\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_name = ['9679', '2468', '2122', '972', '786', '679', '273', '093', '00016', '0016', '016', '16', '01', '1', '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = np.array([[4,9,6,7,9,0], [4,2,4,6,8,0], [4,2,1,2,2,0], [3,9,7,2,0,0], [3,7,8,6,0,0], [3,6,7,9,0,0], [3,2,7,3,0,0], [3,10,9,3,0,0], [5,10,10,10,1,6], [4,10,10,1,6,0], [3,10,1,6,0,0], [2,1,6,0,0,0], [2,10,1,0,0,0], [1,1,0,0,0,0], [1,10,0,0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = np.array([[4,9,6,7,9,10], [4,2,4,6,8,10], [4,2,1,2,2,10], [3,9,7,2,10,10], [3,7,8,6,10,10], [3,6,7,9,10,10], [3,2,7,3,10,10], [3,0,9,3,10,10], [5,0,0,0,1,6], [4,0,0,1,6,10], [3,0,1,6,10,10], [2,1,6,10,10,10], [2,0,1,10,10,10], [1,1,10,10,10,10], [1,0,10,10,10,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for img in img_name :\n",
    "    n = 'test_images/' + img + '.jpg'\n",
    "    img = Image.open(n)\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype=\"int32\")\n",
    "    img = scipy.misc.imresize(img, (32, 96))\n",
    "    img = np.dot(img, [[0.2989],[0.5870],[0.1140]])\n",
    "    \n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = np.asarray(images)\n",
    "images = (images.astype(np.float32))\n",
    "tags = (tags.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 32, 96, 1) (15, 6)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape, tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for CNN_MNIST_MULTI.ckpt\n\t [[Node: save/RestoreV2_23 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_23/tensor_names, save/RestoreV2_23/shape_and_slices)]]\n\t [[Node: save/RestoreV2_47/_29 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_401_save/RestoreV2_47\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_23', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-2d4a82792c36>\", line 90, in <module>\n    model_saver = tf.train.Saver()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for CNN_MNIST_MULTI.ckpt\n\t [[Node: save/RestoreV2_23 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_23/tensor_names, save/RestoreV2_23/shape_and_slices)]]\n\t [[Node: save/RestoreV2_47/_29 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_401_save/RestoreV2_47\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for CNN_MNIST_MULTI.ckpt\n\t [[Node: save/RestoreV2_23 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_23/tensor_names, save/RestoreV2_23/shape_and_slices)]]\n\t [[Node: save/RestoreV2_47/_29 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_401_save/RestoreV2_47\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d4af327b23e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_svhn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CNN_MNIST_MULTI.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1388\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for CNN_MNIST_MULTI.ckpt\n\t [[Node: save/RestoreV2_23 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_23/tensor_names, save/RestoreV2_23/shape_and_slices)]]\n\t [[Node: save/RestoreV2_47/_29 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_401_save/RestoreV2_47\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save/RestoreV2_23', defined at:\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-2d4a82792c36>\", line 90, in <module>\n    model_saver = tf.train.Saver()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\n    self.build()\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for CNN_MNIST_MULTI.ckpt\n\t [[Node: save/RestoreV2_23 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_23/tensor_names, save/RestoreV2_23/shape_and_slices)]]\n\t [[Node: save/RestoreV2_47/_29 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_401_save/RestoreV2_47\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    model_saver.restore(session, \"CNN_MNIST_MULTI.ckpt\")\n",
    "    print(\"Model restored.\")  \n",
    "\n",
    "    print('Initialized')\n",
    "    \n",
    "    predictions = session.run([pred], feed_dict={X : images_array, Y_ : tags, pkeep : 1.0, alpha : 0.002})\n",
    "    print(predictions)\n",
    "    print(tags[:,1:6])\n",
    "    print ('    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "(5, 15, 11)\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "2\n",
      "9\n",
      "1\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "----\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "4\n",
      "4\n",
      "6\n",
      "0\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "----\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "----\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "----\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "----\n",
      "[[ 9  6  7  9 10]\n",
      " [ 2  4  6  8 10]\n",
      " [ 2  1  2  2 10]\n",
      " [ 9  7  2 10 10]\n",
      " [ 7  8  6 10 10]\n",
      " [ 6  7  9 10 10]\n",
      " [ 2  7  3 10 10]\n",
      " [ 0  9  3 10 10]\n",
      " [ 0  0  0  1  6]\n",
      " [ 0  0  1  6 10]\n",
      " [ 0  1  6 10 10]\n",
      " [ 1  6 10 10 10]\n",
      " [ 0  1 10 10 10]\n",
      " [ 1 10 10 10 10]\n",
      " [ 0 10 10 10 10]]\n",
      "Final Test Set Accuracy :  24.00\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    \n",
    "    model_saver.restore(session, model_to_save)\n",
    "\n",
    "    _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : images, Y_ : tags, pkeep : 1.0, alpha : 0.002})\n",
    "    accuracy = acc(predictions, tags[:,1:6])\n",
    "    \n",
    "    \n",
    "    print((predictions).shape)\n",
    "    for i in range(predictions.shape[0]):\n",
    "        p = predictions[i]\n",
    "        for j in range(p.shape[0]):\n",
    "            s = p[j]\n",
    "            print(np.argmax(s))\n",
    "        print('----')\n",
    "    print(tags[:,1:6])\n",
    "    \n",
    "    \n",
    "    print('Final Test Set Accuracy : ',\"%.2f\" % accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
