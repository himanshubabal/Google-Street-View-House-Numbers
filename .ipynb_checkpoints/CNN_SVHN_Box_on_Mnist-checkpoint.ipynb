{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "import gc\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (229087, 32, 96, 1) (229087, 6)\n",
      "Test set (13068, 32, 96, 1) (13068, 6)\n",
      "Validation set (6666, 32, 96, 1) (6666, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf_file = 'datasets/pickles/SVHN_multi_box.hdf5'\n",
    "\n",
    "hdf = h5py.File(hdf_file,'r')\n",
    "train_dataset = hdf['train_images'][:]\n",
    "train_labels = hdf['train_labels'][:]\n",
    "test_dataset = hdf['test_images'][:]\n",
    "test_labels = hdf['test_labels'][:]\n",
    "valid_dataset = hdf['valid_images'][:]\n",
    "valid_labels = hdf['valid_labels'][:]\n",
    "            \n",
    "hdf.close()    \n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.astype(np.float32)\n",
    "test_dataset = test_dataset.astype(np.float32)\n",
    "valid_dataset = valid_dataset.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "valid_labels = valid_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_save = \"saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\"\n",
    "saved_mnist_model = \"saved_models/mnist/CNN_SVHN_Mnist.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_svhn = tf.Graph()\n",
    "\n",
    "with graph_svhn.as_default():\n",
    "    HEIGHT = 32\n",
    "    WIDTH = 32*3\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, HEIGHT, WIDTH, 1])\n",
    "    Y_ = tf.placeholder(tf.int32, [None, 6])\n",
    "    \n",
    "    # Learning Rate - alpha\n",
    "    alpha = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Dropout Probablity\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # 6 Layers and their no of neurons\n",
    "    # 3 Convolutional Layers and a fully connected layer\n",
    "    K = 12     # First Conv Layer with depth 12\n",
    "    L = 24     # Second Conv Layer with depth 24\n",
    "    M = 36    # Third Conv layer with depth 36\n",
    "    N = 300   # Fourth Fully Connected layer with 300 neurons\n",
    "    P = 200   # Fifth Fully Connected layer with 200 neurons\n",
    "    # Last one will be softmax layer with 10 output channels\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")    # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1), name=\"W2\")\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]), name=\"B2\")\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1), name=\"W3\")\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]), name=\"B3\")\n",
    "    \n",
    "    W5_1 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_1\")\n",
    "    B5_1 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_1\")\n",
    "    \n",
    "    W5_2 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_2\")\n",
    "    B5_2 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_2\")\n",
    "    \n",
    "    W5_3 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_3\")\n",
    "    B5_3 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_3\")\n",
    "    \n",
    "    W5_4 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_4\")\n",
    "    B5_4 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_4\")\n",
    "    \n",
    "    W5_5 = tf.Variable(tf.truncated_normal([P, 11], stddev=0.1), name=\"W5_5\")\n",
    "    B5_5 = tf.Variable(tf.constant(0.1, tf.float32, [11]), name=\"B5_5\")\n",
    "    \n",
    "    # Model\n",
    "    stride = 1  # output is 32x96\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    \n",
    "    stride = 2  # output is 16x48\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    \n",
    "    stride = 2  # output is 8x24\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    shape = Y3.get_shape().as_list()\n",
    "    YY = tf.reshape(Y3, shape=[-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([shape[1] * shape[2] * shape[3], N], stddev=0.1), name=\"W4\")\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]), name=\"B4\")\n",
    "    \n",
    "    W5 = tf.Variable(tf.truncated_normal([N, P], stddev=0.1), name=\"W5\")\n",
    "    B5 = tf.Variable(tf.constant(0.1, tf.float32, [P]), name=\"B5\")\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    Y5 = tf.nn.relu(tf.matmul(Y4, W5) + B5)\n",
    "    \n",
    "    Y_F = tf.nn.dropout(Y5, pkeep)\n",
    "    \n",
    "    Ylogits_1 = tf.matmul(Y_F, W5_1) + B5_1\n",
    "    Ylogits_2 = tf.matmul(Y_F, W5_2) + B5_2\n",
    "    Ylogits_3 = tf.matmul(Y_F, W5_3) + B5_3\n",
    "    Ylogits_4 = tf.matmul(Y_F, W5_4) + B5_4\n",
    "    Ylogits_5 = tf.matmul(Y_F, W5_5) + B5_5   \n",
    "    ## ('Ylogits_1 shape : ', [None, 11])\n",
    "    \n",
    "    Y_1 = tf.nn.softmax(Ylogits_1)\n",
    "    Y_2 = tf.nn.softmax(Ylogits_2)\n",
    "    Y_3 = tf.nn.softmax(Ylogits_3)\n",
    "    Y_4 = tf.nn.softmax(Ylogits_4)\n",
    "    Y_5 = tf.nn.softmax(Ylogits_5)\n",
    "   \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_1, Y_[:,1])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_2, Y_[:,2])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_3, Y_[:,3])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_4, Y_[:,4])) +\\\n",
    "    tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(Ylogits_5, Y_[:,5]))\n",
    "\n",
    "    train_prediction = tf.pack([Y_1, Y_2, Y_3, Y_4, Y_5])\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(alpha).minimize(cross_entropy)\n",
    "    \n",
    "    W_s = tf.pack([tf.reduce_max(tf.abs(W1)),tf.reduce_max(tf.abs(W2)),tf.reduce_max(tf.abs(W3))\\\n",
    "                   ,tf.reduce_max(tf.abs(W4)),tf.reduce_max(tf.abs(W5))])\n",
    "    b_s = tf.pack([tf.reduce_max(tf.abs(B1)),tf.reduce_max(tf.abs(B2)),tf.reduce_max(tf.abs(B3))\\\n",
    "                   ,tf.reduce_max(tf.abs(B4)),tf.reduce_max(tf.abs(B5))])\n",
    "    \n",
    "    model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (229087, 32, 96, 1)   test :  (229087, 6)\n",
      "Initialized\n",
      "Loss at step 0: 11.220667\n",
      "Minibatch accuracy: 31.1%\n",
      "W :  [ 0.30989823  0.38223922  0.43278304  0.77872795  0.57660186]\n",
      "B :  [ 0.09201913  0.22464228  0.26228482  0.22948168  0.23504254]\n",
      "    \n",
      "Loss at step 500: 1.837270\n",
      "Minibatch accuracy: 88.9%\n",
      "W :  [ 0.28472903  0.37438309  0.43183544  0.77871025  0.57955348]\n",
      "B :  [ 0.18997099  0.2468127   0.25204077  0.2332004   0.26845166]\n",
      "    \n",
      "Loss at step 1000: 1.992791\n",
      "Minibatch accuracy: 87.3%\n",
      "W :  [ 0.27960128  0.40311718  0.43189716  0.77871025  0.57955348]\n",
      "B :  [ 0.18094735  0.25329784  0.2523236   0.23172502  0.27208018]\n",
      "    \n",
      "Loss at step 1500: 1.536280\n",
      "Minibatch accuracy: 90.3%\n",
      "W :  [ 0.27532208  0.42615762  0.43135744  0.77871025  0.57955348]\n",
      "B :  [ 0.17686723  0.2614899   0.25108984  0.22919612  0.27384588]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 1  Complete with accuracy: 74.41%\n",
      "Epoch 1  Test Accuracy : 90.73%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 1.426882\n",
      "Minibatch accuracy: 90.2%\n",
      "W :  [ 0.27519217  0.42818025  0.43116587  0.77871025  0.57955348]\n",
      "B :  [ 0.17236134  0.26098973  0.25165358  0.230703    0.2753734 ]\n",
      "    \n",
      "Loss at step 500: 0.933713\n",
      "Minibatch accuracy: 93.8%\n",
      "W :  [ 0.27615353  0.42543575  0.43267453  0.77871025  0.57955348]\n",
      "B :  [ 0.16616826  0.2663466   0.24618374  0.22905849  0.27596793]\n",
      "    \n",
      "Loss at step 1000: 1.337950\n",
      "Minibatch accuracy: 92.7%\n",
      "W :  [ 0.27313179  0.43286008  0.45468965  0.77871025  0.57955348]\n",
      "B :  [ 0.16160546  0.26642492  0.25056803  0.22986001  0.27934572]\n",
      "    \n",
      "Loss at step 1500: 1.028189\n",
      "Minibatch accuracy: 92.7%\n",
      "W :  [ 0.27359039  0.43435887  0.47568324  0.77871025  0.57955348]\n",
      "B :  [ 0.16227308  0.27097234  0.24754375  0.22709465  0.27920327]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 2  Complete with accuracy: 92.31%\n",
      "Epoch 2  Test Accuracy : 92.30%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.742241\n",
      "Minibatch accuracy: 94.8%\n",
      "W :  [ 0.27223963  0.43044901  0.48130715  0.77871025  0.57955348]\n",
      "B :  [ 0.15970542  0.26930362  0.25020039  0.22981599  0.27787271]\n",
      "    \n",
      "Loss at step 500: 0.606223\n",
      "Minibatch accuracy: 95.9%\n",
      "W :  [ 0.27542084  0.43139738  0.49577299  0.77871025  0.57955348]\n",
      "B :  [ 0.15732437  0.2704832   0.26008865  0.2272255   0.27702156]\n",
      "    \n",
      "Loss at step 1000: 1.068877\n",
      "Minibatch accuracy: 94.4%\n",
      "W :  [ 0.27491021  0.44013304  0.51028252  0.77871025  0.57955348]\n",
      "B :  [ 0.15127382  0.27095214  0.26543614  0.22687499  0.27892601]\n",
      "    \n",
      "Loss at step 1500: 0.810561\n",
      "Minibatch accuracy: 94.8%\n",
      "W :  [ 0.27651384  0.43373004  0.51216608  0.77871025  0.57955348]\n",
      "B :  [ 0.15482782  0.27719784  0.27224264  0.22418268  0.27822414]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 3  Complete with accuracy: 95.00%\n",
      "Epoch 3  Test Accuracy : 94.18%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.546161\n",
      "Minibatch accuracy: 96.6%\n",
      "W :  [ 0.27682221  0.42783707  0.50797951  0.77871025  0.57955348]\n",
      "B :  [ 0.15261386  0.27470398  0.27351904  0.22165957  0.27916327]\n",
      "    \n",
      "Loss at step 500: 0.474311\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.27967244  0.42970783  0.51686579  0.77871025  0.58007997]\n",
      "B :  [ 0.15341325  0.27807522  0.2799401   0.22450112  0.28014481]\n",
      "    \n",
      "Loss at step 1000: 0.888485\n",
      "Minibatch accuracy: 95.5%\n",
      "W :  [ 0.27655965  0.42329645  0.53673893  0.77887887  0.58007997]\n",
      "B :  [ 0.14990719  0.28051367  0.28385839  0.22834763  0.27703601]\n",
      "    \n",
      "Loss at step 1500: 0.597927\n",
      "Minibatch accuracy: 96.2%\n",
      "W :  [ 0.28132308  0.41636819  0.54130721  0.77901679  0.58005804]\n",
      "B :  [ 0.15325047  0.2839061   0.29088977  0.22331429  0.27668628]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 4  Complete with accuracy: 96.44%\n",
      "Epoch 4  Test Accuracy : 94.21%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.508995\n",
      "Minibatch accuracy: 96.9%\n",
      "W :  [ 0.27998212  0.41820127  0.53474849  0.77901679  0.58005804]\n",
      "B :  [ 0.14871828  0.28476828  0.28931427  0.22607696  0.27782336]\n",
      "    \n",
      "Loss at step 500: 0.351019\n",
      "Minibatch accuracy: 98.0%\n",
      "W :  [ 0.28378683  0.41492924  0.54080522  0.77909625  0.5800879 ]\n",
      "B :  [ 0.15345059  0.28922984  0.29265952  0.22445686  0.27673876]\n",
      "    \n",
      "Loss at step 1000: 0.694455\n",
      "Minibatch accuracy: 96.1%\n",
      "W :  [ 0.28407508  0.42267713  0.5505408   0.77909625  0.58007121]\n",
      "B :  [ 0.15022889  0.28777415  0.29779711  0.22514482  0.27459008]\n",
      "    \n",
      "Loss at step 1500: 0.403919\n",
      "Minibatch accuracy: 96.7%\n",
      "W :  [ 0.28477901  0.41275156  0.54978222  0.77909625  0.58007121]\n",
      "B :  [ 0.15287994  0.29114476  0.30880031  0.22296132  0.28019863]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 5  Complete with accuracy: 96.91%\n",
      "Epoch 5  Test Accuracy : 93.83%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.461532\n",
      "Minibatch accuracy: 96.6%\n",
      "W :  [ 0.28665516  0.41965479  0.54605258  0.77909625  0.58123404]\n",
      "B :  [ 0.15271509  0.29198131  0.30782387  0.2247114   0.27782577]\n",
      "    \n",
      "Loss at step 500: 0.312560\n",
      "Minibatch accuracy: 98.0%\n",
      "W :  [ 0.28707403  0.42630762  0.55322742  0.77909625  0.5855971 ]\n",
      "B :  [ 0.15725304  0.29955631  0.31166983  0.22366515  0.27170926]\n",
      "    \n",
      "Loss at step 1000: 0.556458\n",
      "Minibatch accuracy: 96.9%\n",
      "W :  [ 0.28579333  0.4219119   0.56125915  0.77909625  0.58583242]\n",
      "B :  [ 0.15664408  0.29813683  0.31602925  0.22501209  0.27129394]\n",
      "    \n",
      "Loss at step 1500: 0.370728\n",
      "Minibatch accuracy: 97.2%\n",
      "W :  [ 0.28775302  0.42070702  0.56279254  0.78282756  0.59764409]\n",
      "B :  [ 0.1575664   0.30144918  0.32331789  0.22020063  0.27419493]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 6  Complete with accuracy: 97.15%\n",
      "Epoch 6  Test Accuracy : 94.02%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.177371\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.28972694  0.42935249  0.56524688  0.78626794  0.59619504]\n",
      "B :  [ 0.15848263  0.29959959  0.31841168  0.22043161  0.2742283 ]\n",
      "    \n",
      "Loss at step 500: 0.172360\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.29221591  0.42615747  0.5756467   0.80052143  0.59922457]\n",
      "B :  [ 0.15837437  0.30919659  0.32678017  0.22250669  0.27576035]\n",
      "    \n",
      "Loss at step 1000: 0.536469\n",
      "Minibatch accuracy: 96.7%\n",
      "W :  [ 0.29209489  0.42335731  0.59104216  0.80052388  0.60161686]\n",
      "B :  [ 0.15927643  0.31062984  0.32538837  0.22125633  0.27379504]\n",
      "    \n",
      "Loss at step 1500: 0.304942\n",
      "Minibatch accuracy: 98.1%\n",
      "W :  [ 0.29386267  0.42562717  0.59884995  0.79635721  0.61092043]\n",
      "B :  [ 0.16458623  0.31527606  0.34174702  0.22152327  0.27412882]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 7  Complete with accuracy: 98.12%\n",
      "Epoch 7  Test Accuracy : 94.90%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.219246\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.29612169  0.43104875  0.59303772  0.79760635  0.62030983]\n",
      "B :  [ 0.16120768  0.31194967  0.33936203  0.21923381  0.27323535]\n",
      "    \n",
      "Loss at step 500: 0.138566\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.30149117  0.4369638   0.60043722  0.79545671  0.60331219]\n",
      "B :  [ 0.16023806  0.32126251  0.3430365   0.22306974  0.27609143]\n",
      "    \n",
      "Loss at step 1000: 0.377637\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.29389659  0.43406832  0.61193424  0.79740679  0.60053653]\n",
      "B :  [ 0.16195068  0.3231622   0.33993939  0.22080046  0.27219883]\n",
      "    \n",
      "Loss at step 1500: 0.261471\n",
      "Minibatch accuracy: 97.8%\n",
      "W :  [ 0.29348099  0.43206021  0.61089736  0.82697344  0.60408431]\n",
      "B :  [ 0.16565695  0.32762077  0.35511509  0.2184214   0.27002433]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 8  Complete with accuracy: 98.28%\n",
      "Epoch 8  Test Accuracy : 94.52%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.200138\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.29743752  0.43205413  0.61184496  0.82686925  0.60378188]\n",
      "B :  [ 0.16803423  0.32945219  0.35049352  0.21798734  0.26626459]\n",
      "    \n",
      "Loss at step 500: 0.118623\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.30092856  0.44168949  0.61502928  0.82687294  0.60876036]\n",
      "B :  [ 0.16137946  0.33613151  0.35648161  0.22103594  0.26862729]\n",
      "    \n",
      "Loss at step 1000: 0.432549\n",
      "Minibatch accuracy: 97.3%\n",
      "W :  [ 0.30029571  0.44078282  0.62118566  0.8268708   0.60858935]\n",
      "B :  [ 0.16459696  0.33471337  0.35700315  0.21725003  0.26845899]\n",
      "    \n",
      "Loss at step 1500: 0.227581\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.30089891  0.44012767  0.62624979  0.82688469  0.62768739]\n",
      "B :  [ 0.16465282  0.33865881  0.368031    0.21701518  0.26967028]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 9  Complete with accuracy: 98.40%\n",
      "Epoch 9  Test Accuracy : 94.37%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.190544\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.30182666  0.44446757  0.62266231  0.83812243  0.634597  ]\n",
      "B :  [ 0.16856861  0.33870652  0.36132038  0.21767263  0.26634714]\n",
      "    \n",
      "Loss at step 500: 0.101510\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.30624446  0.45333073  0.65207469  0.83849645  0.64798814]\n",
      "B :  [ 0.16727935  0.34866619  0.36506936  0.21923472  0.26412144]\n",
      "    \n",
      "Loss at step 1000: 0.243676\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.30550829  0.4550119   0.67000127  0.83885151  0.65583771]\n",
      "B :  [ 0.16862544  0.34673133  0.36415496  0.21960302  0.26347134]\n",
      "    \n",
      "Loss at step 1500: 0.159753\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.30311894  0.45415771  0.66653305  0.84463704  0.65420288]\n",
      "B :  [ 0.17150344  0.35089636  0.37628415  0.21729901  0.26330879]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 10  Complete with accuracy: 99.06%\n",
      "Epoch 10  Test Accuracy : 95.10%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.082738\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.30424565  0.45963311  0.66172028  0.84549707  0.65180224]\n",
      "B :  [ 0.16773137  0.34960708  0.37609145  0.21935797  0.25757489]\n",
      "    \n",
      "Loss at step 500: 0.113845\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.30795735  0.46762565  0.66587716  0.84545857  0.64691013]\n",
      "B :  [ 0.15994526  0.35832912  0.38101158  0.21851866  0.25865039]\n",
      "    \n",
      "Loss at step 1000: 0.374693\n",
      "Minibatch accuracy: 97.5%\n",
      "W :  [ 0.3046228   0.46707094  0.67780215  0.84701854  0.65524936]\n",
      "B :  [ 0.16541779  0.35976774  0.37984604  0.21472956  0.25200063]\n",
      "    \n",
      "Loss at step 1500: 0.155757\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.3028073   0.46237287  0.67920548  0.84618127  0.66173971]\n",
      "B :  [ 0.16542716  0.3593756   0.39005193  0.21545634  0.26206911]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 11  Complete with accuracy: 98.71%\n",
      "Epoch 11  Test Accuracy : 93.87%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.092079\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.30462334  0.46118131  0.67993134  0.85412878  0.65277058]\n",
      "B :  [ 0.1676514   0.35802916  0.39083204  0.2121778   0.25459328]\n",
      "    \n",
      "Loss at step 500: 0.096564\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.30624169  0.46622649  0.69826818  0.85173529  0.65955204]\n",
      "B :  [ 0.16461262  0.36646807  0.3952719   0.21726945  0.25904721]\n",
      "    \n",
      "Loss at step 1000: 0.146965\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.30490813  0.46952954  0.7106337   0.85250765  0.65342188]\n",
      "B :  [ 0.16627686  0.3717393   0.39227974  0.2187746   0.2614311 ]\n",
      "    \n",
      "Loss at step 1500: 0.112431\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.30476263  0.46451005  0.70531243  0.85026973  0.6656431 ]\n",
      "B :  [ 0.16667743  0.37603074  0.40131447  0.21641107  0.26190531]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 12  Complete with accuracy: 99.10%\n",
      "Epoch 12  Test Accuracy : 94.67%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.134437\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.30831534  0.4731178   0.69984937  0.8621012   0.66465026]\n",
      "B :  [ 0.16679747  0.37316093  0.40056857  0.21827349  0.25763202]\n",
      "    \n",
      "Loss at step 500: 0.053169\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31496277  0.48082739  0.71661007  0.8602801   0.68110567]\n",
      "B :  [ 0.1608194   0.38115138  0.40606081  0.21792653  0.2614654 ]\n",
      "    \n",
      "Loss at step 1000: 0.190991\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31294084  0.48310095  0.72274345  0.8602801   0.68437469]\n",
      "B :  [ 0.16928928  0.38496178  0.40562937  0.21957877  0.26010111]\n",
      "    \n",
      "Loss at step 1500: 0.129510\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31056046  0.48259231  0.71955115  0.86023438  0.68503624]\n",
      "B :  [ 0.17273779  0.38605446  0.41385207  0.21817538  0.26324037]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 13  Complete with accuracy: 99.06%\n",
      "Epoch 13  Test Accuracy : 94.29%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.108270\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31434482  0.49464995  0.71234185  0.85997534  0.68471044]\n",
      "B :  [ 0.16949253  0.37868416  0.41487914  0.21768205  0.26042515]\n",
      "    \n",
      "Loss at step 500: 0.028183\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.31583506  0.49592376  0.72266817  0.86088234  0.69025403]\n",
      "B :  [ 0.1636852   0.38503098  0.41706714  0.2198301   0.26811826]\n",
      "    \n",
      "Loss at step 1000: 0.120705\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.31385216  0.5025245   0.72210419  0.86075097  0.69140512]\n",
      "B :  [ 0.16490467  0.38289133  0.41351217  0.22007592  0.27056211]\n",
      "    \n",
      "Loss at step 1500: 0.129625\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.31364557  0.5002923   0.71926993  0.86079282  0.68962938]\n",
      "B :  [ 0.17368165  0.38596696  0.42140791  0.22161704  0.26895767]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 14  Complete with accuracy: 99.18%\n",
      "Epoch 14  Test Accuracy : 94.33%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.044326\n",
      "Minibatch accuracy: 100.0%\n",
      "W :  [ 0.31278273  0.49135774  0.71801662  0.86164993  0.69582438]\n",
      "B :  [ 0.16851012  0.38353679  0.42141941  0.21550427  0.26926354]\n",
      "    \n",
      "Loss at step 500: 0.063144\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31727093  0.50480574  0.72577304  0.86114049  0.7022441 ]\n",
      "B :  [ 0.16589563  0.38874573  0.42017204  0.21825458  0.27591816]\n",
      "    \n",
      "Loss at step 1000: 0.152254\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31621194  0.51071465  0.73880738  0.86114144  0.70175993]\n",
      "B :  [ 0.16760778  0.38818574  0.4198792   0.21861553  0.28022388]\n",
      "    \n",
      "Loss at step 1500: 0.117525\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31606558  0.50253105  0.73931921  0.86995256  0.68760812]\n",
      "B :  [ 0.1673232   0.39268494  0.42682475  0.21646003  0.27290803]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 15  Complete with accuracy: 99.57%\n",
      "Epoch 15  Test Accuracy : 94.75%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.083989\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31535622  0.50908989  0.73805916  0.88195306  0.69070566]\n",
      "B :  [ 0.17060973  0.3877387   0.42373797  0.21855049  0.27013943]\n",
      "    \n",
      "Loss at step 500: 0.060515\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31625903  0.51067984  0.73866796  0.88227838  0.69007397]\n",
      "B :  [ 0.16179736  0.39356554  0.42680675  0.21888326  0.27332085]\n",
      "    \n",
      "Loss at step 1000: 0.167502\n",
      "Minibatch accuracy: 98.6%\n",
      "W :  [ 0.31081751  0.5185203   0.74576592  0.88229269  0.69094765]\n",
      "B :  [ 0.16132578  0.3948566   0.43035549  0.2196146   0.27758643]\n",
      "    \n",
      "Loss at step 1500: 0.096411\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.31153598  0.51707387  0.74640304  0.88100684  0.69979221]\n",
      "B :  [ 0.1591045   0.39304453  0.4355832   0.22090507  0.2863932 ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 16  Complete with accuracy: 99.10%\n",
      "Epoch 16  Test Accuracy : 93.91%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.029006\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.31488973  0.5253973   0.74347848  0.88097435  0.69286835]\n",
      "B :  [ 0.15915185  0.39175445  0.43840513  0.22108804  0.27670836]\n",
      "    \n",
      "Loss at step 500: 0.124600\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31766084  0.53445637  0.75570899  0.89947784  0.70982701]\n",
      "B :  [ 0.15643467  0.39277622  0.4389737   0.22091927  0.28212512]\n",
      "    \n",
      "Loss at step 1000: 0.151669\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31327799  0.54105324  0.7891475   0.89936304  0.70797545]\n",
      "B :  [ 0.15446232  0.39480135  0.43394026  0.21841417  0.28358993]\n",
      "    \n",
      "Loss at step 1500: 0.068170\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31564245  0.54018742  0.79255474  0.90530616  0.69752282]\n",
      "B :  [ 0.1617413   0.39729097  0.44150338  0.22005016  0.28569406]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 17  Complete with accuracy: 99.45%\n",
      "Epoch 17  Test Accuracy : 94.33%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.178636\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.31455606  0.53601933  0.78301573  0.90536588  0.69912535]\n",
      "B :  [ 0.16267245  0.39230186  0.43729889  0.22478797  0.27957839]\n",
      "    \n",
      "Loss at step 500: 0.099032\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.31924009  0.54103553  0.79651654  0.91084844  0.7135489 ]\n",
      "B :  [ 0.15780042  0.39652961  0.44559926  0.22763686  0.27799261]\n",
      "    \n",
      "Loss at step 1000: 0.129949\n",
      "Minibatch accuracy: 98.8%\n",
      "W :  [ 0.31281808  0.54596138  0.81674421  0.91093922  0.72394371]\n",
      "B :  [ 0.15901805  0.3982642   0.44214201  0.22382957  0.2831279 ]\n",
      "    \n",
      "Loss at step 1500: 0.116051\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31382537  0.53646433  0.81448805  0.91094142  0.72254032]\n",
      "B :  [ 0.1592219   0.40026349  0.44916973  0.21952428  0.286672  ]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 18  Complete with accuracy: 98.94%\n",
      "Epoch 18  Test Accuracy : 93.91%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.069610\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.31759816  0.53877109  0.80817693  0.91093826  0.72197509]\n",
      "B :  [ 0.15726171  0.39646235  0.44629034  0.21968567  0.28363556]\n",
      "    \n",
      "Loss at step 500: 0.045233\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31570974  0.54320121  0.81913936  0.89849037  0.71851069]\n",
      "B :  [ 0.15878221  0.39821345  0.44285679  0.22552273  0.28736582]\n",
      "    \n",
      "Loss at step 1000: 0.105171\n",
      "Minibatch accuracy: 99.1%\n",
      "W :  [ 0.31530592  0.54960406  0.82365191  0.88573563  0.73132843]\n",
      "B :  [ 0.15654022  0.39774713  0.44234779  0.22306304  0.28408873]\n",
      "    \n",
      "Loss at step 1500: 0.056809\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.31771234  0.5457809   0.82048315  0.89461637  0.72766286]\n",
      "B :  [ 0.15765086  0.39485726  0.45002058  0.22274779  0.28628355]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 19  Complete with accuracy: 99.38%\n",
      "Epoch 19  Test Accuracy : 94.37%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.026537\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.31733471  0.55015063  0.83190089  0.89459687  0.71915948]\n",
      "B :  [ 0.16019696  0.39469808  0.44656342  0.22192997  0.28816795]\n",
      "    \n",
      "Loss at step 500: 0.021083\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.32202733  0.56689793  0.83262843  0.88456392  0.70777225]\n",
      "B :  [ 0.15368496  0.39622891  0.44977105  0.22070645  0.29111972]\n",
      "    \n",
      "Loss at step 1000: 0.124111\n",
      "Minibatch accuracy: 98.9%\n",
      "W :  [ 0.32078829  0.57467538  0.84038812  0.88397193  0.71255648]\n",
      "B :  [ 0.15834081  0.40341777  0.45537022  0.22682779  0.2926394 ]\n",
      "    \n",
      "Loss at step 1500: 0.090192\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31912223  0.5696665   0.83830273  0.88315892  0.72499073]\n",
      "B :  [ 0.15385035  0.40265498  0.46250531  0.22983797  0.29588091]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 20  Complete with accuracy: 99.49%\n",
      "Epoch 20  Test Accuracy : 93.60%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.035507\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.32004583  0.57580781  0.83816373  0.8842178   0.7281183 ]\n",
      "B :  [ 0.15498997  0.40563464  0.45603904  0.22725914  0.28709319]\n",
      "    \n",
      "Loss at step 500: 0.035348\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.32078758  0.57566136  0.83854795  0.88822448  0.73287964]\n",
      "B :  [ 0.15697129  0.40479288  0.46070623  0.22284105  0.29714587]\n",
      "    \n",
      "Loss at step 1000: 0.083982\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31856245  0.57409596  0.84187239  0.88836092  0.73863703]\n",
      "B :  [ 0.15098755  0.40325728  0.46118921  0.22957791  0.30438626]\n",
      "    \n",
      "Loss at step 1500: 0.070711\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31985149  0.57643908  0.83611268  0.88891697  0.74283981]\n",
      "B :  [ 0.15279265  0.40279695  0.46798617  0.2330659   0.29774374]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 21  Complete with accuracy: 99.61%\n",
      "Epoch 21  Test Accuracy : 94.87%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.049430\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.31744432  0.57443559  0.8272931   0.89040244  0.73592967]\n",
      "B :  [ 0.1504384   0.40074292  0.46073008  0.22708264  0.30174172]\n",
      "    \n",
      "Loss at step 500: 0.028462\n",
      "Minibatch accuracy: 99.8%\n",
      "W :  [ 0.32414538  0.57468277  0.82020456  0.87455934  0.7519275 ]\n",
      "B :  [ 0.15521587  0.40252605  0.46135822  0.22549085  0.30328566]\n",
      "    \n",
      "Loss at step 1000: 0.050974\n",
      "Minibatch accuracy: 99.7%\n",
      "W :  [ 0.32037863  0.57408577  0.81128937  0.86769348  0.7653271 ]\n",
      "B :  [ 0.15767796  0.4010554   0.45964393  0.22746535  0.30365333]\n",
      "    \n",
      "Loss at step 1500: 0.154674\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.32116643  0.57428652  0.80741251  0.88805264  0.77746135]\n",
      "B :  [ 0.15756766  0.40370744  0.46659869  0.23109894  0.30306798]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 22  Complete with accuracy: 99.65%\n",
      "Epoch 22  Test Accuracy : 93.41%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.113106\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31730509  0.58026463  0.81108481  0.89200616  0.77244711]\n",
      "B :  [ 0.15517704  0.40378562  0.46479702  0.23178229  0.30130547]\n",
      "    \n",
      "Loss at step 500: 0.006039\n",
      "Minibatch accuracy: 100.0%\n",
      "W :  [ 0.32169867  0.57405573  0.81930387  0.89804119  0.76927751]\n",
      "B :  [ 0.15211886  0.40486017  0.46603456  0.23008429  0.30473429]\n",
      "    \n",
      "Loss at step 1000: 0.089186\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.32093665  0.58360589  0.84307414  0.90755695  0.76898235]\n",
      "B :  [ 0.15727474  0.40603444  0.47134969  0.23165649  0.31197029]\n",
      "    \n",
      "Loss at step 1500: 0.092583\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.32140037  0.58124107  0.84175605  0.90355432  0.7658155 ]\n",
      "B :  [ 0.15361281  0.40764338  0.47053546  0.23525742  0.31081495]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 23  Complete with accuracy: 99.57%\n",
      "Epoch 23  Test Accuracy : 94.44%\n",
      "------------------------------------\n",
      "        \n",
      "Loss at step 0: 0.046221\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.32075226  0.58197248  0.83845097  0.9011696   0.76116961]\n",
      "B :  [ 0.15367045  0.40633211  0.46832263  0.23758094  0.30919191]\n",
      "    \n",
      "Loss at step 500: 0.047402\n",
      "Minibatch accuracy: 99.5%\n",
      "W :  [ 0.32340339  0.6021772   0.83846653  0.88897473  0.76503968]\n",
      "B :  [ 0.15303956  0.41087615  0.47177994  0.24001771  0.32046527]\n",
      "    \n",
      "Loss at step 1000: 0.118018\n",
      "Minibatch accuracy: 99.2%\n",
      "W :  [ 0.32136354  0.61292082  0.85138983  0.88899815  0.75791621]\n",
      "B :  [ 0.15860535  0.41059053  0.47273391  0.24419607  0.31381333]\n",
      "    \n",
      "Loss at step 1500: 0.058318\n",
      "Minibatch accuracy: 99.4%\n",
      "W :  [ 0.31879929  0.61383438  0.85652918  0.89374602  0.74403971]\n",
      "B :  [ 0.15234016  0.41058254  0.47669077  0.24160387  0.31736088]\n",
      "    \n",
      "------------------------------------\n",
      "Epoch 24  Complete with accuracy: 99.38%\n",
      "Epoch 24  Test Accuracy : 93.56%\n",
      "------------------------------------\n",
      "        \n",
      "Training Complete on MNIST Data\n",
      "Test Accuracy :  94.01979565772668\n",
      "Model saved in file: saved_models/combined/box_on_mnist/CNN_SVHN_Box_on_Mnist.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset\n",
    "label_data = train_labels\n",
    "print('train : ', train_data.shape, '  test : ', label_data.shape)\n",
    "\n",
    "box_train_dict = {}\n",
    "batch_size = 128\n",
    "num_steps = int(label_data.shape[0] / batch_size)\n",
    "num_epochs = 25\n",
    "\n",
    "with tf.Session(graph=graph_svhn) as session:\n",
    "    # tf.global_variables_initializer().run()\n",
    "    model_saver.restore(session, saved_mnist_model)\n",
    "    print('Initialized')\n",
    "\n",
    "    test_batch = int(test_dataset.shape[0]/num_epochs)\n",
    "    test_acc = list()\n",
    "    \n",
    "    for epoch in range(num_epochs - 1):\n",
    "        res_epoch = {}\n",
    "        t_data = test_dataset[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        t_label = test_labels[epoch*test_batch:(epoch+1)*test_batch]\n",
    "        \n",
    "        for step in range(num_steps - 1):\n",
    "            max_learning_rate = 0.0005\n",
    "            min_learning_rate = 0.0001\n",
    "\n",
    "            decay_speed = 5000.0\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-step/decay_speed)\n",
    "\n",
    "            batch_data = train_data[step*batch_size:(step + 1)*batch_size, :, :, :]\n",
    "            batch_labels = label_data[step*batch_size:(step + 1)*batch_size, :]\n",
    "\n",
    "            feed_dict = {X : batch_data, Y_ : batch_labels, pkeep : 0.80, alpha : learning_rate}\n",
    "            _, l, train_pred, W, b = session.run([train_step, cross_entropy, train_prediction, W_s, b_s], feed_dict=feed_dict)\n",
    "            accuracy = float(acc(train_pred, batch_labels[:,1:6]))\n",
    "\n",
    "            if (step % 500 == 0):\n",
    "                minibatch = {}\n",
    "                minibatch['loss'] = l\n",
    "                minibatch['W'] = W\n",
    "                minibatch['B'] = b\n",
    "                minibatch['accuracy'] = \"%.2f\" % accuracy\n",
    "\n",
    "                res_epoch[int(step/500)] = minibatch\n",
    "                print('Loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % acc(train_pred, batch_labels[:,1:6]))\n",
    "                print('W : ',W)\n",
    "                print('B : ',b)\n",
    "                print('    ')\n",
    "                \n",
    "        box_train_dict[epoch+1] = res_epoch\n",
    "\n",
    "        epoch_acc = 0\n",
    "        for f in res_epoch:\n",
    "            minibatch = res_epoch[f]\n",
    "            epoch_acc += float(minibatch['accuracy'])\n",
    "        epoch_acc = float(epoch_acc/len(res_epoch))\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : t_data, Y_ : t_label, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = float(acc(predictions, t_label[:,1:6]))\n",
    "        test_acc.append(accuracy)\n",
    "\n",
    "        print('------------------------------------')\n",
    "        print('Epoch',epoch+1,' Complete with accuracy: %.2f%%' % epoch_acc)\n",
    "        print('Epoch',epoch+1,' Test Accuracy : %.2f%%' % accuracy)\n",
    "        print('------------------------------------')\n",
    "        print('        ')\n",
    "            \n",
    "    print('Training Complete on MNIST Data')\n",
    "    print('Test Accuracy : ', mean(test_acc))\n",
    "    \n",
    "    save_path = model_saver.save(session, model_to_save)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'results/Box_on_Mnist.pickle'\n",
    "\n",
    "with open(file, 'wb') as handle:\n",
    "    pickle.dump(box_train_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Valid-Accuracy 0\n",
      "Valid accuracy:  96.3\n",
      "        \n",
      "Valid-Accuracy 1\n",
      "Valid accuracy:  96.12\n",
      "        \n",
      "Valid-Accuracy 2\n",
      "Valid accuracy:  95.56\n",
      "        \n",
      "Valid-Accuracy 3\n",
      "Valid accuracy:  95.84\n",
      "        \n",
      "Valid-Accuracy 4\n",
      "Valid accuracy:  95.52\n",
      "        \n",
      "-----  FINAL  ------\n",
      "Final Validation Set Accuracy :  95.87\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_svhn) as session: \n",
    "    print('Initialized')\n",
    "    batch = 1000\n",
    "    \n",
    "    valid_acc = list()\n",
    "    valid_no = int(valid_labels.shape[0] /  batch)\n",
    "    for i in range(valid_no - 1):\n",
    "        model_saver.restore(session, model_to_save)\n",
    "        data = valid_dataset[i*batch:(i+1)*batch]\n",
    "        labels = valid_labels[i*batch:(i+1)*batch]\n",
    "        \n",
    "        _, l, predictions = session.run([train_step, cross_entropy, train_prediction], feed_dict={X : data, Y_ : labels, pkeep : 1.0, alpha : 0.002})\n",
    "        accuracy = acc(predictions, labels[:,1:6])\n",
    "        valid_acc.append(accuracy)\n",
    "        \n",
    "        print('Valid-Accuracy', i)\n",
    "        print('Valid accuracy: ', accuracy)\n",
    "        print('        ')\n",
    "            \n",
    "    valid_avg = mean(valid_acc)\n",
    "    \n",
    "    print('-----  FINAL  ------')\n",
    "    print('Final Validation Set Accuracy : ',\"%.2f\" % valid_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
